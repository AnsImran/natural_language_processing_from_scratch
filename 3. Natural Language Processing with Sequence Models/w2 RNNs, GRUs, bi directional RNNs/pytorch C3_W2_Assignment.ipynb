{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YePowkb73k2O",
   "metadata": {
    "id": "YePowkb73k2O"
   },
   "source": [
    "# ------------------------ **pytorch** ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-Jv7Y4hXwt0j",
   "metadata": {
    "id": "-Jv7Y4hXwt0j"
   },
   "source": [
    "# Assignment 2:  Deep N-grams\n",
    "\n",
    "Welcome to the second assignment of course 3. In this assignment you will explore Recurrent Neural Networks `RNN`.\n",
    "- You will be using the fundamentals of pytorch to implement any kind of deeplearning model.\n",
    "\n",
    "By completing this assignment, you will learn how to implement models from scratch:\n",
    "- How to convert a line of text into a tensor\n",
    "- Create an iterator to feed data to the model\n",
    "- Define a GRU model using `pytorch`\n",
    "- Train the model using `pytorch`\n",
    "- Compute the accuracy of your model using the perplexity\n",
    "- Predict using your own model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V8_3fIOdkGv1",
   "metadata": {
    "id": "V8_3fIOdkGv1"
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Overview](#0)\n",
    "- [1 - Importing the Data](#1)\n",
    "    - [1.1 - Loading in the Data](#1-1)\n",
    "    - [1.2 - Convert a Line to Tensor](#1-2)\n",
    "        - [Exercise 1 - line_to_tensor (UNQ_C1)](#ex-1)\n",
    "    - [1.3 - Batch Generator](#1-3)\n",
    "        - [Exercise 2 - data_generator (UNQ_C2)](#ex-2)\n",
    "    - [1.4 - Repeating Batch Generator](#1-4)        \n",
    "- [2 - Defining the GRU Model](#2)\n",
    "    - [Exercise 3 - GRULM (UNQ_C3)](#ex-3)\n",
    "- [3 - Training](#3)\n",
    "    - [3.1 - Training the Model](#3-1)\n",
    "        - [Exercise 4 - train_model (UNQ_C4)](#ex-4)\n",
    "- [4 - Evaluation](#4)\n",
    "    - [4.1 - Evaluating using the Deep Nets](#4-1)\n",
    "        - [Exercise 5 - test_model (UNQ_C5)](#ex-5)\n",
    "- [5 - Generating the Language with your Own Model](#5)    \n",
    "- [Summary](#6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JP0inrk5kGv3",
   "metadata": {
    "id": "JP0inrk5kGv3"
   },
   "source": [
    "<a name='0'></a>\n",
    "## Overview\n",
    "\n",
    "Your task will be to predict the next set of characters using the previous characters.\n",
    "- Although this task sounds simple, it is pretty useful.\n",
    "- You will start by converting a line of text into a tensor\n",
    "- Then you will create a generator to feed data into the model\n",
    "- You will train a neural network in order to predict the new set of characters of defined length.\n",
    "- You will use embeddings for each character and feed them as inputs to your model.\n",
    "    - Many natural language tasks rely on using embeddings for predictions.\n",
    "- Your model will convert each character to its embedding, run the embeddings through a Gated Recurrent Unit `GRU`, and run it through a linear layer to predict the next set of characters.\n",
    "\n",
    "<img src = \"images/model.png\" style=\"width:600px;height:150px;\"/>\n",
    "\n",
    "The figure above gives you a summary of what you are about to implement.\n",
    "- You will get the embeddings;\n",
    "- Stack the embeddings on top of each other;\n",
    "- Run them through two layers with a relu activation in the middle;\n",
    "- Finally, you will compute the softmax.\n",
    "\n",
    "To predict the next character:\n",
    "- Use the softmax output and identify the word with the highest probability.\n",
    "- The word with the highest probability is the prediction for the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RVSwzQ5Bwt0m",
   "metadata": {
    "id": "RVSwzQ5Bwt0m"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "\n",
    "# set random seed\n",
    "rnd.seed(32)\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4sF9Hqzgwt0l",
   "metadata": {
    "id": "4sF9Hqzgwt0l"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Importing the Data\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Loading in the Data\n",
    "\n",
    "<img src = \"images/shakespeare.png\" style=\"width:250px;height:250px;\"/>\n",
    "\n",
    "Now import the dataset and do some processing.\n",
    "- The dataset has one sentence per line.\n",
    "- You will be doing character generation, so you have to process each sentence by converting each **character** (and not word) to a number.\n",
    "- You will use the `ord` function to convert a unique character to a unique integer ID.\n",
    "- Store each line in a list.\n",
    "- Create a data generator that takes in the `batch_size` and the `max_length`.\n",
    "    - The `max_length` corresponds to the maximum length of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9YIsUb8J3ODM",
   "metadata": {
    "id": "9YIsUb8J3ODM",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "dirname = 'data/'\n",
    "filename = 'shakespeare_data.txt'\n",
    "lines = [] # storing all the lines in a variable.\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with open(filename) as files:\n",
    "    for line in files:\n",
    "        # remove leading and trailing whitespace    \n",
    "        pure_line = line.strip()\n",
    "\n",
    "        # if pure_line is not the empty string,\n",
    "        if pure_line:\n",
    "            # append it to the list\n",
    "            lines.append(pure_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "-zMCe7aJkGwA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zMCe7aJkGwA",
    "outputId": "2b4955be-b6c6-4c7f-afa6-d38f3f0268c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "Sample line at position 0 A LOVER'S COMPLAINT\n",
      "Sample line at position 999 With this night's revels and expire the term\n"
     ]
    }
   ],
   "source": [
    "n_lines = len(lines)\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sample line at position 999 {lines[999]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G6XsiyHvkGwD",
   "metadata": {
    "id": "G6XsiyHvkGwD"
   },
   "source": [
    "Notice that the letters are both uppercase and lowercase.  In order to reduce the complexity of the task, we will convert all characters to lowercase.  This way, the model only needs to predict the likelihood that a letter is 'a' and not decide between uppercase 'A' and lowercase 'a'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "UBO9jI8EkGwE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBO9jI8EkGwE",
    "outputId": "0dc140b2-38d6-494c-aedf-2cbbb2a4f150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 125097\n",
      "Sample line at position 0 a lover's complaint\n",
      "Sample line at position 999 with this night's revels and expire the term\n"
     ]
    }
   ],
   "source": [
    "# go through each line\n",
    "for i, line in enumerate(lines):\n",
    "    # convert to all lowercase\n",
    "    lines[i] = line.lower()        # new list nahi bnanai pri, vohi puranin ist hi uodate ho gai\n",
    "\n",
    "print(f\"Number of lines: {n_lines}\")\n",
    "print(f\"Sample line at position 0 {lines[0]}\")\n",
    "print(f\"Sample line at position 999 {lines[999]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "EBLScZNs3ODO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBLScZNs3ODO",
    "outputId": "20fa550c-dfce-4873-ccb3-05c928afd3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines for training: 124097\n",
      "Number of lines for validation: 1000\n"
     ]
    }
   ],
   "source": [
    "eval_lines = lines[-1000:] # Create a holdout validation set\n",
    "lines      = lines[:-1000] # Leave the rest for training\n",
    "\n",
    "print(f\"Number of lines for training: {len(lines)}\")\n",
    "print(f\"Number of lines for validation: {len(eval_lines)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BDcxEmX31y3d",
   "metadata": {
    "id": "BDcxEmX31y3d"
   },
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Convert a Line to Tensor\n",
    "\n",
    "Now that you have your list of lines, you will convert each character in that list to a number. You can use Python's `ord` function to do it.\n",
    "\n",
    "Given a string representation of one Unicode character, the `ord` function return an integer representing the Unicode code point of that character.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Cc_B8ae3kGwI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cc_B8ae3kGwI",
    "outputId": "0e20f3da-f44b-4871-ecd1-a18db9a8d692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ord('a'): 97\n",
      "ord('b'): 98\n",
      "ord('c'): 99\n",
      "ord(' '): 32\n",
      "ord('x'): 120\n",
      "ord('y'): 121\n",
      "ord('z'): 122\n",
      "ord('1'): 49\n",
      "ord('2'): 50\n",
      "ord('3'): 51\n"
     ]
    }
   ],
   "source": [
    "# View the unique unicode integer associated with each character\n",
    "print(f\"ord('a'): {ord('a')}\")\n",
    "print(f\"ord('b'): {ord('b')}\")\n",
    "print(f\"ord('c'): {ord('c')}\")\n",
    "print(f\"ord(' '): {ord(' ')}\")    # blank space ko bhi aik number associate kia hua hay\n",
    "print(f\"ord('x'): {ord('x')}\")\n",
    "print(f\"ord('y'): {ord('y')}\")\n",
    "print(f\"ord('z'): {ord('z')}\")\n",
    "print(f\"ord('1'): {ord('1')}\")\n",
    "print(f\"ord('2'): {ord('2')}\")\n",
    "print(f\"ord('3'): {ord('3')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZWB9qOLOkGwL",
   "metadata": {
    "id": "ZWB9qOLOkGwL"
   },
   "source": [
    "### Line_to_tensor\n",
    "\n",
    "**Instructions:** Write a function that takes in a single line and transforms each character into its unicode integer.  **This returns a list of integers, which we'll refer to as a tensor**.\n",
    "- Use a special integer to represent the end of the sentence (the end of the line).\n",
    "- This will be the EOS_int (end of sentence integer) parameter of the function.\n",
    "- Include the EOS_int as the last integer of the\n",
    "- For this exercise, you will use the number `1` to represent the end of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IO4NSPkOITNK",
   "metadata": {
    "id": "IO4NSPkOITNK"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: line_to_tensor\n",
    "def line_to_tensor(line, EOS_int=1):\n",
    "    \"\"\"Turns a line of text into a tensor\n",
    "\n",
    "    Args:\n",
    "        line (str): A single line of text.\n",
    "        EOS_int (int, optional): End-of-sentence integer. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        list: a list of integers (unicode values) for the characters in the `line`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the tensor as an empty list\n",
    "    tensor = []\n",
    "\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # for each character:\n",
    "    for c in line:\n",
    "\n",
    "        # convert to unicode int\n",
    "        c_int = ord(c)              # current integer\n",
    "\n",
    "        # append the unicode integer to the tensor list\n",
    "        tensor.append(c_int)        # abhi ye aik list hi hay\n",
    "\n",
    "    # include the end-of-sentence integer\n",
    "    tensor.append(EOS_int)          # sentence poray par loop chal gai, ab end main hum nay aik End Of Sequence integer append kar dia\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "D9Z_vtI7tTcw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9Z_vtI7tTcw",
    "outputId": "c0f794bf-0704-4df8-ba7e-22f3504592a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[97, 98, 99, 32, 120, 121, 122, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing your output\n",
    "line_to_tensor('abc xyz')  # white space k corresponding bhi aik integer hay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7MwEspKCtTc4",
   "metadata": {
    "id": "7MwEspKCtTc4"
   },
   "source": [
    "##### Expected Output\n",
    "```CPP\n",
    "[97, 98, 99, 32, 120, 121, 122, 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fOiMZU52s2b",
   "metadata": {
    "id": "3fOiMZU52s2b"
   },
   "source": [
    "# Converting Data to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uZtTHNNU2eLo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZtTHNNU2eLo",
    "outputId": "7af49727-ec22-40f4-93ac-8f93d494fb74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a lover's complaint\",\n",
       " 'from off a hill whose concave womb reworded',\n",
       " 'a plaintful story from a sistering vale,',\n",
       " 'my spirits to attend this double voice accorded,',\n",
       " 'and down i laid to list the sad-tuned tale;']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ZNHGq5ey2ePJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZNHGq5ey2ePJ",
    "outputId": "4118a1dd-d1e2-4da9-ca0e-60cd4570d0f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a lover's complaint\n",
      "from off a hill whose concave womb reworded\n",
      "a plaintful story from a sistering vale,\n",
      "my spirits to attend this double voice accorded,\n",
      "and down i laid to list the sad-tuned tale;\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for line in lines:\n",
    "  i+=1\n",
    "  print(line)\n",
    "  if i>=5:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ypQ2EE-2eSR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ypQ2EE-2eSR",
    "outputId": "cf86b08b-3f59-4f2b-9e67-fd1a9ad9f9a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97, 32, 108, 111, 118, 101, 114, 39, 115, 32, 99, 111, 109, 112, 108, 97, 105, 110, 116, 1], [102, 114, 111, 109, 32, 111, 102, 102, 32, 97, 32, 104, 105, 108, 108, 32, 119, 104, 111, 115, 101, 32, 99, 111, 110, 99, 97, 118, 101, 32, 119, 111, 109, 98, 32, 114, 101, 119, 111, 114, 100, 101, 100, 1], [97, 32, 112, 108, 97, 105, 110, 116, 102, 117, 108, 32, 115, 116, 111, 114, 121, 32, 102, 114, 111, 109, 32, 97, 32, 115, 105, 115, 116, 101, 114, 105, 110, 103, 32, 118, 97, 108, 101, 44, 1]]\n"
     ]
    }
   ],
   "source": [
    "tensor_list = []\n",
    "i=0\n",
    "for line in lines:\n",
    "    i+=1\n",
    "    current_tensor = line_to_tensor(line)\n",
    "    tensor_list.append(current_tensor)\n",
    "    if i>=3:\n",
    "        break\n",
    "print(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "l_NAIBN72eU5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_NAIBN72eU5",
    "outputId": "427ba549-7106-4b2f-e085-e441224528a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 32, 108, 111, 118, 101, 114, 39, 115, 32, 99, 111, 109, 112, 108, 97, 105, 110, 116, 1]\n"
     ]
    }
   ],
   "source": [
    "print(tensor_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1RCsvh8f2eXP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RCsvh8f2eXP",
    "outputId": "cd9cb331-56b3-4610-d32c-712ce68522ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 32, 108, 111, 118, 101, 114, 39, 115, 32, 99, 111, 109, 112, 108, 97, 105, 110, 116, 1]\n"
     ]
    }
   ],
   "source": [
    "print(line_to_tensor(lines[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44760852-fd3f-454f-a1d2-6fc787b4460d",
   "metadata": {},
   "source": [
    "## Tensor List\n",
    "List of all tensorized string lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "r0oEjDnm2ean",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0oEjDnm2ean",
    "outputId": "d51ce1f5-510a-423e-fb01-721464525e75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122689\n"
     ]
    }
   ],
   "source": [
    "max_len=64\n",
    "tensor_list = []\n",
    "# i=0\n",
    "for line in lines:\n",
    "    # i+=1\n",
    "    current_tensor = line_to_tensor(line)\n",
    "    if len(current_tensor) <= max_len:\n",
    "        tensor_list.append(current_tensor)\n",
    "    # if i>=3:\n",
    "    #     break\n",
    "print(len(tensor_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9807eea-0194-4f3e-8f44-9627d89f13fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines) - len(tensor_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63aebf70-7ba1-4765-8a0b-4f437c2eb558",
   "metadata": {},
   "source": [
    "## Tensor Array\n",
    "tensor list converted into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93901eb8-cbe4-4886-b48c-305fec824283",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93901eb8-cbe4-4886-b48c-305fec824283",
    "outputId": "14177854-d280-49c7-a87e-035eae2d2258"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix = np.zeros((len(tensor_list), 64))\n",
    "tensor_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2217edaf-ac56-43af-8f32-965d469ebdd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2217edaf-ac56-43af-8f32-965d469ebdd4",
    "outputId": "f4ee7c43-1bfc-4370-aa3b-44fcf2b141ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122689, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1a615cf-c9fd-4e33-afb7-d75bcf00871f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b1a615cf-c9fd-4e33-afb7-d75bcf00871f",
    "outputId": "347a3c54-d140-4e29-f227-b079a1d3fe0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 97.,  32., 108., 111., 118., 101., 114.,  39., 115.,  32.,  99.,\n",
       "        111., 109., 112., 108.,  97., 105., 110., 116.,   1.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [102., 114., 111., 109.,  32., 111., 102., 102.,  32.,  97.,  32.,\n",
       "        104., 105., 108., 108.,  32., 119., 104., 111., 115., 101.,  32.,\n",
       "         99., 111., 110.,  99.,  97., 118., 101.,  32., 119., 111., 109.,\n",
       "         98.,  32., 114., 101., 119., 111., 114., 100., 101., 100.,   1.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [ 97.,  32., 112., 108.,  97., 105., 110., 116., 102., 117., 108.,\n",
       "         32., 115., 116., 111., 114., 121.,  32., 102., 114., 111., 109.,\n",
       "         32.,  97.,  32., 115., 105., 115., 116., 101., 114., 105., 110.,\n",
       "        103.,  32., 118.,  97., 108., 101.,  44.,   1.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for tensor in tensor_list:                   # for i, tensor in enumerate(tensor_list):\n",
    "    tensor_matrix[i,:len(tensor)] = tensor\n",
    "    i+=1\n",
    "    if i>=3:\n",
    "        break\n",
    "tensor_matrix[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92d25d3f-738f-4d88-b097-cd6da69b3fc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92d25d3f-738f-4d88-b097-cd6da69b3fc6",
    "outputId": "a685203a-73dd-4875-a5d2-bdc61ffcbd0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97.,  32., 108., 111., 118., 101., 114.,  39., 115.,  32.,  99.,\n",
       "       111., 109., 112., 108.,  97., 105., 110., 116.,   1.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_matrix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7df3d806-805a-4cd4-a45d-34c5b6a8093f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7df3d806-805a-4cd4-a45d-34c5b6a8093f",
    "outputId": "5844fafc-59a6-4a87-adc2-aba98f6dc6e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97, 32, 108, 111, 118, 101, 114, 39, 115, 32, 99, 111, 109, 112, 108, 97, 105, 110, 116, 1]\n"
     ]
    }
   ],
   "source": [
    "print(line_to_tensor(lines[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0bcbe95-ad44-4fe2-a725-511a358cd576",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0bcbe95-ad44-4fe2-a725-511a358cd576",
    "outputId": "21dc148e-e981-4fd8-ff04-34d3c5dd0574"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97.,  32., 108., 111., 118., 101., 114.,  39., 115.,  32.,  99.,\n",
       "       111., 109., 112., 108.,  97., 105., 110., 116.,   1.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for tensor in tensor_list:\n",
    "    tensor_matrix[i,:len(tensor)] = tensor\n",
    "    i+=1\n",
    "    # if i>=3:\n",
    "    #     break\n",
    "tensor_matrix[0,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f974d4-31e5-4a56-a3c3-768b244eccce",
   "metadata": {},
   "source": [
    "## Training and Evaluation Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50751493-b4c2-4298-a5a8-cdf864febf32",
   "metadata": {
    "id": "50751493-b4c2-4298-a5a8-cdf864febf32"
   },
   "outputs": [],
   "source": [
    "inputs         = tensor_matrix.copy()\n",
    "shifted_inputs = tensor_matrix.copy()\n",
    "targets        = tensor_matrix.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ad3519-dc40-4988-bedc-0ffe29d9c341",
   "metadata": {},
   "source": [
    "### shifting the inputs to the right by 1 index\n",
    "necessary for current assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d22b1d2-6204-4e00-93d7-e96a7b472f74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d22b1d2-6204-4e00-93d7-e96a7b472f74",
    "outputId": "ae601508-f7fa-473e-cc09-bd2ccea96a1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolled array: [5 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Roll the array by 1 position to the right\n",
    "rolled_arr = np.roll(arr, 1)\n",
    "print(\"Rolled array:\", rolled_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "752ee181-3849-4d31-9fcb-4e3ee8d4a617",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "752ee181-3849-4d31-9fcb-4e3ee8d4a617",
    "outputId": "a4365344-ac45-4dcc-df88-b5821f2c6d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,  97.,  32., 108., 111., 118., 101., 114.,  39., 115.,  32.,\n",
       "        99., 111., 109., 112., 108.,  97., 105., 110., 116.,   1.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_inputs = np.roll(shifted_inputs, 1)\n",
    "shifted_inputs[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8eba6efe-f537-4f60-9071-f112188ecbb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eba6efe-f537-4f60-9071-f112188ecbb8",
    "outputId": "3eec7273-5ba8-4447-975b-18feddfda8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 97.,  32., 108., 111., 118., 101., 114.,  39., 115.,  32.,  99.,\n",
       "       111., 109., 112., 108.,  97., 105., 110., 116.,   1.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634b416-fc03-47fe-9eea-82d1f4ab2ede",
   "metadata": {},
   "source": [
    "### Converting the numpy arrays into torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ce0ccf2-be9b-4d86-b25c-3c6e362b89b5",
   "metadata": {
    "id": "0ce0ccf2-be9b-4d86-b25c-3c6e362b89b5"
   },
   "outputs": [],
   "source": [
    "inputs         = torch.from_numpy(inputs).long()\n",
    "shifted_inputs = torch.from_numpy(shifted_inputs).long()\n",
    "targets        = torch.from_numpy(targets).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de597c68-84d4-4d8e-88de-bda685da6dfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de597c68-84d4-4d8e-88de-bda685da6dfe",
    "outputId": "acc793c3-4106-488c-c392-05aadcdd7971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97,  32, 108, 111, 118, 101, 114,  39, 115,  32,  99, 111, 109, 112,\n",
       "        108,  97, 105, 110, 116,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047ca12-d803-41a5-abeb-c601f21eca58",
   "metadata": {},
   "source": [
    "## Training and Evaluation Data generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4g1t9B-qBeCQ",
   "metadata": {
    "id": "4g1t9B-qBeCQ"
   },
   "outputs": [],
   "source": [
    "def shifted_inputs_and_NOT_shifted_targets_generator(shifted_inputs_, targets_, batch_size_):\n",
    "\n",
    "  counter = 0\n",
    "  second_counter = batch_size_\n",
    "  while True:\n",
    "    batch_of_shifted_inputs_ = shifted_inputs_[counter:second_counter]\n",
    "    batch_of_targets_        = targets_[counter:second_counter]\n",
    "\n",
    "    yield batch_of_shifted_inputs_, batch_of_targets_\n",
    "\n",
    "    counter        = counter + batch_size_\n",
    "    second_counter = second_counter + batch_size_\n",
    "    if second_counter >= shifted_inputs_.shape[0]:\n",
    "      counter=0\n",
    "      second_counter = batch_size_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "N-_rJzeuEJtc",
   "metadata": {
    "id": "N-_rJzeuEJtc"
   },
   "outputs": [],
   "source": [
    "gen = shifted_inputs_and_NOT_shifted_targets_generator(shifted_inputs_=shifted_inputs, targets_=targets, batch_size_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "KbqsYoy7BeLo",
   "metadata": {
    "id": "KbqsYoy7BeLo"
   },
   "outputs": [],
   "source": [
    "tmp_inputs, tmp_targets = next(gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pYRiSdFOEbLT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYRiSdFOEbLT",
    "outputId": "50c6e057-ac58-46d7-9a1f-bd2777083adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,  97,  32, 108, 111, 118, 101, 114,  39, 115,  32,  99, 111, 109,\n",
       "          112, 108,  97, 105, 110, 116,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 102, 114, 111, 109,  32, 111, 102, 102,  32,  97,  32, 104, 105,\n",
       "          108, 108,  32, 119, 104, 111, 115, 101,  32,  99, 111, 110,  99,  97,\n",
       "          118, 101,  32, 119, 111, 109,  98,  32, 114, 101, 119, 111, 114, 100,\n",
       "          101, 100,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " tensor([[ 97,  32, 108, 111, 118, 101, 114,  39, 115,  32,  99, 111, 109, 112,\n",
       "          108,  97, 105, 110, 116,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [102, 114, 111, 109,  32, 111, 102, 102,  32,  97,  32, 104, 105, 108,\n",
       "          108,  32, 119, 104, 111, 115, 101,  32,  99, 111, 110,  99,  97, 118,\n",
       "          101,  32, 119, 111, 109,  98,  32, 114, 101, 119, 111, 114, 100, 101,\n",
       "          100,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inputs, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fGg1BbxHU8zd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGg1BbxHU8zd",
    "outputId": "07a4992c-b659-4418-93c4-e002b2ab6ac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inputs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tjaRyoEeEeud",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjaRyoEeEeud",
    "outputId": "38f20922-76eb-48ba-d710-63e80347f672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,  97,  32, 112, 108,  97, 105, 110, 116, 102, 117, 108,  32, 115,\n",
       "          116, 111, 114, 121,  32, 102, 114, 111, 109,  32,  97,  32, 115, 105,\n",
       "          115, 116, 101, 114, 105, 110, 103,  32, 118,  97, 108, 101,  44,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 109, 121,  32, 115, 112, 105, 114, 105, 116, 115,  32, 116, 111,\n",
       "           32,  97, 116, 116, 101, 110, 100,  32, 116, 104, 105, 115,  32, 100,\n",
       "          111, 117,  98, 108, 101,  32, 118, 111, 105,  99, 101,  32,  97,  99,\n",
       "           99, 111, 114, 100, 101, 100,  44,   1,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " tensor([[ 97,  32, 112, 108,  97, 105, 110, 116, 102, 117, 108,  32, 115, 116,\n",
       "          111, 114, 121,  32, 102, 114, 111, 109,  32,  97,  32, 115, 105, 115,\n",
       "          116, 101, 114, 105, 110, 103,  32, 118,  97, 108, 101,  44,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [109, 121,  32, 115, 112, 105, 114, 105, 116, 115,  32, 116, 111,  32,\n",
       "           97, 116, 116, 101, 110, 100,  32, 116, 104, 105, 115,  32, 100, 111,\n",
       "          117,  98, 108, 101,  32, 118, 111, 105,  99, 101,  32,  97,  99,  99,\n",
       "          111, 114, 100, 101, 100,  44,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inputs, tmp_targets = next(gen)\n",
    "tmp_inputs, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "OZ4lZ4-SF1EC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZ4lZ4-SF1EC",
    "outputId": "79cbc518-93eb-4a18-f316-ecca7226112c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,  97, 110, 100,  32, 100, 111, 119, 110,  32, 105,  32, 108,  97,\n",
       "          105, 100,  32, 116, 111,  32, 108, 105, 115, 116,  32, 116, 104, 101,\n",
       "           32, 115,  97, 100,  45, 116, 117, 110, 101, 100,  32, 116,  97, 108,\n",
       "          101,  59,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 101, 114, 101,  32, 108, 111, 110, 103,  32, 101, 115, 112, 105,\n",
       "          101, 100,  32,  97,  32, 102, 105,  99, 107, 108, 101,  32, 109,  97,\n",
       "          105, 100,  32, 102, 117, 108, 108,  32, 112,  97, 108, 101,  44,   1,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " tensor([[ 97, 110, 100,  32, 100, 111, 119, 110,  32, 105,  32, 108,  97, 105,\n",
       "          100,  32, 116, 111,  32, 108, 105, 115, 116,  32, 116, 104, 101,  32,\n",
       "          115,  97, 100,  45, 116, 117, 110, 101, 100,  32, 116,  97, 108, 101,\n",
       "           59,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [101, 114, 101,  32, 108, 111, 110, 103,  32, 101, 115, 112, 105, 101,\n",
       "          100,  32,  97,  32, 102, 105,  99, 107, 108, 101,  32, 109,  97, 105,\n",
       "          100,  32, 102, 117, 108, 108,  32, 112,  97, 108, 101,  44,   1,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inputs, tmp_targets = next(gen)\n",
    "tmp_inputs, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "Hgio62HjBeRY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hgio62HjBeRY",
    "outputId": "8705546d-aa77-47b0-c407-00ddb8b3296f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 109, 121,  32, 115, 112, 105, 114, 105, 116, 115,  32, 116, 111,\n",
       "         32,  97, 116, 116, 101, 110, 100,  32, 116, 104, 105, 115,  32, 100,\n",
       "        111, 117,  98, 108, 101,  32, 118, 111, 105,  99, 101,  32,  97,  99,\n",
       "         99, 111, 114, 100, 101, 100,  44,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_inputs[3,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaeac6b-2730-4d63-8172-ee325bd5d9c2",
   "metadata": {},
   "source": [
    "## Data Generator for calculating perplexity\n",
    "It generates one hot encoded targets, which are necessary for the computing perplexity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78370ea8-942a-4073-8184-352ca81e9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded tensor:\n",
      " tensor([[[1, 0, 0, 0],\n",
      "         [0, 1, 0, 0],\n",
      "         [0, 0, 1, 0]],\n",
      "\n",
      "        [[0, 1, 0, 0],\n",
      "         [0, 0, 1, 0],\n",
      "         [0, 0, 0, 1]]])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# Example usage\n",
    "categories = torch.tensor([[0,1,2],[1,2,3]])\n",
    "num_classes = 3\n",
    "one_hot_encoded = torch.nn.functional.one_hot(categories, num_classes=4)\n",
    "\n",
    "print(\"One-hot encoded tensor:\\n\", one_hot_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "KqKDymKGGWto",
   "metadata": {
    "id": "KqKDymKGGWto"
   },
   "outputs": [],
   "source": [
    "def shifted_inputs_and_one_hot_encoded_targets_generator(shifted_inputs_, targets_, batch_size_):\n",
    "\n",
    "  # num_of_epochs = shifted_inputs_.shape[0]/batch_size_\n",
    "  counter = 0\n",
    "  second_counter = batch_size_\n",
    "  while True:\n",
    "    batch_of_shifted_inputs_            = shifted_inputs_[counter:second_counter]\n",
    "    batch_of_one_hot_encoded_targets_   = torch.nn.functional.one_hot(targets_[counter:second_counter], num_classes=256)\n",
    "\n",
    "    yield batch_of_shifted_inputs_, batch_of_one_hot_encoded_targets_\n",
    "\n",
    "    counter        = counter + batch_size_\n",
    "    second_counter = second_counter + batch_size_\n",
    "    if second_counter >= shifted_inputs_.shape[0]:\n",
    "      counter=0\n",
    "      second_counter = batch_size_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "m_SHsP1sG6TE",
   "metadata": {
    "id": "m_SHsP1sG6TE"
   },
   "outputs": [],
   "source": [
    "gen = shifted_inputs_and_one_hot_encoded_targets_generator(shifted_inputs_=shifted_inputs, targets_=targets, batch_size_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9VwOyPP6G6TG",
   "metadata": {
    "id": "9VwOyPP6G6TG"
   },
   "outputs": [],
   "source": [
    "tmp_inputs, tmp_targets = next(gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "PZOL8m5gG6TH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PZOL8m5gG6TH",
    "outputId": "d6f39f23-92da-4177-b175-5073dc45a997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,  97,  32, 108, 111, 118, 101, 114,  39, 115,  32,  99, 111, 109,\n",
       "          112, 108,  97, 105, 110, 116,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0, 102, 114, 111, 109,  32, 111, 102, 102,  32,  97,  32, 104, 105,\n",
       "          108, 108,  32, 119, 104, 111, 115, 101,  32,  99, 111, 110,  99,  97,\n",
       "          118, 101,  32, 119, 111, 109,  98,  32, 114, 101, 119, 111, 114, 100,\n",
       "          101, 100,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0]]),\n",
       " tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 0, 0,  ..., 0, 0, 0],\n",
       "          [1, 0, 0,  ..., 0, 0, 0],\n",
       "          [1, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 0, 0,  ..., 0, 0, 0],\n",
       "          [1, 0, 0,  ..., 0, 0, 0],\n",
       "          [1, 0, 0,  ..., 0, 0, 0]]]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_inputs, tmp_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "I_QByS1EHBGG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_QByS1EHBGG",
    "outputId": "0cab9397-b1b4-45ab-a705-136f92ac3608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_targets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "W5I8WN6PGWyN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5I8WN6PGWyN",
    "outputId": "9dff049a-fc5e-490a-a807-2d9e59ce369f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(tmp_targets[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4SlvZF_GW1r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4SlvZF_GW1r",
    "outputId": "594c3809-bdda-4149-9ab7-105ce0095197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[97]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(tmp_targets[0,0,:])\n",
    "# perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf7f12-45b8-4f11-9120-0c15061ee12d",
   "metadata": {
    "id": "51ad400f-0db7-4685-a7e3-ea547b418e39"
   },
   "source": [
    "# I did'nt use the following data generator provided by course instructors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iFOR19cX2TQs",
   "metadata": {
    "id": "iFOR19cX2TQs"
   },
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Batch Generator\n",
    "\n",
    "Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. Here, you will build a data generator that takes in a text and returns a batch of text lines (lines are sentences).\n",
    "- The generator converts text lines (sentences) into numpy arrays of integers padded by zeros so that all arrays have the same length, which is **the length of the longest sentence in the ENTIRE data set** ???\n",
    "\n",
    "Once you create the generator, you can iterate on it like this:\n",
    "\n",
    "```\n",
    "next(data_generator)\n",
    "```\n",
    "\n",
    "This generator returns the data in a format that you could directly use in your model when computing the feed-forward of your algorithm. This iterator returns a batch of lines and per token mask. The batch is a tuple of three parts: inputs, targets, mask. The inputs and targets are identical. The second column will be used to evaluate your predictions. Mask is 1 for non-padding tokens.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - data_generator\n",
    "**Instructions:** Implement the data generator below. Here are some things you will need.\n",
    "\n",
    "- While True loop: this will yield one batch at a time.\n",
    "- if index >= num_lines, set index to 0.\n",
    "- The generator should return shuffled batches of data. To achieve this without modifying the actual lines a list containing the indexes of `data_lines` is created. This list can be shuffled and used to get random batches everytime the index is reset.\n",
    "- if len(line) < max_length append line to cur_batch.\n",
    "    - Note that a line that has length equal to max_length should not be appended to the batch.\n",
    "    - This is because when converting the characters into a tensor of integers, an additional end of sentence token id will be added.  \n",
    "    - So if max_length is 5, and a line has 4 characters, the tensor representing those 4 characters plus the end of sentence character will be of length 5, which is the max length.\n",
    "- if len(cur_batch) == batch_size, go over every line, convert it to an int and store it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ekSEQlvtTc7",
   "metadata": {
    "id": "_ekSEQlvtTc7"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>Use the line_to_tensor function above inside a list comprehension in order to pad lines with zeros.</li>\n",
    "    <li>Keep in mind that the length of the tensor is always 1 + the length of the original line of characters.  Keep this in mind when setting the padding of zeros.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6f6e4203-ce81-4a8e-b9b1-088c31de3783",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f6e4203-ce81-4a8e-b9b1-088c31de3783",
    "outputId": "f8552804-9d28-49bd-9d18-757de1933c7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "OMingz5xzrGD",
   "metadata": {
    "id": "OMingz5xzrGD"
   },
   "outputs": [],
   "source": [
    "# # UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# # GRADED FUNCTION: data_generator\n",
    "# def data_generator(batch_size, max_length, data_lines, line_to_tensor=line_to_tensor, shuffle=True):\n",
    "#     \"\"\"Generator function that yields batches of data\n",
    "\n",
    "#     Args:\n",
    "#         batch_size (int): number of examples (in this case, sentences) per batch.\n",
    "#         max_length (int): maximum length of the output tensor.                         # max length hum nay khud pass ki hay | function k andar, data say infer nahi kar rahay |\n",
    "#         NOTE: max_length includes the end-of-sentence character that will be added\n",
    "#                 to the tensor.\n",
    "#                 Keep in mind that the length of the tensor is always 1 + the length\n",
    "#                 of the original line of characters.\n",
    "#         data_lines (list): list of the sentences to group into batches.\n",
    "#         line_to_tensor (function, optional): function that converts line to tensor. Defaults to line_to_tensor.\n",
    "#         shuffle (bool, optional): True if the generator should generate random batches of data. Defaults to True.\n",
    "\n",
    "#     Yields:\n",
    "#         tuple: two copies of the batch and mask.\n",
    "#     \"\"\"\n",
    "#     # initialize the index that points to the current position in the lines index array\n",
    "#     index = 0\n",
    "\n",
    "#     # initialize the list that will contain the current batch\n",
    "#     cur_batch = []\n",
    "\n",
    "#     # count the number of lines in data_lines\n",
    "#     num_lines = len(data_lines)\n",
    "\n",
    "#     # create an array with the indexes of data_lines that can be shuffled\n",
    "#     lines_index = [*range(num_lines)]\n",
    "\n",
    "#     # shuffle line indexes if shuffle is set to True\n",
    "#     if shuffle:\n",
    "#         rnd.shuffle(lines_index)\n",
    "\n",
    "#     ### START CODE HERE ###\n",
    "#     while True:\n",
    "\n",
    "#         # if the index is greater than or equal to the number of lines in data_lines | yani agar aik baar saaray ka sara data read kar lia hay tu phir next set of batches nikalnay say pehlay dobara shuffle kr do\n",
    "#         if index >= num_lines:\n",
    "#             # then reset the index to 0\n",
    "#             index = 0\n",
    "#             # shuffle line indexes if shuffle is set to True\n",
    "#             if shuffle:\n",
    "#                 rnd.shuffle(lines_index)\n",
    "\n",
    "#         # get a line at the `lines_index[index]` position in data_lines\n",
    "#         line = data_lines[lines_index[index]]\n",
    "\n",
    "#         # if the length of the line is less than max_length\n",
    "#         if len(line) < max_length:\n",
    "#             # append the line to the current batch\n",
    "#             cur_batch.append(line)                               # initially string sentences k hi batch bana rahay hain\n",
    "\n",
    "#         # increment the index by one\n",
    "#         index += 1\n",
    "\n",
    "#         # if the current batch is now equal to the desired batch size\n",
    "#         if len(cur_batch) == batch_size:\n",
    "\n",
    "#             batch = []          # agar jitnay sentences aik batch main chahiye thay, otnay mil gaye hain, tu phir ab conversion-of-sentences-to-integers start krtay hain\n",
    "#             mask  = []\n",
    "\n",
    "#             # go through each line (li) in cur_batch\n",
    "#             for li in cur_batch:\n",
    "#                 # convert the line (li) to a tensor of integers\n",
    "#                 tensor = line_to_tensor(li)\n",
    "\n",
    "#                 # Create a list of zeros to represent the padding\n",
    "#                 # so that the tensor plus padding will have length `max_length`\n",
    "#                 pad = [0] * (max_length - len(tensor))\n",
    "\n",
    "#                 # combine the tensor plus pad\n",
    "#                 tensor_pad = tensor + pad\n",
    "\n",
    "#                 # append the padded tensor to the batch\n",
    "#                 batch.append(tensor_pad)\n",
    "\n",
    "#                 # A mask for this tensor_pad is 1 whereever tensor_pad is not\n",
    "#                 # 0 and 0 whereever tensor_pad is 0, i.e. if tensor_pad is\n",
    "#                 # [1, 2, 3, 0, 0, 0] then example_mask should be\n",
    "#                 # [1, 1, 1, 0, 0, 0]\n",
    "#                 example_mask = [0 if t == 0 else 1 for t in tensor_pad]\n",
    "#                 mask.append(example_mask) # @ KEEPTHIS                             # har sample ki creation k sath hi os ka mask bhi create kr lia | see nb 4 why mask is imp for perplexity score calcs\n",
    "\n",
    "#             # convert the batch (data type list) to a numpy array\n",
    "#             batch_np_arr = np.array(batch)\n",
    "#             mask_np_arr  = np.array(mask)\n",
    "\n",
    "#             ### END CODE HERE ##\n",
    "\n",
    "#             # Yield two copies of the batch and mask.\n",
    "#             yield batch_np_arr, batch_np_arr, mask_np_arr\n",
    "\n",
    "#             # reset the current batch to an empty list | curr_batch string-form-of-sentences  ko store krnay k liye use hotay tha,\n",
    "#             cur_batch = []                              # pehlay yeild krva lia, os k bad function continue raha, nice!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "a--X2VpI3ODR",
   "metadata": {
    "id": "a--X2VpI3ODR"
   },
   "outputs": [],
   "source": [
    "# # Try out your data generator\n",
    "# tmp_lines = ['12345678901', #length 11\n",
    "#              '123456789', # length 9\n",
    "#              '234567890', # length 9\n",
    "#              '345678901'] # length 9\n",
    "\n",
    "# # Get a batch size of 2, max length 10\n",
    "# tmp_data_gen = data_generator(batch_size = 2,\n",
    "#                               max_length = 10,\n",
    "#                               data_lines = tmp_lines,\n",
    "#                               shuffle    = False)\n",
    "\n",
    "# # get one batch\n",
    "# tmp_batch = next(tmp_data_gen)\n",
    "\n",
    "# # view the batch\n",
    "# tmp_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1rWMOk7ikGwZ",
   "metadata": {
    "id": "1rWMOk7ikGwZ"
   },
   "source": [
    "##### Expected output\n",
    "\n",
    "```CPP\n",
    "(array([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
    "              [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
    " array([[49, 50, 51, 52, 53, 54, 55, 56, 57,  1],\n",
    "              [50, 51, 52, 53, 54, 55, 56, 57, 48,  1]], dtype=int32),\n",
    " array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "670351d6-3d98-43a9-ae6b-7c7531fed3d3",
   "metadata": {
    "id": "670351d6-3d98-43a9-ae6b-7c7531fed3d3"
   },
   "outputs": [],
   "source": [
    "# type(tmp_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2842ad71-fd8f-485a-883b-db485c7e39f2",
   "metadata": {
    "id": "2842ad71-fd8f-485a-883b-db485c7e39f2"
   },
   "outputs": [],
   "source": [
    "# len(tmp_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d90ea900-18e0-4d98-96aa-130dd57417a0",
   "metadata": {
    "id": "d90ea900-18e0-4d98-96aa-130dd57417a0"
   },
   "outputs": [],
   "source": [
    "# tmp_batch[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "855ea8e1-f3db-49f6-9d44-c32d6b576e7f",
   "metadata": {
    "id": "855ea8e1-f3db-49f6-9d44-c32d6b576e7f"
   },
   "outputs": [],
   "source": [
    "# # Try out your data generator\n",
    "# tmp_lines = ['98765432101', #length 11\n",
    "#              '123456789', # length 9\n",
    "#              '234567890', # length 9\n",
    "#              '345'] # length 9\n",
    "\n",
    "# # Get a batch size of 2, max length 10\n",
    "# tmp_data_gen = data_generator(batch_size = 4,\n",
    "#                               max_length = 10,                  # jis sequnce ki length 10 say ziada thi, osay is nay siray say hi uthaya hi nahi, ye nahi k trim kr dain, nahi, uthaya hi nahi osay\n",
    "#                               data_lines = tmp_lines,\n",
    "#                               shuffle    = False)\n",
    "\n",
    "# # get one batch\n",
    "# tmp_batch = next(tmp_data_gen)\n",
    "\n",
    "# # view the batch\n",
    "# tmp_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "LoxMi1gQ3ODS",
   "metadata": {
    "id": "LoxMi1gQ3ODS"
   },
   "outputs": [],
   "source": [
    "# # Test your function\n",
    "# w2_unittest.test_data_generator(data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D-M0U9GDwt0r",
   "metadata": {
    "id": "D-M0U9GDwt0r"
   },
   "source": [
    "Now that you have your generator, you can just call them and they will return tensors which correspond to your lines in Shakespeare. The first column and the second column are identical. Now you can go ahead and start building your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gFcB-i-rDd68",
   "metadata": {
    "id": "gFcB-i-rDd68"
   },
   "source": [
    "<a name='1-4'></a>\n",
    "### 1.4 - Repeating Batch Generator\n",
    "\n",
    "The way the iterator is currently defined, it will keep providing batches forever.\n",
    "\n",
    "Although it is not needed, we want to show you the `itertools.cycle` function which is really useful when the generator eventually stops\n",
    "\n",
    "Notice that it is expected to use this function within the training function further below\n",
    "\n",
    "Usually we want to cycle over the dataset multiple times during training (i.e. train for multiple *epochs*).\n",
    "\n",
    "For small datasets we can use [`itertools.cycle`](https://docs.python.org/3.8/library/itertools.html#itertools.cycle) to achieve this easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "v589leeZETy7",
   "metadata": {
    "id": "v589leeZETy7"
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "\n",
    "# infinite_data_generator = itertools.cycle(\n",
    "#     data_generator(batch_size=2, max_length=10, data_lines=tmp_lines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RWvsSxDUFB0p",
   "metadata": {
    "id": "RWvsSxDUFB0p"
   },
   "source": [
    "You can see that we can get more than the 5 lines in tmp_lines using this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0lJhBPgJFAxb",
   "metadata": {
    "id": "0lJhBPgJFAxb"
   },
   "outputs": [],
   "source": [
    "# ten_lines = [next(infinite_data_generator) for _ in range(10)]\n",
    "# print(len(ten_lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c36cbe60-d340-456a-8978-6f9d8290f397",
   "metadata": {
    "collapsed": true,
    "id": "c36cbe60-d340-456a-8978-6f9d8290f397",
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ten_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KmZRBoaMwt0w",
   "metadata": {
    "id": "KmZRBoaMwt0w"
   },
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Defining the GRU Model\n",
    "\n",
    "Now that you have the input and output tensors, you will go ahead and initialize your model. You will be implementing the `GRULM`, gated recurrent unit model. To implement this model, you will be using google's `pytorch`. You can use the following techniques and tools when constructing the model:\n",
    "\n",
    "\n",
    "- `Embedding`: Initializes the embedding. In this case it is the size of the vocabulary by the dimension of the model.\n",
    "    - `Embedding(vocab_size, d_feature)`.\n",
    "    - `vocab_size` is the number of unique words in the given vocabulary.\n",
    "    - `d_feature` is the number of elements in the word embedding (some choices for a word embedding size range from 150 to 300, for example).\n",
    "___\n",
    "\n",
    "- `GRU`: GRU layer.\n",
    "    - `GRU(n_units)` Builds a traditional GRU of n_cells with dense internal transformations.\n",
    "    - `GRU` paper: https://arxiv.org/abs/1412.3555\n",
    "___\n",
    "\n",
    "- `Dense`: A dense layer.\n",
    "    - `Dense(n_units)`: The parameter `n_units` is the number of units chosen for this dense layer.\n",
    "\n",
    "**Instructions:** Implement the `GRULM` class below. You should be using all the methods explained above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "uVylY2qjfJJY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVylY2qjfJJY",
    "outputId": "88e548d8-ef85-49c7-cfb8-70f90a81997b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3834.03125"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor_list)/32\n",
    "# ~ 3500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "RH8UOQbm0ovs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RH8UOQbm0ovs",
    "outputId": "763ed37d-85cf-4fd0-87ff-f954054a5d74"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Parameters\n",
    "vocab_size         = 256  # Size of the vocabulary\n",
    "emb_size           = 512  # Dimensionality of embedding vectors\n",
    "hidden_size        = 512  # Number of features in the GRU hidden state\n",
    "num_layers         = 2    # Number of GRU layers\n",
    "linear_output_size = 256  # Number of output features for the linear layer\n",
    "sequence_length    = 64   # Length of the sequences\n",
    "batch_size         = 32   # Batch size\n",
    "\n",
    "# Define the neural network\n",
    "class GRULM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRULM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, linear_output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        gru_output, hidden = self.gru(x, hidden)\n",
    "\n",
    "        linear_output = self.linear(gru_output)\n",
    "\n",
    "        log_softmax_output = F.log_softmax(linear_output, dim=-1)\n",
    "        return log_softmax_output, hidden\n",
    "\n",
    "# Instantiate the network and move it to the device\n",
    "model = GRULM().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea052af4-baef-458c-8663-2750eddec469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Define the generator\n",
    "# def shifted_inputs_and_NOT_shifted_targets_generator(shifted_inputs_, targets_, batch_size_):\n",
    "#     counter = 0\n",
    "#     second_counter = batch_size_\n",
    "#     while True:\n",
    "#         batch_of_shifted_inputs_ = shifted_inputs_[counter:second_counter].to(device)\n",
    "#         batch_of_targets_ = targets_[counter:second_counter].to(device)\n",
    "#         yield batch_of_shifted_inputs_, batch_of_targets_\n",
    "#         counter += batch_size_\n",
    "#         second_counter += batch_size_\n",
    "#         if second_counter >= shifted_inputs_.shape[0]:\n",
    "#             counter = 0\n",
    "#             second_counter = batch_size_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02136c52-c002-4834-b7ac-a37adf9b09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "inputs         = tensor_matrix.copy()\n",
    "shifted_inputs = tensor_matrix.copy()\n",
    "targets        = tensor_matrix.copy()\n",
    "\n",
    "shifted_inputs = np.roll(shifted_inputs, 1)\n",
    "\n",
    "inputs         = torch.from_numpy(inputs).long().to(device)\n",
    "shifted_inputs = torch.from_numpy(shifted_inputs).long().to(device)\n",
    "targets        = torch.from_numpy(targets).long().to(device)\n",
    "\n",
    "# Initialize the hidden state\n",
    "hidden_state = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1418a3f-7939-4140-9c8d-6efe5ca0a6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  10\n",
      "loss:  2.766151254827326\n",
      "\n",
      "i:  20\n",
      "loss:  2.350588736079988\n",
      "\n",
      "i:  30\n",
      "loss:  2.166026588409178\n",
      "\n",
      "i:  40\n",
      "loss:  2.028937802082155\n",
      "\n",
      "i:  50\n",
      "loss:  1.9379488954357071\n",
      "\n",
      "i:  60\n",
      "loss:  1.8714234457641352\n",
      "\n",
      "i:  70\n",
      "loss:  1.8208710777927453\n",
      "\n",
      "i:  80\n",
      "loss:  1.773002313978878\n",
      "\n",
      "i:  90\n",
      "loss:  1.7325746410495633\n",
      "\n",
      "i:  100\n",
      "loss:  1.6923185339068423\n",
      "\n",
      "i:  110\n",
      "loss:  1.661053245132034\n",
      "\n",
      "i:  120\n",
      "loss:  1.628834010155733\n",
      "\n",
      "i:  130\n",
      "loss:  1.6027340843477322\n",
      "\n",
      "i:  140\n",
      "loss:  1.5726939947047132\n",
      "\n",
      "i:  150\n",
      "loss:  1.549672634396332\n",
      "\n",
      "i:  160\n",
      "loss:  1.5341296906797042\n",
      "\n",
      "i:  170\n",
      "loss:  1.5164401837956836\n",
      "\n",
      "i:  180\n",
      "loss:  1.49820435771626\n",
      "\n",
      "i:  190\n",
      "loss:  1.4802117129270944\n",
      "\n",
      "i:  200\n",
      "loss:  1.4691077900763174\n",
      "\n",
      "i:  210\n",
      "loss:  1.4616154000092456\n",
      "\n",
      "i:  220\n",
      "loss:  1.4540658247956324\n",
      "\n",
      "i:  230\n",
      "loss:  1.4457016752395795\n",
      "\n",
      "i:  240\n",
      "loss:  1.435878803373867\n",
      "\n",
      "i:  250\n",
      "loss:  1.4241608293407941\n",
      "\n",
      "i:  260\n",
      "loss:  1.4117574751148736\n",
      "\n",
      "i:  270\n",
      "loss:  1.3978148657017528\n",
      "\n",
      "i:  280\n",
      "loss:  1.3863523538850804\n",
      "\n",
      "i:  290\n",
      "loss:  1.3801749154054832\n",
      "\n",
      "i:  300\n",
      "loss:  1.3718551023061885\n",
      "\n",
      "i:  310\n",
      "loss:  1.361997342186342\n",
      "\n",
      "i:  320\n",
      "loss:  1.3523431034102988\n",
      "\n",
      "i:  330\n",
      "loss:  1.342993713757783\n",
      "\n",
      "i:  340\n",
      "loss:  1.3348492289568321\n",
      "\n",
      "i:  350\n",
      "loss:  1.3276751729158254\n",
      "\n",
      "i:  360\n",
      "loss:  1.3216827363188577\n",
      "\n",
      "i:  370\n",
      "loss:  1.3146778308156366\n",
      "\n",
      "i:  380\n",
      "loss:  1.3070695584840348\n",
      "\n",
      "i:  390\n",
      "loss:  1.3002394821942616\n",
      "\n",
      "i:  400\n",
      "loss:  1.2940973319912195\n",
      "\n",
      "i:  410\n",
      "loss:  1.2878501017888386\n",
      "\n",
      "i:  420\n",
      "loss:  1.2818636509131933\n",
      "\n",
      "i:  430\n",
      "loss:  1.276556865383467\n",
      "\n",
      "i:  440\n",
      "loss:  1.2702249495350584\n",
      "\n",
      "i:  450\n",
      "loss:  1.2634544712212556\n",
      "\n",
      "i:  460\n",
      "loss:  1.2572761171551952\n",
      "\n",
      "i:  470\n",
      "loss:  1.2514464145253419\n",
      "\n",
      "i:  480\n",
      "loss:  1.245563671147749\n",
      "\n",
      "i:  490\n",
      "loss:  1.241136748897568\n",
      "\n",
      "i:  500\n",
      "loss:  1.2352756790058341\n",
      "\n",
      "i:  510\n",
      "loss:  1.2327773032123095\n",
      "\n",
      "i:  520\n",
      "loss:  1.2308470315072908\n",
      "\n",
      "i:  530\n",
      "loss:  1.2274783951863506\n",
      "\n",
      "i:  540\n",
      "loss:  1.2241857861635204\n",
      "\n",
      "i:  550\n",
      "loss:  1.2198016229212392\n",
      "\n",
      "i:  560\n",
      "loss:  1.2165904821771565\n",
      "\n",
      "i:  570\n",
      "loss:  1.2129653358208945\n",
      "\n",
      "i:  580\n",
      "loss:  1.2099918794919209\n",
      "\n",
      "i:  590\n",
      "loss:  1.2089345981626947\n",
      "\n",
      "i:  600\n",
      "loss:  1.2065565009878796\n",
      "\n",
      "i:  610\n",
      "loss:  1.2034279068050915\n",
      "\n",
      "i:  620\n",
      "loss:  1.2010377755871526\n",
      "\n",
      "i:  630\n",
      "loss:  1.1982118661165615\n",
      "\n",
      "i:  640\n",
      "loss:  1.1950059742339874\n",
      "\n",
      "i:  650\n",
      "loss:  1.192028841023804\n",
      "\n",
      "i:  660\n",
      "loss:  1.1895838112044803\n",
      "\n",
      "i:  670\n",
      "loss:  1.1885262946258182\n",
      "\n",
      "i:  680\n",
      "loss:  1.1871197421470228\n",
      "\n",
      "i:  690\n",
      "loss:  1.1859133257362156\n",
      "\n",
      "i:  700\n",
      "loss:  1.1833506899961561\n",
      "\n",
      "i:  710\n",
      "loss:  1.1815207270294972\n",
      "\n",
      "i:  720\n",
      "loss:  1.1789848158825782\n",
      "\n",
      "i:  730\n",
      "loss:  1.1770140465078862\n",
      "\n",
      "i:  740\n",
      "loss:  1.1744374906324986\n",
      "\n",
      "i:  750\n",
      "loss:  1.1722115308403493\n",
      "\n",
      "i:  760\n",
      "loss:  1.1709938457384999\n",
      "\n",
      "i:  770\n",
      "loss:  1.1696066703313983\n",
      "\n",
      "i:  780\n",
      "loss:  1.1680893527866174\n",
      "\n",
      "i:  790\n",
      "loss:  1.166612283092383\n",
      "\n",
      "i:  800\n",
      "loss:  1.1641419212172244\n",
      "\n",
      "i:  810\n",
      "loss:  1.1618871778506974\n",
      "\n",
      "i:  820\n",
      "loss:  1.1593308938841873\n",
      "\n",
      "i:  830\n",
      "loss:  1.1570046564875671\n",
      "\n",
      "i:  840\n",
      "loss:  1.1546055311680408\n",
      "\n",
      "i:  850\n",
      "loss:  1.1542518713919732\n",
      "\n",
      "i:  860\n",
      "loss:  1.1535480331876136\n",
      "\n",
      "i:  870\n",
      "loss:  1.1523422704224746\n",
      "\n",
      "i:  880\n",
      "loss:  1.1506317163163227\n",
      "\n",
      "i:  890\n",
      "loss:  1.1487269597556589\n",
      "\n",
      "i:  900\n",
      "loss:  1.1470710471785162\n",
      "\n",
      "i:  910\n",
      "loss:  1.144810101857693\n",
      "\n",
      "i:  920\n",
      "loss:  1.1435232201305974\n",
      "\n",
      "i:  930\n",
      "loss:  1.141869634613955\n",
      "\n",
      "i:  940\n",
      "loss:  1.1403296097052085\n",
      "\n",
      "i:  950\n",
      "loss:  1.1382474112711243\n",
      "\n",
      "i:  960\n",
      "loss:  1.1362094183246005\n",
      "\n",
      "i:  970\n",
      "loss:  1.1334496723021832\n",
      "\n",
      "i:  980\n",
      "loss:  1.132313918994472\n",
      "\n",
      "i:  990\n",
      "loss:  1.130272548867523\n",
      "\n",
      "i:  1000\n",
      "loss:  1.1280835183350357\n",
      "\n",
      "i:  1010\n",
      "loss:  1.1258488780902707\n",
      "\n",
      "i:  1020\n",
      "loss:  1.1237626111355632\n",
      "\n",
      "i:  1030\n",
      "loss:  1.1220797189338825\n",
      "\n",
      "i:  1040\n",
      "loss:  1.12053299826229\n",
      "\n",
      "i:  1050\n",
      "loss:  1.1181247571782766\n",
      "\n",
      "i:  1060\n",
      "loss:  1.116288950485963\n",
      "\n",
      "i:  1070\n",
      "loss:  1.1161766966629207\n",
      "\n",
      "i:  1080\n",
      "loss:  1.1156027652840168\n",
      "\n",
      "i:  1090\n",
      "loss:  1.1149161500629212\n",
      "\n",
      "i:  1100\n",
      "loss:  1.1143409353727431\n",
      "\n",
      "i:  1110\n",
      "loss:  1.113670501378503\n",
      "\n",
      "i:  1120\n",
      "loss:  1.1128537311392315\n",
      "\n",
      "i:  1130\n",
      "loss:  1.1119684162232646\n",
      "\n",
      "i:  1140\n",
      "loss:  1.1109760945351055\n",
      "\n",
      "i:  1150\n",
      "loss:  1.1096089780071732\n",
      "\n",
      "i:  1160\n",
      "loss:  1.1083387809514382\n",
      "\n",
      "i:  1170\n",
      "loss:  1.1086670437702046\n",
      "\n",
      "i:  1180\n",
      "loss:  1.108583872899678\n",
      "\n",
      "i:  1190\n",
      "loss:  1.1084080180333102\n",
      "\n",
      "i:  1200\n",
      "loss:  1.108135230287128\n",
      "\n",
      "i:  1210\n",
      "loss:  1.1078355798142494\n",
      "\n",
      "i:  1220\n",
      "loss:  1.107167690528601\n",
      "\n",
      "i:  1230\n",
      "loss:  1.1062544308766227\n",
      "\n",
      "i:  1240\n",
      "loss:  1.105195109158346\n",
      "\n",
      "i:  1250\n",
      "loss:  1.1034812391709556\n",
      "\n",
      "i:  1260\n",
      "loss:  1.1018277267252614\n",
      "\n",
      "i:  1270\n",
      "loss:  1.1004844563012983\n",
      "\n",
      "i:  1280\n",
      "loss:  1.0987354996705037\n",
      "\n",
      "i:  1290\n",
      "loss:  1.0970757129485988\n",
      "\n",
      "i:  1300\n",
      "loss:  1.09584838930778\n",
      "\n",
      "i:  1310\n",
      "loss:  1.0944713713739047\n",
      "\n",
      "i:  1320\n",
      "loss:  1.0926252437034942\n",
      "\n",
      "i:  1330\n",
      "loss:  1.091683393085388\n",
      "\n",
      "i:  1340\n",
      "loss:  1.0906211612030785\n",
      "\n",
      "i:  1350\n",
      "loss:  1.0896931273420152\n",
      "\n",
      "i:  1360\n",
      "loss:  1.0886076808326126\n",
      "\n",
      "i:  1370\n",
      "loss:  1.0876494848667315\n",
      "\n",
      "i:  1380\n",
      "loss:  1.0868852067304469\n",
      "\n",
      "i:  1390\n",
      "loss:  1.0860422490570376\n",
      "\n",
      "i:  1400\n",
      "loss:  1.085163170018424\n",
      "\n",
      "i:  1410\n",
      "loss:  1.0848639976209482\n",
      "\n",
      "i:  1420\n",
      "loss:  1.084011027546184\n",
      "\n",
      "i:  1430\n",
      "loss:  1.0833026578091476\n",
      "\n",
      "i:  1440\n",
      "loss:  1.0821652883129926\n",
      "\n",
      "i:  1450\n",
      "loss:  1.081339618734127\n",
      "\n",
      "i:  1460\n",
      "loss:  1.0806641897300104\n",
      "\n",
      "i:  1470\n",
      "loss:  1.0792857957972222\n",
      "\n",
      "i:  1480\n",
      "loss:  1.0779959363844007\n",
      "\n",
      "i:  1490\n",
      "loss:  1.0773121132936996\n",
      "\n",
      "i:  1500\n",
      "loss:  1.0762723764525026\n",
      "\n",
      "i:  1510\n",
      "loss:  1.0749659935107378\n",
      "\n",
      "i:  1520\n",
      "loss:  1.0736798678943\n",
      "\n",
      "i:  1530\n",
      "loss:  1.0721717559380286\n",
      "\n",
      "i:  1540\n",
      "loss:  1.071623621359806\n",
      "\n",
      "i:  1550\n",
      "loss:  1.0713366200507342\n",
      "\n",
      "i:  1560\n",
      "loss:  1.0706942012339047\n",
      "\n",
      "i:  1570\n",
      "loss:  1.0700807308862348\n",
      "\n",
      "i:  1580\n",
      "loss:  1.069422257089826\n",
      "\n",
      "i:  1590\n",
      "loss:  1.0684685125656654\n",
      "\n",
      "i:  1600\n",
      "loss:  1.0675176225328058\n",
      "\n",
      "i:  1610\n",
      "loss:  1.0667387400259518\n",
      "\n",
      "i:  1620\n",
      "loss:  1.0657031450427512\n",
      "\n",
      "i:  1630\n",
      "loss:  1.0656020985944807\n",
      "\n",
      "i:  1640\n",
      "loss:  1.0648311469556353\n",
      "\n",
      "i:  1650\n",
      "loss:  1.0638276446883712\n",
      "\n",
      "i:  1660\n",
      "loss:  1.063354107107763\n",
      "\n",
      "i:  1670\n",
      "loss:  1.0628085433545047\n",
      "\n",
      "i:  1680\n",
      "loss:  1.0621962521772594\n",
      "\n",
      "i:  1690\n",
      "loss:  1.0613005813376428\n",
      "\n",
      "i:  1700\n",
      "loss:  1.060360450593252\n",
      "\n",
      "i:  1710\n",
      "loss:  1.0597555407092698\n",
      "\n",
      "i:  1720\n",
      "loss:  1.059407601101602\n",
      "\n",
      "i:  1730\n",
      "loss:  1.0582318087315574\n",
      "\n",
      "i:  1740\n",
      "loss:  1.0569098767092144\n",
      "\n",
      "i:  1750\n",
      "loss:  1.055779770501745\n",
      "\n",
      "i:  1760\n",
      "loss:  1.054546324012633\n",
      "\n",
      "i:  1770\n",
      "loss:  1.0535920625147612\n",
      "\n",
      "i:  1780\n",
      "loss:  1.0531901504670818\n",
      "\n",
      "i:  1790\n",
      "loss:  1.0531874114344866\n",
      "\n",
      "i:  1800\n",
      "loss:  1.0530070257742892\n",
      "\n",
      "i:  1810\n",
      "loss:  1.052675393982397\n",
      "\n",
      "i:  1820\n",
      "loss:  1.0519012603898548\n",
      "\n",
      "i:  1830\n",
      "loss:  1.0515043279110312\n",
      "\n",
      "i:  1840\n",
      "loss:  1.0510166971531982\n",
      "\n",
      "i:  1850\n",
      "loss:  1.0499749043901052\n",
      "\n",
      "i:  1860\n",
      "loss:  1.0491052878473088\n",
      "\n",
      "i:  1870\n",
      "loss:  1.0483091916393177\n",
      "\n",
      "i:  1880\n",
      "loss:  1.047496430548121\n",
      "\n",
      "i:  1890\n",
      "loss:  1.0464020046779303\n",
      "\n",
      "i:  1900\n",
      "loss:  1.0463797135894892\n",
      "\n",
      "i:  1910\n",
      "loss:  1.0455639402882582\n",
      "\n",
      "i:  1920\n",
      "loss:  1.0447054214926823\n",
      "\n",
      "i:  1930\n",
      "loss:  1.0449345589363161\n",
      "\n",
      "i:  1940\n",
      "loss:  1.044784423126995\n",
      "\n",
      "i:  1950\n",
      "loss:  1.0449474818397337\n",
      "\n",
      "i:  1960\n",
      "loss:  1.0446174207358625\n",
      "\n",
      "i:  1970\n",
      "loss:  1.0442131579315401\n",
      "\n",
      "i:  1980\n",
      "loss:  1.043598985262798\n",
      "\n",
      "i:  1990\n",
      "loss:  1.0429976412484778\n",
      "\n",
      "i:  2000\n",
      "loss:  1.0424827302413724\n",
      "\n",
      "i:  2010\n",
      "loss:  1.0420283920014455\n",
      "\n",
      "i:  2020\n",
      "loss:  1.041199625777113\n",
      "\n",
      "i:  2030\n",
      "loss:  1.0407900164011135\n",
      "\n",
      "i:  2040\n",
      "loss:  1.0404719257401462\n",
      "\n",
      "i:  2050\n",
      "loss:  1.039990150829689\n",
      "\n",
      "i:  2060\n",
      "loss:  1.0392962760395474\n",
      "\n",
      "i:  2070\n",
      "loss:  1.0386413611230616\n",
      "\n",
      "i:  2080\n",
      "loss:  1.0375187382395596\n",
      "\n",
      "i:  2090\n",
      "loss:  1.0366740405474024\n",
      "\n",
      "i:  2100\n",
      "loss:  1.0363928589124103\n",
      "\n",
      "i:  2110\n",
      "loss:  1.035975289903846\n",
      "\n",
      "i:  2120\n",
      "loss:  1.0347894577134729\n",
      "\n",
      "i:  2130\n",
      "loss:  1.0344216193128002\n",
      "\n",
      "i:  2140\n",
      "loss:  1.033961280714068\n",
      "\n",
      "i:  2150\n",
      "loss:  1.0332808471568404\n",
      "\n",
      "i:  2160\n",
      "loss:  1.0323723285962785\n",
      "\n",
      "i:  2170\n",
      "loss:  1.0316491072653406\n",
      "\n",
      "i:  2180\n",
      "loss:  1.0308987807101582\n",
      "\n",
      "i:  2190\n",
      "loss:  1.0299677053633916\n",
      "\n",
      "i:  2200\n",
      "loss:  1.0289154153203812\n",
      "\n",
      "i:  2210\n",
      "loss:  1.027575979589715\n",
      "\n",
      "i:  2220\n",
      "loss:  1.0271741671639485\n",
      "\n",
      "i:  2230\n",
      "loss:  1.0265391711320966\n",
      "\n",
      "i:  2240\n",
      "loss:  1.0257349230252648\n",
      "\n",
      "i:  2250\n",
      "loss:  1.024616406870545\n",
      "\n",
      "i:  2260\n",
      "loss:  1.0237336351195567\n",
      "\n",
      "i:  2270\n",
      "loss:  1.022742400291154\n",
      "\n",
      "i:  2280\n",
      "loss:  1.0217942156482296\n",
      "\n",
      "i:  2290\n",
      "loss:  1.021040303693594\n",
      "\n",
      "i:  2300\n",
      "loss:  1.0197474712757688\n",
      "\n",
      "i:  2310\n",
      "loss:  1.0187580551434678\n",
      "\n",
      "i:  2320\n",
      "loss:  1.0177544958115856\n",
      "\n",
      "i:  2330\n",
      "loss:  1.0168904848540612\n",
      "\n",
      "i:  2340\n",
      "loss:  1.016485255556909\n",
      "\n",
      "i:  2350\n",
      "loss:  1.0159350535505531\n",
      "\n",
      "i:  2360\n",
      "loss:  1.015648479887814\n",
      "\n",
      "i:  2370\n",
      "loss:  1.015328437479575\n",
      "\n",
      "i:  2380\n",
      "loss:  1.0147159519139481\n",
      "\n",
      "i:  2390\n",
      "loss:  1.0138946079599562\n",
      "\n",
      "i:  2400\n",
      "loss:  1.013293183852811\n",
      "\n",
      "i:  2410\n",
      "loss:  1.012492515570096\n",
      "\n",
      "i:  2420\n",
      "loss:  1.0116332917112991\n",
      "\n",
      "i:  2430\n",
      "loss:  1.0107907291206004\n",
      "\n",
      "i:  2440\n",
      "loss:  1.0100625502384377\n",
      "\n",
      "i:  2450\n",
      "loss:  1.0091912249116108\n",
      "\n",
      "i:  2460\n",
      "loss:  1.008816595873858\n",
      "\n",
      "i:  2470\n",
      "loss:  1.008476535857134\n",
      "\n",
      "i:  2480\n",
      "loss:  1.0077693668501553\n",
      "\n",
      "i:  2490\n",
      "loss:  1.007397783276356\n",
      "\n",
      "i:  2500\n",
      "loss:  1.006709655348371\n",
      "\n",
      "i:  2510\n",
      "loss:  1.0059934367415726\n",
      "\n",
      "i:  2520\n",
      "loss:  1.0051789510491254\n",
      "\n",
      "i:  2530\n",
      "loss:  1.004340160462942\n",
      "\n",
      "i:  2540\n",
      "loss:  1.0035759595518552\n",
      "\n",
      "i:  2550\n",
      "loss:  1.0028785922302073\n",
      "\n",
      "i:  2560\n",
      "loss:  1.002045795420379\n",
      "\n",
      "i:  2570\n",
      "loss:  1.0015673141959853\n",
      "\n",
      "i:  2580\n",
      "loss:  1.000891438130028\n",
      "\n",
      "i:  2590\n",
      "loss:  1.0001316136694562\n",
      "\n",
      "i:  2600\n",
      "loss:  0.9996768527767008\n",
      "\n",
      "i:  2610\n",
      "loss:  0.9991651077760859\n",
      "\n",
      "i:  2620\n",
      "loss:  0.998642996186657\n",
      "\n",
      "i:  2630\n",
      "loss:  0.9979080741893017\n",
      "\n",
      "i:  2640\n",
      "loss:  0.9977716704585795\n",
      "\n",
      "i:  2650\n",
      "loss:  0.9974725512525623\n",
      "\n",
      "i:  2660\n",
      "loss:  0.9971302208238327\n",
      "\n",
      "i:  2670\n",
      "loss:  0.9965594818265373\n",
      "\n",
      "i:  2680\n",
      "loss:  0.9964959834970142\n",
      "\n",
      "i:  2690\n",
      "loss:  0.9964503702267711\n",
      "\n",
      "i:  2700\n",
      "loss:  0.9960181668637992\n",
      "\n",
      "i:  2710\n",
      "loss:  0.9958351259410095\n",
      "\n",
      "i:  2720\n",
      "loss:  0.9956744754086606\n",
      "\n",
      "i:  2730\n",
      "loss:  0.9954511393277647\n",
      "\n",
      "i:  2740\n",
      "loss:  0.995069828891528\n",
      "\n",
      "i:  2750\n",
      "loss:  0.9945394227891261\n",
      "\n",
      "i:  2760\n",
      "loss:  0.9942462970082719\n",
      "\n",
      "i:  2770\n",
      "loss:  0.9944562260337101\n",
      "\n",
      "i:  2780\n",
      "loss:  0.9943663483577339\n",
      "\n",
      "i:  2790\n",
      "loss:  0.994018676940022\n",
      "\n",
      "i:  2800\n",
      "loss:  0.9937078361530808\n",
      "\n",
      "i:  2810\n",
      "loss:  0.9933429182805611\n",
      "\n",
      "i:  2820\n",
      "loss:  0.9929649940685615\n",
      "\n",
      "i:  2830\n",
      "loss:  0.9926896970396706\n",
      "\n",
      "i:  2840\n",
      "loss:  0.9923337639133429\n",
      "\n",
      "i:  2850\n",
      "loss:  0.9920459800605312\n",
      "\n",
      "i:  2860\n",
      "loss:  0.9918477928896794\n",
      "\n",
      "i:  2870\n",
      "loss:  0.9918603514989716\n",
      "\n",
      "i:  2880\n",
      "loss:  0.9915691735905022\n",
      "\n",
      "i:  2890\n",
      "loss:  0.9913967509597117\n",
      "\n",
      "i:  2900\n",
      "loss:  0.9909210947927464\n",
      "\n",
      "i:  2910\n",
      "loss:  0.990385593918745\n",
      "\n",
      "i:  2920\n",
      "loss:  0.9900084445326347\n",
      "\n",
      "i:  2930\n",
      "loss:  0.9898874087672883\n",
      "\n",
      "i:  2940\n",
      "loss:  0.9895177466433213\n",
      "\n",
      "i:  2950\n",
      "loss:  0.9889904237508531\n",
      "\n",
      "i:  2960\n",
      "loss:  0.9887016659671091\n",
      "\n",
      "i:  2970\n",
      "loss:  0.9884217862668\n",
      "\n",
      "i:  2980\n",
      "loss:  0.9881928775963148\n",
      "\n",
      "i:  2990\n",
      "loss:  0.9880682581425988\n",
      "\n",
      "i:  3000\n",
      "loss:  0.9877844438458315\n",
      "\n",
      "i:  3010\n",
      "loss:  0.9876043600463582\n",
      "\n",
      "i:  3020\n",
      "loss:  0.9873407896150622\n",
      "\n",
      "i:  3030\n",
      "loss:  0.9870269769235477\n",
      "\n",
      "i:  3040\n",
      "loss:  0.9866760745424066\n",
      "\n",
      "i:  3050\n",
      "loss:  0.9868756979166661\n",
      "\n",
      "i:  3060\n",
      "loss:  0.9866586350822169\n",
      "\n",
      "i:  3070\n",
      "loss:  0.9866870503031986\n",
      "\n",
      "i:  3080\n",
      "loss:  0.9866258024840493\n",
      "\n",
      "i:  3090\n",
      "loss:  0.9866775240820228\n",
      "\n",
      "i:  3100\n",
      "loss:  0.9865549082469264\n",
      "\n",
      "i:  3110\n",
      "loss:  0.9865220723543777\n",
      "\n",
      "i:  3120\n",
      "loss:  0.9863252946005843\n",
      "\n",
      "i:  3130\n",
      "loss:  0.985944331520398\n",
      "\n",
      "i:  3140\n",
      "loss:  0.9855557131998784\n",
      "\n",
      "i:  3150\n",
      "loss:  0.9851712359110161\n",
      "\n",
      "i:  3160\n",
      "loss:  0.985036700172011\n",
      "\n",
      "i:  3170\n",
      "loss:  0.9849534708876145\n",
      "\n",
      "i:  3180\n",
      "loss:  0.9848007892839041\n",
      "\n",
      "i:  3190\n",
      "loss:  0.9855382543807865\n",
      "\n",
      "i:  3200\n",
      "loss:  0.9855945686350313\n",
      "\n",
      "i:  3210\n",
      "loss:  0.9855557373196713\n",
      "\n",
      "i:  3220\n",
      "loss:  0.9854400351768471\n",
      "\n",
      "i:  3230\n",
      "loss:  0.9852990846134346\n",
      "\n",
      "i:  3240\n",
      "loss:  0.9852215087237236\n",
      "\n",
      "i:  3250\n",
      "loss:  0.9854357924526634\n",
      "\n",
      "i:  3260\n",
      "loss:  0.9851483920442294\n",
      "\n",
      "i:  3270\n",
      "loss:  0.9850270304520244\n",
      "\n",
      "i:  3280\n",
      "loss:  0.9846563922654052\n",
      "\n",
      "i:  3290\n",
      "loss:  0.9842236035049813\n",
      "\n",
      "i:  3300\n",
      "loss:  0.9838694295840565\n",
      "\n",
      "i:  3310\n",
      "loss:  0.9835340597862853\n",
      "\n",
      "i:  3320\n",
      "loss:  0.983384564110616\n",
      "\n",
      "i:  3330\n",
      "loss:  0.9830004605524749\n",
      "\n",
      "i:  3340\n",
      "loss:  0.9824933753028596\n",
      "\n",
      "i:  3350\n",
      "loss:  0.9823345551114409\n",
      "\n",
      "i:  3360\n",
      "loss:  0.9817603301147164\n",
      "\n",
      "i:  3370\n",
      "loss:  0.9812087415322746\n",
      "\n",
      "i:  3380\n",
      "loss:  0.9811601915485723\n",
      "\n",
      "i:  3390\n",
      "loss:  0.9807140226474521\n",
      "\n",
      "i:  3400\n",
      "loss:  0.9806375710605278\n",
      "\n",
      "i:  3410\n",
      "loss:  0.980360556761913\n",
      "\n",
      "i:  3420\n",
      "loss:  0.9800001184813497\n",
      "\n",
      "i:  3430\n",
      "loss:  0.9797188259098767\n",
      "\n",
      "i:  3440\n",
      "loss:  0.97946172331662\n",
      "\n",
      "i:  3450\n",
      "loss:  0.9790685081250493\n",
      "\n",
      "i:  3460\n",
      "loss:  0.9785497259780253\n",
      "\n",
      "i:  3470\n",
      "loss:  0.9783393187280417\n",
      "\n",
      "i:  3480\n",
      "loss:  0.9781912676444241\n",
      "\n",
      "i:  3490\n",
      "loss:  0.9781263505394907\n",
      "\n",
      "i:  3500\n",
      "loss:  0.977881637386716\n",
      "\n",
      "i:  3510\n",
      "loss:  0.9776588947523085\n",
      "\n",
      "i:  3520\n",
      "loss:  0.9774053463862045\n",
      "\n",
      "i:  3530\n",
      "loss:  0.9769984469117338\n",
      "\n",
      "i:  3540\n",
      "loss:  0.9766616436409028\n",
      "\n",
      "i:  3550\n",
      "loss:  0.976309390470566\n",
      "\n",
      "i:  3560\n",
      "loss:  0.9760763519049963\n",
      "\n",
      "i:  3570\n",
      "loss:  0.9757599211797364\n",
      "\n",
      "i:  3580\n",
      "loss:  0.9753760691046615\n",
      "\n",
      "i:  3590\n",
      "loss:  0.9750231577887969\n",
      "\n",
      "i:  3600\n",
      "loss:  0.9747629208768019\n",
      "\n",
      "i:  3610\n",
      "loss:  0.9746418731244308\n",
      "\n",
      "i:  3620\n",
      "loss:  0.9744615696619572\n",
      "\n",
      "i:  3630\n",
      "loss:  0.9742755709568419\n",
      "\n",
      "i:  3640\n",
      "loss:  0.9740984840515517\n",
      "\n",
      "i:  3650\n",
      "loss:  0.9739445468247083\n",
      "\n",
      "i:  3660\n",
      "loss:  0.973657872573628\n",
      "\n",
      "i:  3670\n",
      "loss:  0.9732934672561012\n",
      "\n",
      "i:  3680\n",
      "loss:  0.9730249916250633\n",
      "\n",
      "i:  3690\n",
      "loss:  0.9728251160063158\n",
      "\n",
      "i:  3700\n",
      "loss:  0.9725644075606392\n",
      "\n",
      "i:  3710\n",
      "loss:  0.9723611073059009\n",
      "\n",
      "i:  3720\n",
      "loss:  0.9722767285251771\n",
      "\n",
      "i:  3730\n",
      "loss:  0.971891912761242\n",
      "\n",
      "i:  3740\n",
      "loss:  0.9715807416467098\n",
      "\n",
      "i:  3750\n",
      "loss:  0.9713613341265251\n",
      "\n",
      "i:  3760\n",
      "loss:  0.9711802887951431\n",
      "\n",
      "i:  3770\n",
      "loss:  0.97071621033754\n",
      "\n",
      "i:  3780\n",
      "loss:  0.9703833098939347\n",
      "\n",
      "i:  3790\n",
      "loss:  0.9704882968654421\n",
      "\n",
      "i:  3800\n",
      "loss:  0.9705061512741721\n",
      "\n",
      "i:  3810\n",
      "loss:  0.9702153619788382\n",
      "\n",
      "i:  3820\n",
      "loss:  0.9700694328685358\n",
      "\n",
      "i:  3830\n",
      "loss:  0.9698781397955065\n",
      "\n",
      "i:  3840\n",
      "loss:  0.9698194095831432\n",
      "\n",
      "i:  3850\n",
      "loss:  0.9698489674637145\n",
      "\n",
      "i:  3860\n",
      "loss:  0.9698329530627392\n",
      "\n",
      "i:  3870\n",
      "loss:  0.9698022738179937\n",
      "\n",
      "i:  3880\n",
      "loss:  0.9695088884797302\n",
      "\n",
      "i:  3890\n",
      "loss:  0.9694842694581428\n",
      "\n",
      "i:  3900\n",
      "loss:  0.9693057071747031\n",
      "\n",
      "i:  3910\n",
      "loss:  0.969153835984698\n",
      "\n",
      "i:  3920\n",
      "loss:  0.9689399724604372\n",
      "\n",
      "i:  3930\n",
      "loss:  0.968583754253157\n",
      "\n",
      "i:  3940\n",
      "loss:  0.9683810886665819\n",
      "\n",
      "i:  3950\n",
      "loss:  0.9680819074599479\n",
      "\n",
      "i:  3960\n",
      "loss:  0.9679348392412537\n",
      "\n",
      "i:  3970\n",
      "loss:  0.9677668766586944\n",
      "\n",
      "i:  3980\n",
      "loss:  0.9674435100777609\n",
      "\n",
      "i:  3990\n",
      "loss:  0.9673287639624492\n",
      "\n",
      "i:  4000\n",
      "loss:  0.9670935910110383\n",
      "\n",
      "i:  4010\n",
      "loss:  0.9669370755787295\n",
      "\n",
      "i:  4020\n",
      "loss:  0.9667471496583335\n",
      "\n",
      "i:  4030\n",
      "loss:  0.966537005883297\n",
      "\n",
      "i:  4040\n",
      "loss:  0.9667872800608137\n",
      "\n",
      "i:  4050\n",
      "loss:  0.9669355398944736\n",
      "\n",
      "i:  4060\n",
      "loss:  0.9670109164168816\n",
      "\n",
      "i:  4070\n",
      "loss:  0.9669648730485453\n",
      "\n",
      "i:  4080\n",
      "loss:  0.9668833579292078\n",
      "\n",
      "i:  4090\n",
      "loss:  0.9666165494228219\n",
      "\n",
      "i:  4100\n",
      "loss:  0.9661912981241804\n",
      "\n",
      "i:  4110\n",
      "loss:  0.9658806156616262\n",
      "\n",
      "i:  4120\n",
      "loss:  0.9657298714768623\n",
      "\n",
      "i:  4130\n",
      "loss:  0.9656600980933542\n",
      "\n",
      "i:  4140\n",
      "loss:  0.9655837699558619\n",
      "\n",
      "i:  4150\n",
      "loss:  0.9652376868399732\n",
      "\n",
      "i:  4160\n",
      "loss:  0.9650190487572047\n",
      "\n",
      "i:  4170\n",
      "loss:  0.9648251267923951\n",
      "\n",
      "i:  4180\n",
      "loss:  0.9645523079429281\n",
      "\n",
      "i:  4190\n",
      "loss:  0.9645120989548167\n",
      "\n",
      "i:  4200\n",
      "loss:  0.9643329777438934\n",
      "\n",
      "i:  4210\n",
      "loss:  0.9641783209643662\n",
      "\n",
      "i:  4220\n",
      "loss:  0.9639342574182491\n",
      "\n",
      "i:  4230\n",
      "loss:  0.9637725391629682\n",
      "\n",
      "i:  4240\n",
      "loss:  0.9636369769976854\n",
      "\n",
      "i:  4250\n",
      "loss:  0.9634032682359036\n",
      "\n",
      "i:  4260\n",
      "loss:  0.9631724795512374\n",
      "\n",
      "i:  4270\n",
      "loss:  0.9629063404253958\n",
      "\n",
      "i:  4280\n",
      "loss:  0.9625465675328719\n",
      "\n",
      "i:  4290\n",
      "loss:  0.9622263130858849\n",
      "\n",
      "i:  4300\n",
      "loss:  0.9618304511317817\n",
      "\n",
      "i:  4310\n",
      "loss:  0.9614946727920258\n",
      "\n",
      "i:  4320\n",
      "loss:  0.9612546237261035\n",
      "\n",
      "i:  4330\n",
      "loss:  0.9609405643957588\n",
      "\n",
      "i:  4340\n",
      "loss:  0.9607371414581001\n",
      "\n",
      "i:  4350\n",
      "loss:  0.9607956850084868\n",
      "\n",
      "i:  4360\n",
      "loss:  0.9606165631911919\n",
      "\n",
      "i:  4370\n",
      "loss:  0.9605588415576675\n",
      "\n",
      "i:  4380\n",
      "loss:  0.9604144530858495\n",
      "\n",
      "i:  4390\n",
      "loss:  0.9601249804979466\n",
      "\n",
      "i:  4400\n",
      "loss:  0.9600750420600602\n",
      "\n",
      "i:  4410\n",
      "loss:  0.9597025678706964\n",
      "\n",
      "i:  4420\n",
      "loss:  0.9597958290814221\n",
      "\n",
      "i:  4430\n",
      "loss:  0.9596706401128797\n",
      "\n",
      "i:  4440\n",
      "loss:  0.9594790538711286\n",
      "\n",
      "i:  4450\n",
      "loss:  0.9593746861603201\n",
      "\n",
      "i:  4460\n",
      "loss:  0.9591980632832969\n",
      "\n",
      "i:  4470\n",
      "loss:  0.9590110644494839\n",
      "\n",
      "i:  4480\n",
      "loss:  0.9587842864041561\n",
      "\n",
      "i:  4490\n",
      "loss:  0.9584927801710543\n",
      "\n",
      "i:  4500\n",
      "loss:  0.9584959397459528\n",
      "\n",
      "i:  4510\n",
      "loss:  0.9584277658379545\n",
      "\n",
      "i:  4520\n",
      "loss:  0.9583762814199152\n",
      "\n",
      "i:  4530\n",
      "loss:  0.9582613694683602\n",
      "\n",
      "i:  4540\n",
      "loss:  0.9581576159506531\n",
      "\n",
      "i:  4550\n",
      "loss:  0.9579380608749662\n",
      "\n",
      "i:  4560\n",
      "loss:  0.9578351100804225\n",
      "\n",
      "i:  4570\n",
      "loss:  0.9576599751213034\n",
      "\n",
      "i:  4580\n",
      "loss:  0.9574139414266113\n",
      "\n",
      "i:  4590\n",
      "loss:  0.9572893820136649\n",
      "\n",
      "i:  4600\n",
      "loss:  0.9572097002112641\n",
      "\n",
      "i:  4610\n",
      "loss:  0.9571777908113303\n",
      "\n",
      "i:  4620\n",
      "loss:  0.9570897892101377\n",
      "\n",
      "i:  4630\n",
      "loss:  0.9568425713296432\n",
      "\n",
      "i:  4640\n",
      "loss:  0.9566595316305676\n",
      "\n",
      "i:  4650\n",
      "loss:  0.9564418245953556\n",
      "\n",
      "i:  4660\n",
      "loss:  0.9561867344803985\n",
      "\n",
      "i:  4670\n",
      "loss:  0.9559351865866536\n",
      "\n",
      "i:  4680\n",
      "loss:  0.9558993955436259\n",
      "\n",
      "i:  4690\n",
      "loss:  0.955937231693713\n",
      "\n",
      "i:  4700\n",
      "loss:  0.9559170802497681\n",
      "\n",
      "i:  4710\n",
      "loss:  0.9558580276933706\n",
      "\n",
      "i:  4720\n",
      "loss:  0.9556984952876841\n",
      "\n",
      "i:  4730\n",
      "loss:  0.9555290494514957\n",
      "\n",
      "i:  4740\n",
      "loss:  0.9552896596527481\n",
      "\n",
      "i:  4750\n",
      "loss:  0.9551206772401694\n",
      "\n",
      "i:  4760\n",
      "loss:  0.9550613730713942\n",
      "\n",
      "i:  4770\n",
      "loss:  0.9547661134305178\n",
      "\n",
      "i:  4780\n",
      "loss:  0.9546684148458227\n",
      "\n",
      "i:  4790\n",
      "loss:  0.9544340642614271\n",
      "\n",
      "i:  4800\n",
      "loss:  0.9541404569640654\n",
      "\n",
      "i:  4810\n",
      "loss:  0.9539502714718981\n",
      "\n",
      "i:  4820\n",
      "loss:  0.9538322946598015\n",
      "\n",
      "i:  4830\n",
      "loss:  0.9535658236209761\n",
      "\n",
      "i:  4840\n",
      "loss:  0.953241416594628\n",
      "\n",
      "i:  4850\n",
      "loss:  0.953046554580125\n",
      "\n",
      "i:  4860\n",
      "loss:  0.952817593618225\n",
      "\n",
      "i:  4870\n",
      "loss:  0.9526509189417268\n",
      "\n",
      "i:  4880\n",
      "loss:  0.9523421032302718\n",
      "\n",
      "i:  4890\n",
      "loss:  0.9519638540712609\n",
      "\n",
      "i:  4900\n",
      "loss:  0.9520224615022421\n",
      "\n",
      "i:  4910\n",
      "loss:  0.9520473083406474\n",
      "\n",
      "i:  4920\n",
      "loss:  0.9520140341919289\n",
      "\n",
      "i:  4930\n",
      "loss:  0.9521041412825905\n",
      "\n",
      "i:  4940\n",
      "loss:  0.952009719185587\n",
      "\n",
      "i:  4950\n",
      "loss:  0.9520198272962903\n",
      "\n",
      "i:  4960\n",
      "loss:  0.9518686099666137\n",
      "\n",
      "i:  4970\n",
      "loss:  0.9517788583604989\n",
      "\n",
      "i:  4980\n",
      "loss:  0.9516772586127596\n",
      "\n",
      "i:  4990\n",
      "loss:  0.9514588732455255\n",
      "\n",
      "i:  5000\n",
      "loss:  0.9515976332719506\n",
      "\n",
      "i:  5010\n",
      "loss:  0.9517275419177659\n",
      "\n",
      "i:  5020\n",
      "loss:  0.9518429949579902\n",
      "\n",
      "i:  5030\n",
      "loss:  0.9519258040162494\n",
      "\n",
      "i:  5040\n",
      "loss:  0.952007707191398\n",
      "\n",
      "i:  5050\n",
      "loss:  0.9520408920582345\n",
      "\n",
      "i:  5060\n",
      "loss:  0.9519322642140463\n",
      "\n",
      "i:  5070\n",
      "loss:  0.951803557156012\n",
      "\n",
      "i:  5080\n",
      "loss:  0.9515578213802732\n",
      "\n",
      "i:  5090\n",
      "loss:  0.9512996157560665\n",
      "\n",
      "i:  5100\n",
      "loss:  0.9510627073754144\n",
      "\n",
      "i:  5110\n",
      "loss:  0.9508420067147438\n",
      "\n",
      "i:  5120\n",
      "loss:  0.950527088172127\n",
      "\n",
      "i:  5130\n",
      "loss:  0.9503319525818591\n",
      "\n",
      "i:  5140\n",
      "loss:  0.9501598034763448\n",
      "\n",
      "i:  5150\n",
      "loss:  0.9498239109190291\n",
      "\n",
      "i:  5160\n",
      "loss:  0.9496689198310928\n",
      "\n",
      "i:  5170\n",
      "loss:  0.949411601830995\n",
      "\n",
      "i:  5180\n",
      "loss:  0.949288589093612\n",
      "\n",
      "i:  5190\n",
      "loss:  0.9491148697999235\n",
      "\n",
      "i:  5200\n",
      "loss:  0.9489498746220916\n",
      "\n",
      "i:  5210\n",
      "loss:  0.9488418707633014\n",
      "\n",
      "i:  5220\n",
      "loss:  0.9487321428916071\n",
      "\n",
      "i:  5230\n",
      "loss:  0.948643666127516\n",
      "\n",
      "i:  5240\n",
      "loss:  0.9485987156965059\n",
      "\n",
      "i:  5250\n",
      "loss:  0.9484721532357895\n",
      "\n",
      "i:  5260\n",
      "loss:  0.9484683352999985\n",
      "\n",
      "i:  5270\n",
      "loss:  0.9483180665139839\n",
      "\n",
      "i:  5280\n",
      "loss:  0.9480771742079706\n",
      "\n",
      "i:  5290\n",
      "loss:  0.947959661748499\n",
      "\n",
      "i:  5300\n",
      "loss:  0.9477500101740103\n",
      "\n",
      "i:  5310\n",
      "loss:  0.9475200196608516\n",
      "\n",
      "i:  5320\n",
      "loss:  0.9473778767158743\n",
      "\n",
      "i:  5330\n",
      "loss:  0.9473184218518038\n",
      "\n",
      "i:  5340\n",
      "loss:  0.9470928574664118\n",
      "\n",
      "i:  5350\n",
      "loss:  0.9468150060937864\n",
      "\n",
      "i:  5360\n",
      "loss:  0.9465618944116947\n",
      "\n",
      "i:  5370\n",
      "loss:  0.9463155766846059\n",
      "\n",
      "i:  5380\n",
      "loss:  0.9463183822418717\n",
      "\n",
      "i:  5390\n",
      "loss:  0.9462768326075881\n",
      "\n",
      "i:  5400\n",
      "loss:  0.9461717652548377\n",
      "\n",
      "i:  5410\n",
      "loss:  0.946031733766278\n",
      "\n",
      "i:  5420\n",
      "loss:  0.9459327059826976\n",
      "\n",
      "i:  5430\n",
      "loss:  0.9457593490473365\n",
      "\n",
      "i:  5440\n",
      "loss:  0.9456388643779993\n",
      "\n",
      "i:  5450\n",
      "loss:  0.9454379067784426\n",
      "\n",
      "i:  5460\n",
      "loss:  0.9453711827264952\n",
      "\n",
      "i:  5470\n",
      "loss:  0.9452634955744621\n",
      "\n",
      "i:  5480\n",
      "loss:  0.9451273177590516\n",
      "\n",
      "i:  5490\n",
      "loss:  0.9450076773689432\n",
      "\n",
      "i:  5500\n",
      "loss:  0.9448830457009786\n",
      "\n",
      "i:  5510\n",
      "loss:  0.9448850214740928\n",
      "\n",
      "i:  5520\n",
      "loss:  0.944802569357344\n",
      "\n",
      "i:  5530\n",
      "loss:  0.9445906439077097\n",
      "\n",
      "i:  5540\n",
      "loss:  0.9444491591474636\n",
      "\n",
      "i:  5550\n",
      "loss:  0.9443756951134262\n",
      "\n",
      "i:  5560\n",
      "loss:  0.9441642477033894\n",
      "\n",
      "i:  5570\n",
      "loss:  0.9439323794165584\n",
      "\n",
      "i:  5580\n",
      "loss:  0.9436252176804347\n",
      "\n",
      "i:  5590\n",
      "loss:  0.9432850971170326\n",
      "\n",
      "i:  5600\n",
      "loss:  0.9431287655285949\n",
      "\n",
      "i:  5610\n",
      "loss:  0.9429560326580227\n",
      "\n",
      "i:  5620\n",
      "loss:  0.9429053750682441\n",
      "\n",
      "i:  5630\n",
      "loss:  0.9429970110284142\n",
      "\n",
      "i:  5640\n",
      "loss:  0.9429599022246109\n",
      "\n",
      "i:  5650\n",
      "loss:  0.9428710740312098\n",
      "\n",
      "i:  5660\n",
      "loss:  0.9427187272262455\n",
      "\n",
      "i:  5670\n",
      "loss:  0.9426831360311866\n",
      "\n",
      "i:  5680\n",
      "loss:  0.9425444525483418\n",
      "\n",
      "i:  5690\n",
      "loss:  0.9422906379491494\n",
      "\n",
      "i:  5700\n",
      "loss:  0.9421773922221741\n",
      "\n",
      "i:  5710\n",
      "loss:  0.9419398896175682\n",
      "\n",
      "i:  5720\n",
      "loss:  0.9416833076260761\n",
      "\n",
      "i:  5730\n",
      "loss:  0.9416224870137199\n",
      "\n",
      "i:  5740\n",
      "loss:  0.9414544495955263\n",
      "\n",
      "i:  5750\n",
      "loss:  0.9413081441593468\n",
      "\n",
      "i:  5760\n",
      "loss:  0.94126099965221\n",
      "\n",
      "i:  5770\n",
      "loss:  0.9414403563179108\n",
      "\n",
      "i:  5780\n",
      "loss:  0.9414439525876032\n",
      "\n",
      "i:  5790\n",
      "loss:  0.9415123341069529\n",
      "\n",
      "i:  5800\n",
      "loss:  0.9414734987786383\n",
      "\n",
      "i:  5810\n",
      "loss:  0.9413144239468904\n",
      "\n",
      "i:  5820\n",
      "loss:  0.9411552669389247\n",
      "\n",
      "i:  5830\n",
      "loss:  0.9411398422971554\n",
      "\n",
      "i:  5840\n",
      "loss:  0.9409852956147905\n",
      "\n",
      "i:  5850\n",
      "loss:  0.940796298886788\n",
      "\n",
      "i:  5860\n",
      "loss:  0.9405930222423181\n",
      "\n",
      "i:  5870\n",
      "loss:  0.9406713656287973\n",
      "\n",
      "i:  5880\n",
      "loss:  0.9405631675513053\n",
      "\n",
      "i:  5890\n",
      "loss:  0.9404329781549691\n",
      "\n",
      "i:  5900\n",
      "loss:  0.940246278457653\n",
      "\n",
      "i:  5910\n",
      "loss:  0.9400093489856087\n",
      "\n",
      "i:  5920\n",
      "loss:  0.9397699847160572\n",
      "\n",
      "i:  5930\n",
      "loss:  0.9396450238020017\n",
      "\n",
      "i:  5940\n",
      "loss:  0.9395635035769985\n",
      "\n",
      "i:  5950\n",
      "loss:  0.9394006387733889\n",
      "\n",
      "i:  5960\n",
      "loss:  0.9391645092758991\n",
      "\n",
      "i:  5970\n",
      "loss:  0.9391032051419198\n",
      "\n",
      "i:  5980\n",
      "loss:  0.938921327889713\n",
      "\n",
      "i:  5990\n",
      "loss:  0.9386933270180848\n",
      "\n",
      "i:  6000\n",
      "loss:  0.9384768547673679\n",
      "\n",
      "i:  6010\n",
      "loss:  0.9382923761207002\n",
      "\n",
      "i:  6020\n",
      "loss:  0.9380493835097352\n",
      "\n",
      "i:  6030\n",
      "loss:  0.9377328011600596\n",
      "\n",
      "i:  6040\n",
      "loss:  0.9374424599738848\n",
      "\n",
      "i:  6050\n",
      "loss:  0.9371806014285484\n",
      "\n",
      "i:  6060\n",
      "loss:  0.9370417740012215\n",
      "\n",
      "i:  6070\n",
      "loss:  0.9367834085678666\n",
      "\n",
      "i:  6080\n",
      "loss:  0.9365087220580969\n",
      "\n",
      "i:  6090\n",
      "loss:  0.9361990173204332\n",
      "\n",
      "i:  6100\n",
      "loss:  0.9358918341461351\n",
      "\n",
      "i:  6110\n",
      "loss:  0.935651521692688\n",
      "\n",
      "i:  6120\n",
      "loss:  0.935390376811946\n",
      "\n",
      "i:  6130\n",
      "loss:  0.9350726738088458\n",
      "\n",
      "i:  6140\n",
      "loss:  0.9347192498948865\n",
      "\n",
      "i:  6150\n",
      "loss:  0.9344441072521433\n",
      "\n",
      "i:  6160\n",
      "loss:  0.9341704918906356\n",
      "\n",
      "i:  6170\n",
      "loss:  0.9339500348806729\n",
      "\n",
      "i:  6180\n",
      "loss:  0.9338080700721348\n",
      "\n",
      "i:  6190\n",
      "loss:  0.9337088168245047\n",
      "\n",
      "i:  6200\n",
      "loss:  0.9336331369097897\n",
      "\n",
      "i:  6210\n",
      "loss:  0.9334909209564407\n",
      "\n",
      "i:  6220\n",
      "loss:  0.9333239686228496\n",
      "\n",
      "i:  6230\n",
      "loss:  0.9331084918993049\n",
      "\n",
      "i:  6240\n",
      "loss:  0.9328929932859344\n",
      "\n",
      "i:  6250\n",
      "loss:  0.9326563772869537\n",
      "\n",
      "i:  6260\n",
      "loss:  0.9323374215234413\n",
      "\n",
      "i:  6270\n",
      "loss:  0.932175078544676\n",
      "\n",
      "i:  6280\n",
      "loss:  0.9318400583313142\n",
      "\n",
      "i:  6290\n",
      "loss:  0.9316283688268948\n",
      "\n",
      "i:  6300\n",
      "loss:  0.9315522172028745\n",
      "\n",
      "i:  6310\n",
      "loss:  0.9314277195180583\n",
      "\n",
      "i:  6320\n",
      "loss:  0.931278419167421\n",
      "\n",
      "i:  6330\n",
      "loss:  0.9311080302103419\n",
      "\n",
      "i:  6340\n",
      "loss:  0.9309133334624957\n",
      "\n",
      "i:  6350\n",
      "loss:  0.9306955088303608\n",
      "\n",
      "i:  6360\n",
      "loss:  0.930399243462631\n",
      "\n",
      "i:  6370\n",
      "loss:  0.9301444403353563\n",
      "\n",
      "i:  6380\n",
      "loss:  0.9298934975521932\n",
      "\n",
      "i:  6390\n",
      "loss:  0.9296151878659927\n",
      "\n",
      "i:  6400\n",
      "loss:  0.929430558199697\n",
      "\n",
      "i:  6410\n",
      "loss:  0.9292673046076434\n",
      "\n",
      "i:  6420\n",
      "loss:  0.9289802557080543\n",
      "\n",
      "i:  6430\n",
      "loss:  0.9288236566862261\n",
      "\n",
      "i:  6440\n",
      "loss:  0.9286194643865477\n",
      "\n",
      "i:  6450\n",
      "loss:  0.928490688414227\n",
      "\n",
      "i:  6460\n",
      "loss:  0.9282419452484945\n",
      "\n",
      "i:  6470\n",
      "loss:  0.928151373903012\n",
      "\n",
      "i:  6480\n",
      "loss:  0.9281159895306255\n",
      "\n",
      "i:  6490\n",
      "loss:  0.928048790263351\n",
      "\n",
      "i:  6500\n",
      "loss:  0.9278505455162173\n",
      "\n",
      "i:  6510\n",
      "loss:  0.9277816370891694\n",
      "\n",
      "i:  6520\n",
      "loss:  0.9277723439722189\n",
      "\n",
      "i:  6530\n",
      "loss:  0.9277209535690604\n",
      "\n",
      "i:  6540\n",
      "loss:  0.9276265684680971\n",
      "\n",
      "i:  6550\n",
      "loss:  0.9276232123829867\n",
      "\n",
      "i:  6560\n",
      "loss:  0.9275789774512576\n",
      "\n",
      "i:  6570\n",
      "loss:  0.9274341088418202\n",
      "\n",
      "i:  6580\n",
      "loss:  0.9272848691481657\n",
      "\n",
      "i:  6590\n",
      "loss:  0.9271081537799578\n",
      "\n",
      "i:  6600\n",
      "loss:  0.9271451137207111\n",
      "\n",
      "i:  6610\n",
      "loss:  0.9271830020757256\n",
      "\n",
      "i:  6620\n",
      "loss:  0.9271219444318114\n",
      "\n",
      "i:  6630\n",
      "loss:  0.9269794791806537\n",
      "\n",
      "i:  6640\n",
      "loss:  0.9268360137221433\n",
      "\n",
      "i:  6650\n",
      "loss:  0.9267218426517428\n",
      "\n",
      "i:  6660\n",
      "loss:  0.9266108019522693\n",
      "\n",
      "i:  6670\n",
      "loss:  0.9265445509587354\n",
      "\n",
      "i:  6680\n",
      "loss:  0.9263892164042637\n",
      "\n",
      "i:  6690\n",
      "loss:  0.9262358043479235\n",
      "\n",
      "i:  6700\n",
      "loss:  0.926308704087884\n",
      "\n",
      "i:  6710\n",
      "loss:  0.9262628160775676\n",
      "\n",
      "i:  6720\n",
      "loss:  0.9262443157803922\n",
      "\n",
      "i:  6730\n",
      "loss:  0.9261573250678757\n",
      "\n",
      "i:  6740\n",
      "loss:  0.9259442588445111\n",
      "\n",
      "i:  6750\n",
      "loss:  0.9257880198462877\n",
      "\n",
      "i:  6760\n",
      "loss:  0.9257153113677188\n",
      "\n",
      "i:  6770\n",
      "loss:  0.925694560990554\n",
      "\n",
      "i:  6780\n",
      "loss:  0.9255243232777259\n",
      "\n",
      "i:  6790\n",
      "loss:  0.9253122406317619\n",
      "\n",
      "i:  6800\n",
      "loss:  0.9252852250102548\n",
      "\n",
      "i:  6810\n",
      "loss:  0.9252089751202566\n",
      "\n",
      "i:  6820\n",
      "loss:  0.925164006127236\n",
      "\n",
      "i:  6830\n",
      "loss:  0.9251073448083146\n",
      "\n",
      "i:  6840\n",
      "loss:  0.9250537505572938\n",
      "\n",
      "i:  6850\n",
      "loss:  0.9249876246732824\n",
      "\n",
      "i:  6860\n",
      "loss:  0.9248998923719389\n",
      "\n",
      "i:  6870\n",
      "loss:  0.9247447473741552\n",
      "\n",
      "i:  6880\n",
      "loss:  0.9247080263764407\n",
      "\n",
      "i:  6890\n",
      "loss:  0.9247608004037051\n",
      "\n",
      "i:  6900\n",
      "loss:  0.9247489078220051\n",
      "\n",
      "i:  6910\n",
      "loss:  0.9247289245802386\n",
      "\n",
      "i:  6920\n",
      "loss:  0.9248358448914857\n",
      "\n",
      "i:  6930\n",
      "loss:  0.9248214806335311\n",
      "\n",
      "i:  6940\n",
      "loss:  0.9248001442108764\n",
      "\n",
      "i:  6950\n",
      "loss:  0.9247613166874389\n",
      "\n",
      "i:  6960\n",
      "loss:  0.9246523650859454\n",
      "\n",
      "i:  6970\n",
      "loss:  0.9245009113719312\n",
      "\n",
      "i:  6980\n",
      "loss:  0.9243183685329237\n",
      "\n",
      "i:  6990\n",
      "loss:  0.9243136383555781\n",
      "\n",
      "i:  7000\n",
      "loss:  0.9242978189999913\n",
      "\n",
      "i:  7010\n",
      "loss:  0.9242620676343578\n",
      "\n",
      "i:  7020\n",
      "loss:  0.9243096037988157\n",
      "\n",
      "i:  7030\n",
      "loss:  0.9245688786989525\n",
      "\n",
      "i:  7040\n",
      "loss:  0.9245910931676478\n",
      "\n",
      "i:  7050\n",
      "loss:  0.9245954531758344\n",
      "\n",
      "i:  7060\n",
      "loss:  0.9246202662298049\n",
      "\n",
      "i:  7070\n",
      "loss:  0.924549505862669\n",
      "\n",
      "i:  7080\n",
      "loss:  0.9246732845950844\n",
      "\n",
      "i:  7090\n",
      "loss:  0.9246416968210613\n",
      "\n",
      "i:  7100\n",
      "loss:  0.9245786607273866\n",
      "\n",
      "i:  7110\n",
      "loss:  0.9244863000990318\n",
      "\n",
      "i:  7120\n",
      "loss:  0.924320447387998\n",
      "\n",
      "i:  7130\n",
      "loss:  0.9242161916509583\n",
      "\n",
      "i:  7140\n",
      "loss:  0.9240800602198014\n",
      "\n",
      "i:  7150\n",
      "loss:  0.9240418607880896\n",
      "\n",
      "i:  7160\n",
      "loss:  0.9239476124029422\n",
      "\n",
      "i:  7170\n",
      "loss:  0.9237753387658504\n",
      "\n",
      "i:  7180\n",
      "loss:  0.9236919715068845\n",
      "\n",
      "i:  7190\n",
      "loss:  0.9235279347398917\n",
      "\n",
      "i:  7200\n",
      "loss:  0.9233214673342398\n",
      "\n",
      "i:  7210\n",
      "loss:  0.9232602944124126\n",
      "\n",
      "i:  7220\n",
      "loss:  0.9230923946008444\n",
      "\n",
      "i:  7230\n",
      "loss:  0.9230794677132971\n",
      "\n",
      "i:  7240\n",
      "loss:  0.9229774736284699\n",
      "\n",
      "i:  7250\n",
      "loss:  0.9228461815018338\n",
      "\n",
      "i:  7260\n",
      "loss:  0.9227533903993402\n",
      "\n",
      "i:  7270\n",
      "loss:  0.9226525720778103\n",
      "\n",
      "i:  7280\n",
      "loss:  0.9224889405545519\n",
      "\n",
      "i:  7290\n",
      "loss:  0.9222912397703146\n",
      "\n",
      "i:  7300\n",
      "loss:  0.9221597162113991\n",
      "\n",
      "i:  7310\n",
      "loss:  0.9221309639738712\n",
      "\n",
      "i:  7320\n",
      "loss:  0.922085591905219\n",
      "\n",
      "i:  7330\n",
      "loss:  0.922022487510358\n",
      "\n",
      "i:  7340\n",
      "loss:  0.9219115621841274\n",
      "\n",
      "i:  7350\n",
      "loss:  0.9218463961193634\n",
      "\n",
      "i:  7360\n",
      "loss:  0.9216864732859689\n",
      "\n",
      "i:  7370\n",
      "loss:  0.9215511508703458\n",
      "\n",
      "i:  7380\n",
      "loss:  0.9214231361785308\n",
      "\n",
      "i:  7390\n",
      "loss:  0.921295041564417\n",
      "\n",
      "i:  7400\n",
      "loss:  0.9212077204608672\n",
      "\n",
      "i:  7410\n",
      "loss:  0.9210559071646481\n",
      "\n",
      "i:  7420\n",
      "loss:  0.9209313159553755\n",
      "\n",
      "i:  7430\n",
      "loss:  0.9207773328533309\n",
      "\n",
      "i:  7440\n",
      "loss:  0.9206686292888496\n",
      "\n",
      "i:  7450\n",
      "loss:  0.9206687817396277\n",
      "\n",
      "i:  7460\n",
      "loss:  0.9205610101335794\n",
      "\n",
      "i:  7470\n",
      "loss:  0.9205286309288585\n",
      "\n",
      "i:  7480\n",
      "loss:  0.9204569618231216\n",
      "\n",
      "i:  7490\n",
      "loss:  0.9203702062348501\n",
      "\n",
      "i:  7500\n",
      "loss:  0.9202207251002575\n",
      "\n",
      "i:  7510\n",
      "loss:  0.9201130296034591\n",
      "\n",
      "i:  7520\n",
      "loss:  0.9200249485807237\n",
      "\n",
      "i:  7530\n",
      "loss:  0.9199275312837163\n",
      "\n",
      "i:  7540\n",
      "loss:  0.9198584269977758\n",
      "\n",
      "i:  7550\n",
      "loss:  0.9198236359758671\n",
      "\n",
      "i:  7560\n",
      "loss:  0.9196899004626441\n",
      "\n",
      "i:  7570\n",
      "loss:  0.9195763556366158\n",
      "\n",
      "i:  7580\n",
      "loss:  0.919441108141611\n",
      "\n",
      "i:  7590\n",
      "loss:  0.9193753970735645\n",
      "\n",
      "i:  7600\n",
      "loss:  0.9192484547050199\n",
      "\n",
      "i:  7610\n",
      "loss:  0.9189999825286264\n",
      "\n",
      "i:  7620\n",
      "loss:  0.9190567659668496\n",
      "\n",
      "i:  7630\n",
      "loss:  0.919066532803869\n",
      "\n",
      "i:  7640\n",
      "loss:  0.9189818301230197\n",
      "\n",
      "i:  7650\n",
      "loss:  0.9188907747875708\n",
      "\n",
      "i:  7660\n",
      "loss:  0.9189073501220183\n",
      "\n",
      "i:  7670\n",
      "loss:  0.9188110248592776\n",
      "\n",
      "i:  7680\n",
      "loss:  0.9188688378395504\n",
      "\n",
      "i:  7690\n",
      "loss:  0.9188682918445665\n",
      "\n",
      "i:  7700\n",
      "loss:  0.9188937039177784\n",
      "\n",
      "i:  7710\n",
      "loss:  0.9188205505635639\n",
      "\n",
      "i:  7720\n",
      "loss:  0.9187967490461295\n",
      "\n",
      "i:  7730\n",
      "loss:  0.9187560568511478\n",
      "\n",
      "i:  7740\n",
      "loss:  0.918688339320684\n",
      "\n",
      "i:  7750\n",
      "loss:  0.9186081502179517\n",
      "\n",
      "i:  7760\n",
      "loss:  0.9185047634574743\n",
      "\n",
      "i:  7770\n",
      "loss:  0.9183828151604948\n",
      "\n",
      "i:  7780\n",
      "loss:  0.9182604747418496\n",
      "\n",
      "i:  7790\n",
      "loss:  0.9181667634923962\n",
      "\n",
      "i:  7800\n",
      "loss:  0.9181300792964876\n",
      "\n",
      "i:  7810\n",
      "loss:  0.9179911940446692\n",
      "\n",
      "i:  7820\n",
      "loss:  0.9178821417685131\n",
      "\n",
      "i:  7830\n",
      "loss:  0.917883253435479\n",
      "\n",
      "i:  7840\n",
      "loss:  0.9177932038384423\n",
      "\n",
      "i:  7850\n",
      "loss:  0.9177587621000342\n",
      "\n",
      "i:  7860\n",
      "loss:  0.9176415887790059\n",
      "\n",
      "i:  7870\n",
      "loss:  0.9177364927282662\n",
      "\n",
      "i:  7880\n",
      "loss:  0.9178694506508946\n",
      "\n",
      "i:  7890\n",
      "loss:  0.9179488299026218\n",
      "\n",
      "i:  7900\n",
      "loss:  0.9179818340908529\n",
      "\n",
      "i:  7910\n",
      "loss:  0.9179464361035045\n",
      "\n",
      "i:  7920\n",
      "loss:  0.9178667698916635\n",
      "\n",
      "i:  7930\n",
      "loss:  0.9177233143586887\n",
      "\n",
      "i:  7940\n",
      "loss:  0.9175514363398887\n",
      "\n",
      "i:  7950\n",
      "loss:  0.9174383109192505\n",
      "\n",
      "i:  7960\n",
      "loss:  0.9175104122038478\n",
      "\n",
      "i:  7970\n",
      "loss:  0.9175097463032544\n",
      "\n",
      "i:  7980\n",
      "loss:  0.917358993079904\n",
      "\n",
      "i:  7990\n",
      "loss:  0.9173271603748984\n",
      "\n",
      "i:  8000\n",
      "loss:  0.9171561475858556\n",
      "\n",
      "i:  8010\n",
      "loss:  0.9170927270017393\n",
      "\n",
      "i:  8020\n",
      "loss:  0.9171010401982824\n",
      "\n",
      "i:  8030\n",
      "loss:  0.9170737571800027\n",
      "\n",
      "i:  8040\n",
      "loss:  0.9170250563594242\n",
      "\n",
      "i:  8050\n",
      "loss:  0.9169427225670005\n",
      "\n",
      "i:  8060\n",
      "loss:  0.9168815327746566\n",
      "\n",
      "i:  8070\n",
      "loss:  0.916841264743519\n",
      "\n",
      "i:  8080\n",
      "loss:  0.9167807221324148\n",
      "\n",
      "i:  8090\n",
      "loss:  0.9166684200126918\n",
      "\n",
      "i:  8100\n",
      "loss:  0.9165537313184183\n",
      "\n",
      "i:  8110\n",
      "loss:  0.9164058865402677\n",
      "\n",
      "i:  8120\n",
      "loss:  0.916244941426533\n",
      "\n",
      "i:  8130\n",
      "loss:  0.9160861370601919\n",
      "\n",
      "i:  8140\n",
      "loss:  0.9159544460853419\n",
      "\n",
      "i:  8150\n",
      "loss:  0.915821839777067\n",
      "\n",
      "i:  8160\n",
      "loss:  0.9157220796325776\n",
      "\n",
      "i:  8170\n",
      "loss:  0.9155635913543785\n",
      "\n",
      "i:  8180\n",
      "loss:  0.915565070787133\n",
      "\n",
      "i:  8190\n",
      "loss:  0.9155675529880615\n",
      "\n",
      "i:  8200\n",
      "loss:  0.9155379439356733\n",
      "\n",
      "i:  8210\n",
      "loss:  0.9154967995526773\n",
      "\n",
      "i:  8220\n",
      "loss:  0.915382423825456\n",
      "\n",
      "i:  8230\n",
      "loss:  0.9153097482284326\n",
      "\n",
      "i:  8240\n",
      "loss:  0.9152195322876662\n",
      "\n",
      "i:  8250\n",
      "loss:  0.9151809835936745\n",
      "\n",
      "i:  8260\n",
      "loss:  0.915183704198958\n",
      "\n",
      "i:  8270\n",
      "loss:  0.9151322036466321\n",
      "\n",
      "i:  8280\n",
      "loss:  0.9150758309577949\n",
      "\n",
      "i:  8290\n",
      "loss:  0.9150092896025082\n",
      "\n",
      "i:  8300\n",
      "loss:  0.9149403151094648\n",
      "\n",
      "i:  8310\n",
      "loss:  0.9148168592243013\n",
      "\n",
      "i:  8320\n",
      "loss:  0.9147393081555242\n",
      "\n",
      "i:  8330\n",
      "loss:  0.914662993085898\n",
      "\n",
      "i:  8340\n",
      "loss:  0.9146646642381947\n",
      "\n",
      "i:  8350\n",
      "loss:  0.9146570640971541\n",
      "\n",
      "i:  8360\n",
      "loss:  0.9146234629513786\n",
      "\n",
      "i:  8370\n",
      "loss:  0.9145341417564741\n",
      "\n",
      "i:  8380\n",
      "loss:  0.9145021029025612\n",
      "\n",
      "i:  8390\n",
      "loss:  0.9144277847178317\n",
      "\n",
      "i:  8400\n",
      "loss:  0.9143668644457484\n",
      "\n",
      "i:  8410\n",
      "loss:  0.9142793258664271\n",
      "\n",
      "i:  8420\n",
      "loss:  0.914189697593086\n",
      "\n",
      "i:  8430\n",
      "loss:  0.9141694634725099\n",
      "\n",
      "i:  8440\n",
      "loss:  0.9141537609392398\n",
      "\n",
      "i:  8450\n",
      "loss:  0.9141260657475807\n",
      "\n",
      "i:  8460\n",
      "loss:  0.9140729231482744\n",
      "\n",
      "i:  8470\n",
      "loss:  0.9139702569958508\n",
      "\n",
      "i:  8480\n",
      "loss:  0.913875070225165\n",
      "\n",
      "i:  8490\n",
      "loss:  0.913757314763155\n",
      "\n",
      "i:  8500\n",
      "loss:  0.9136468827086411\n",
      "\n",
      "i:  8510\n",
      "loss:  0.9135623753329951\n",
      "\n",
      "i:  8520\n",
      "loss:  0.9136188019680426\n",
      "\n",
      "i:  8530\n",
      "loss:  0.9136318842001725\n",
      "\n",
      "i:  8540\n",
      "loss:  0.9136443308401605\n",
      "\n",
      "i:  8550\n",
      "loss:  0.913571482443026\n",
      "\n",
      "i:  8560\n",
      "loss:  0.91347858034385\n",
      "\n",
      "i:  8570\n",
      "loss:  0.9134245128562606\n",
      "\n",
      "i:  8580\n",
      "loss:  0.9133469281517783\n",
      "\n",
      "i:  8590\n",
      "loss:  0.9133253589926409\n",
      "\n",
      "i:  8600\n",
      "loss:  0.9132058678248804\n",
      "\n",
      "i:  8610\n",
      "loss:  0.9131440727321158\n",
      "\n",
      "i:  8620\n",
      "loss:  0.9130449671712667\n",
      "\n",
      "i:  8630\n",
      "loss:  0.9129344624296813\n",
      "\n",
      "i:  8640\n",
      "loss:  0.9127969091143573\n",
      "\n",
      "i:  8650\n",
      "loss:  0.9127891597245115\n",
      "\n",
      "i:  8660\n",
      "loss:  0.9126327677833443\n",
      "\n",
      "i:  8670\n",
      "loss:  0.9125202293764993\n",
      "\n",
      "i:  8680\n",
      "loss:  0.9124012222324095\n",
      "\n",
      "i:  8690\n",
      "loss:  0.9122846921696486\n",
      "\n",
      "i:  8700\n",
      "loss:  0.912246180209548\n",
      "\n",
      "i:  8710\n",
      "loss:  0.912149307785564\n",
      "\n",
      "i:  8720\n",
      "loss:  0.911981905426622\n",
      "\n",
      "i:  8730\n",
      "loss:  0.9118693672379136\n",
      "\n",
      "i:  8740\n",
      "loss:  0.9119134917744455\n",
      "\n",
      "i:  8750\n",
      "loss:  0.9119607988166449\n",
      "\n",
      "i:  8760\n",
      "loss:  0.911996121735704\n",
      "\n",
      "i:  8770\n",
      "loss:  0.9119670904731957\n",
      "\n",
      "i:  8780\n",
      "loss:  0.9120155994386556\n",
      "\n",
      "i:  8790\n",
      "loss:  0.9119524276679645\n",
      "\n",
      "i:  8800\n",
      "loss:  0.9119316002189158\n",
      "\n",
      "i:  8810\n",
      "loss:  0.9119065676458225\n",
      "\n",
      "i:  8820\n",
      "loss:  0.9117922974901802\n",
      "\n",
      "i:  8830\n",
      "loss:  0.9118234818207962\n",
      "\n",
      "i:  8840\n",
      "loss:  0.9119268894067462\n",
      "\n",
      "i:  8850\n",
      "loss:  0.9120142161846161\n",
      "\n",
      "i:  8860\n",
      "loss:  0.9120827470773123\n",
      "\n",
      "i:  8870\n",
      "loss:  0.912151289478712\n",
      "\n",
      "i:  8880\n",
      "loss:  0.9122167933048959\n",
      "\n",
      "i:  8890\n",
      "loss:  0.9121829156176524\n",
      "\n",
      "i:  8900\n",
      "loss:  0.9121576817253174\n",
      "\n",
      "i:  8910\n",
      "loss:  0.9120976722724723\n",
      "\n",
      "i:  8920\n",
      "loss:  0.9119620434459637\n",
      "\n",
      "i:  8930\n",
      "loss:  0.9118106292291446\n",
      "\n",
      "i:  8940\n",
      "loss:  0.91172125891556\n",
      "\n",
      "i:  8950\n",
      "loss:  0.9115631062183257\n",
      "\n",
      "i:  8960\n",
      "loss:  0.911471810790926\n",
      "\n",
      "i:  8970\n",
      "loss:  0.9113728901525628\n",
      "\n",
      "i:  8980\n",
      "loss:  0.9112432563594264\n",
      "\n",
      "i:  8990\n",
      "loss:  0.9110912612973219\n",
      "\n",
      "i:  9000\n",
      "loss:  0.9110154461501744\n",
      "\n",
      "i:  9010\n",
      "loss:  0.9109517705154768\n",
      "\n",
      "i:  9020\n",
      "loss:  0.9108763592210951\n",
      "\n",
      "i:  9030\n",
      "loss:  0.9108043734403745\n",
      "\n",
      "i:  9040\n",
      "loss:  0.9107436680243931\n",
      "\n",
      "i:  9050\n",
      "loss:  0.910702464426042\n",
      "\n",
      "i:  9060\n",
      "loss:  0.9106743186366912\n",
      "\n",
      "i:  9070\n",
      "loss:  0.9106267918570278\n",
      "\n",
      "i:  9080\n",
      "loss:  0.9106334202674999\n",
      "\n",
      "i:  9090\n",
      "loss:  0.9105979303016271\n",
      "\n",
      "i:  9100\n",
      "loss:  0.9105462733140006\n",
      "\n",
      "i:  9110\n",
      "loss:  0.9104381704674557\n",
      "\n",
      "i:  9120\n",
      "loss:  0.910373521879072\n",
      "\n",
      "i:  9130\n",
      "loss:  0.9103478147686931\n",
      "\n",
      "i:  9140\n",
      "loss:  0.9101854493673828\n",
      "\n",
      "i:  9150\n",
      "loss:  0.9100808867658113\n",
      "\n",
      "i:  9160\n",
      "loss:  0.9100882826400837\n",
      "\n",
      "i:  9170\n",
      "loss:  0.9099569196315515\n",
      "\n",
      "i:  9180\n",
      "loss:  0.9098751756175257\n",
      "\n",
      "i:  9190\n",
      "loss:  0.9097273538251681\n",
      "\n",
      "i:  9200\n",
      "loss:  0.9095829683708738\n",
      "\n",
      "i:  9210\n",
      "loss:  0.9095888310237941\n",
      "\n",
      "i:  9220\n",
      "loss:  0.9095572773494427\n",
      "\n",
      "i:  9230\n",
      "loss:  0.9095382169316822\n",
      "\n",
      "i:  9240\n",
      "loss:  0.9095036315558057\n",
      "\n",
      "i:  9250\n",
      "loss:  0.909466543087198\n",
      "\n",
      "i:  9260\n",
      "loss:  0.9093877794501617\n",
      "\n",
      "i:  9270\n",
      "loss:  0.9092940595842799\n",
      "\n",
      "i:  9280\n",
      "loss:  0.9092660619355574\n",
      "\n",
      "i:  9290\n",
      "loss:  0.9091474376887503\n",
      "\n",
      "i:  9300\n",
      "loss:  0.9091527768552028\n",
      "\n",
      "i:  9310\n",
      "loss:  0.9090630020552171\n",
      "\n",
      "i:  9320\n",
      "loss:  0.9090050990848042\n",
      "\n",
      "i:  9330\n",
      "loss:  0.9089611544350746\n",
      "\n",
      "i:  9340\n",
      "loss:  0.9089909800273578\n",
      "\n",
      "i:  9350\n",
      "loss:  0.9089405561032722\n",
      "\n",
      "i:  9360\n",
      "loss:  0.9088653023936226\n",
      "\n",
      "i:  9370\n",
      "loss:  0.9087534233627191\n",
      "\n",
      "i:  9380\n",
      "loss:  0.9087467054233738\n",
      "\n",
      "i:  9390\n",
      "loss:  0.908722513054725\n",
      "\n",
      "i:  9400\n",
      "loss:  0.908546545270047\n",
      "\n",
      "i:  9410\n",
      "loss:  0.9083860695438093\n",
      "\n",
      "i:  9420\n",
      "loss:  0.9082389777126288\n",
      "\n",
      "i:  9430\n",
      "loss:  0.9081247865129864\n",
      "\n",
      "i:  9440\n",
      "loss:  0.9079500080234557\n",
      "\n",
      "i:  9450\n",
      "loss:  0.9079945803779658\n",
      "\n",
      "i:  9460\n",
      "loss:  0.9080609601637158\n",
      "\n",
      "i:  9470\n",
      "loss:  0.9080439906332514\n",
      "\n",
      "i:  9480\n",
      "loss:  0.9080453301712048\n",
      "\n",
      "i:  9490\n",
      "loss:  0.907957222652993\n",
      "\n",
      "i:  9500\n",
      "loss:  0.9079560808646856\n",
      "\n",
      "i:  9510\n",
      "loss:  0.9079051500094475\n",
      "\n",
      "i:  9520\n",
      "loss:  0.9077856661034862\n",
      "\n",
      "i:  9530\n",
      "loss:  0.9077049316151447\n",
      "\n",
      "i:  9540\n",
      "loss:  0.9075822720967702\n",
      "\n",
      "i:  9550\n",
      "loss:  0.9075174359280006\n",
      "\n",
      "i:  9560\n",
      "loss:  0.9073914266314644\n",
      "\n",
      "i:  9570\n",
      "loss:  0.9073938011730768\n",
      "\n",
      "i:  9580\n",
      "loss:  0.9073072717148978\n",
      "\n",
      "i:  9590\n",
      "loss:  0.9072075691483911\n",
      "\n",
      "i:  9600\n",
      "loss:  0.9073578476651287\n",
      "\n",
      "i:  9610\n",
      "loss:  0.9073641548176832\n",
      "\n",
      "i:  9620\n",
      "loss:  0.9074255085954199\n",
      "\n",
      "i:  9630\n",
      "loss:  0.9074303610817985\n",
      "\n",
      "i:  9640\n",
      "loss:  0.9074179584889006\n",
      "\n",
      "i:  9650\n",
      "loss:  0.9073332675027546\n",
      "\n",
      "i:  9660\n",
      "loss:  0.9072719535470046\n",
      "\n",
      "i:  9670\n",
      "loss:  0.9072189032600038\n",
      "\n",
      "i:  9680\n",
      "loss:  0.907134374915513\n",
      "\n",
      "i:  9690\n",
      "loss:  0.9070432103371524\n",
      "\n",
      "i:  9700\n",
      "loss:  0.9070207035617722\n",
      "\n",
      "i:  9710\n",
      "loss:  0.9069897164100108\n",
      "\n",
      "i:  9720\n",
      "loss:  0.9069801293280546\n",
      "\n",
      "i:  9730\n",
      "loss:  0.9068763628579058\n",
      "\n",
      "i:  9740\n",
      "loss:  0.906792149729411\n",
      "\n",
      "i:  9750\n",
      "loss:  0.9066451918179042\n",
      "\n",
      "i:  9760\n",
      "loss:  0.9065432859858141\n",
      "\n",
      "i:  9770\n",
      "loss:  0.9065400326542351\n",
      "\n",
      "i:  9780\n",
      "loss:  0.9064950904510051\n",
      "\n",
      "i:  9790\n",
      "loss:  0.9063304379656979\n",
      "\n",
      "i:  9800\n",
      "loss:  0.9063024612917315\n",
      "\n",
      "i:  9810\n",
      "loss:  0.9062087660614181\n",
      "\n",
      "i:  9820\n",
      "loss:  0.9061135837185978\n",
      "\n",
      "i:  9830\n",
      "loss:  0.9059895573712695\n",
      "\n",
      "i:  9840\n",
      "loss:  0.9058797072466644\n",
      "\n",
      "i:  9850\n",
      "loss:  0.9057646624879321\n",
      "\n",
      "i:  9860\n",
      "loss:  0.9056070405351815\n",
      "\n",
      "i:  9870\n",
      "loss:  0.9054444176262363\n",
      "\n",
      "i:  9880\n",
      "loss:  0.9052355541215108\n",
      "\n",
      "i:  9890\n",
      "loss:  0.9051720043722461\n",
      "\n",
      "i:  9900\n",
      "loss:  0.9050681269652867\n",
      "\n",
      "i:  9910\n",
      "loss:  0.9049392093558231\n",
      "\n",
      "i:  9920\n",
      "loss:  0.9047320174475181\n",
      "\n",
      "i:  9930\n",
      "loss:  0.9046172185008253\n",
      "\n",
      "i:  9940\n",
      "loss:  0.9044600261365752\n",
      "\n",
      "i:  9950\n",
      "loss:  0.9043051199587898\n",
      "\n",
      "i:  9960\n",
      "loss:  0.9041715578978565\n",
      "\n",
      "i:  9970\n",
      "loss:  0.9039437832803404\n",
      "\n",
      "i:  9980\n",
      "loss:  0.9037681815052376\n",
      "\n",
      "i:  9990\n",
      "loss:  0.9036025090620164\n",
      "\n",
      "i:  10000\n",
      "loss:  0.903468639457146\n",
      "\n",
      "i:  10010\n",
      "loss:  0.9034017811388584\n",
      "\n",
      "i:  10020\n",
      "loss:  0.9033207100952781\n",
      "\n",
      "i:  10030\n",
      "loss:  0.9032908825447215\n",
      "\n",
      "i:  10040\n",
      "loss:  0.9032546240825623\n",
      "\n",
      "i:  10050\n",
      "loss:  0.9031953630091811\n",
      "\n",
      "i:  10060\n",
      "loss:  0.9030330344188902\n",
      "\n",
      "i:  10070\n",
      "loss:  0.9029507124575493\n",
      "\n",
      "i:  10080\n",
      "loss:  0.9027752958200432\n",
      "\n",
      "i:  10090\n",
      "loss:  0.902619959976472\n",
      "\n",
      "i:  10100\n",
      "loss:  0.9025052412024065\n",
      "\n",
      "i:  10110\n",
      "loss:  0.9023492192169194\n",
      "\n",
      "i:  10120\n",
      "loss:  0.9022158052378075\n",
      "\n",
      "i:  10130\n",
      "loss:  0.9021600104045473\n",
      "\n",
      "i:  10140\n",
      "loss:  0.9021207221530502\n",
      "\n",
      "i:  10150\n",
      "loss:  0.9019892458850651\n",
      "\n",
      "i:  10160\n",
      "loss:  0.9019557681888263\n",
      "\n",
      "i:  10170\n",
      "loss:  0.9018371149937132\n",
      "\n",
      "i:  10180\n",
      "loss:  0.9017120990036818\n",
      "\n",
      "i:  10190\n",
      "loss:  0.9015698778554438\n",
      "\n",
      "i:  10200\n",
      "loss:  0.901404070233074\n",
      "\n",
      "i:  10210\n",
      "loss:  0.9012584621923092\n",
      "\n",
      "i:  10220\n",
      "loss:  0.9011262706721929\n",
      "\n",
      "i:  10230\n",
      "loss:  0.9009959438500569\n",
      "\n",
      "i:  10240\n",
      "loss:  0.9009151888765542\n",
      "\n",
      "i:  10250\n",
      "loss:  0.9007491286603803\n",
      "\n",
      "i:  10260\n",
      "loss:  0.9006253109464124\n",
      "\n",
      "i:  10270\n",
      "loss:  0.9005601112890842\n",
      "\n",
      "i:  10280\n",
      "loss:  0.9004647770479673\n",
      "\n",
      "i:  10290\n",
      "loss:  0.9003608641564447\n",
      "\n",
      "i:  10300\n",
      "loss:  0.9002458521369915\n",
      "\n",
      "i:  10310\n",
      "loss:  0.9002462914219861\n",
      "\n",
      "i:  10320\n",
      "loss:  0.9002204610475354\n",
      "\n",
      "i:  10330\n",
      "loss:  0.9001510048516087\n",
      "\n",
      "i:  10340\n",
      "loss:  0.9000373543138811\n",
      "\n",
      "i:  10350\n",
      "loss:  0.9000612715254336\n",
      "\n",
      "i:  10360\n",
      "loss:  0.9000728131117203\n",
      "\n",
      "i:  10370\n",
      "loss:  0.9000076129407527\n",
      "\n",
      "i:  10380\n",
      "loss:  0.9000095994316789\n",
      "\n",
      "i:  10390\n",
      "loss:  0.899975900129294\n",
      "\n",
      "i:  10400\n",
      "loss:  0.8999290905993852\n",
      "\n",
      "i:  10410\n",
      "loss:  0.8998595769192848\n",
      "\n",
      "i:  10420\n",
      "loss:  0.8997686777659609\n",
      "\n",
      "i:  10430\n",
      "loss:  0.8997296287719521\n",
      "\n",
      "i:  10440\n",
      "loss:  0.8997676079014734\n",
      "\n",
      "i:  10450\n",
      "loss:  0.8997569093777453\n",
      "\n",
      "i:  10460\n",
      "loss:  0.8996683025967492\n",
      "\n",
      "i:  10470\n",
      "loss:  0.8995968819535481\n",
      "\n",
      "i:  10480\n",
      "loss:  0.8995291654696936\n",
      "\n",
      "i:  10490\n",
      "loss:  0.8994530917446876\n",
      "\n",
      "i:  10500\n",
      "loss:  0.8994100869110614\n",
      "\n",
      "i:  10510\n",
      "loss:  0.8993556228507179\n",
      "\n",
      "i:  10520\n",
      "loss:  0.8992826270435079\n",
      "\n",
      "i:  10530\n",
      "loss:  0.8992826917715736\n",
      "\n",
      "i:  10540\n",
      "loss:  0.8992781659370694\n",
      "\n",
      "i:  10550\n",
      "loss:  0.899243946197349\n",
      "\n",
      "i:  10560\n",
      "loss:  0.89924655436352\n",
      "\n",
      "i:  10570\n",
      "loss:  0.8991282787440054\n",
      "\n",
      "i:  10580\n",
      "loss:  0.8990282659612433\n",
      "\n",
      "i:  10590\n",
      "loss:  0.8989643641143331\n",
      "\n",
      "i:  10600\n",
      "loss:  0.8989757759488312\n",
      "\n",
      "i:  10610\n",
      "loss:  0.898885170941685\n",
      "\n",
      "i:  10620\n",
      "loss:  0.8987925434845471\n",
      "\n",
      "i:  10630\n",
      "loss:  0.898745236215918\n",
      "\n",
      "i:  10640\n",
      "loss:  0.8986958473369083\n",
      "\n",
      "i:  10650\n",
      "loss:  0.8986748905962436\n",
      "\n",
      "i:  10660\n",
      "loss:  0.8986542620748106\n",
      "\n",
      "i:  10670\n",
      "loss:  0.898615129016219\n",
      "\n",
      "i:  10680\n",
      "loss:  0.898607601396556\n",
      "\n",
      "i:  10690\n",
      "loss:  0.8985483672233953\n",
      "\n",
      "i:  10700\n",
      "loss:  0.8984754016611936\n",
      "\n",
      "i:  10710\n",
      "loss:  0.8984090334732941\n",
      "\n",
      "i:  10720\n",
      "loss:  0.8984821505476963\n",
      "\n",
      "i:  10730\n",
      "loss:  0.8984295353036527\n",
      "\n",
      "i:  10740\n",
      "loss:  0.8984645834244138\n",
      "\n",
      "i:  10750\n",
      "loss:  0.8984889796601596\n",
      "\n",
      "i:  10760\n",
      "loss:  0.898533904176365\n",
      "\n",
      "i:  10770\n",
      "loss:  0.8985129844958643\n",
      "\n",
      "i:  10780\n",
      "loss:  0.8985146884102844\n",
      "\n",
      "i:  10790\n",
      "loss:  0.898486056969988\n",
      "\n",
      "i:  10800\n",
      "loss:  0.8984024765706484\n",
      "\n",
      "i:  10810\n",
      "loss:  0.898306460671548\n",
      "\n",
      "i:  10820\n",
      "loss:  0.898257686857507\n",
      "\n",
      "i:  10830\n",
      "loss:  0.898262400734888\n",
      "\n",
      "i:  10840\n",
      "loss:  0.8982461455832459\n",
      "\n",
      "i:  10850\n",
      "loss:  0.8982461627485917\n",
      "\n",
      "i:  10860\n",
      "loss:  0.8984403966150608\n",
      "\n",
      "i:  10870\n",
      "loss:  0.8984911970766101\n",
      "\n",
      "i:  10880\n",
      "loss:  0.8984937958967795\n",
      "\n",
      "i:  10890\n",
      "loss:  0.8985185872921766\n",
      "\n",
      "i:  10900\n",
      "loss:  0.8984880653934384\n",
      "\n",
      "i:  10910\n",
      "loss:  0.8985062658885105\n",
      "\n",
      "i:  10920\n",
      "loss:  0.8985582928459522\n",
      "\n",
      "i:  10930\n",
      "loss:  0.8985281653253084\n",
      "\n",
      "i:  10940\n",
      "loss:  0.8985054230882855\n",
      "\n",
      "i:  10950\n",
      "loss:  0.8984271127109102\n",
      "\n",
      "i:  10960\n",
      "loss:  0.898374026961575\n",
      "\n",
      "i:  10970\n",
      "loss:  0.8982781431465464\n",
      "\n",
      "i:  10980\n",
      "loss:  0.8982230193404789\n",
      "\n",
      "i:  10990\n",
      "loss:  0.8982162862058962\n",
      "\n",
      "i:  11000\n",
      "loss:  0.8981358389233082\n",
      "\n",
      "i:  11010\n",
      "loss:  0.8980250563281356\n",
      "\n",
      "i:  11020\n",
      "loss:  0.8980102175599098\n",
      "\n",
      "i:  11030\n",
      "loss:  0.8978680733318786\n",
      "\n",
      "i:  11040\n",
      "loss:  0.8977552211545924\n",
      "\n",
      "i:  11050\n",
      "loss:  0.897765453911272\n",
      "\n",
      "i:  11060\n",
      "loss:  0.897708854829087\n",
      "\n",
      "i:  11070\n",
      "loss:  0.8976855082715842\n",
      "\n",
      "i:  11080\n",
      "loss:  0.8976194890045042\n",
      "\n",
      "i:  11090\n",
      "loss:  0.897545741057656\n",
      "\n",
      "i:  11100\n",
      "loss:  0.897491340532076\n",
      "\n",
      "i:  11110\n",
      "loss:  0.8974121839073601\n",
      "\n",
      "i:  11120\n",
      "loss:  0.8973155506956804\n",
      "\n",
      "i:  11130\n",
      "loss:  0.8971965667153184\n",
      "\n",
      "i:  11140\n",
      "loss:  0.8971457429729772\n",
      "\n",
      "i:  11150\n",
      "loss:  0.8971165930136534\n",
      "\n",
      "i:  11160\n",
      "loss:  0.8971030368603917\n",
      "\n",
      "i:  11170\n",
      "loss:  0.8970512190321631\n",
      "\n",
      "i:  11180\n",
      "loss:  0.8970180876368476\n",
      "\n",
      "i:  11190\n",
      "loss:  0.896930556716042\n",
      "\n",
      "i:  11200\n",
      "loss:  0.8968326115824263\n",
      "\n",
      "i:  11210\n",
      "loss:  0.8967592380817967\n",
      "\n",
      "i:  11220\n",
      "loss:  0.8966606326408537\n",
      "\n",
      "i:  11230\n",
      "loss:  0.8966302413776333\n",
      "\n",
      "i:  11240\n",
      "loss:  0.8965502681575014\n",
      "\n",
      "i:  11250\n",
      "loss:  0.8964588632081183\n",
      "\n",
      "i:  11260\n",
      "loss:  0.8963575950816198\n",
      "\n",
      "i:  11270\n",
      "loss:  0.896312170272055\n",
      "\n",
      "i:  11280\n",
      "loss:  0.896294386764017\n",
      "\n",
      "i:  11290\n",
      "loss:  0.8962723291640307\n",
      "\n",
      "i:  11300\n",
      "loss:  0.8962326437015996\n",
      "\n",
      "i:  11310\n",
      "loss:  0.896191393158689\n",
      "\n",
      "i:  11320\n",
      "loss:  0.8961634042379703\n",
      "\n",
      "i:  11330\n",
      "loss:  0.8960821749847151\n",
      "\n",
      "i:  11340\n",
      "loss:  0.8960046057647082\n",
      "\n",
      "i:  11350\n",
      "loss:  0.8959589902156986\n",
      "\n",
      "i:  11360\n",
      "loss:  0.8958722944699714\n",
      "\n",
      "i:  11370\n",
      "loss:  0.8958370855123803\n",
      "\n",
      "i:  11380\n",
      "loss:  0.8958145809549616\n",
      "\n",
      "i:  11390\n",
      "loss:  0.8957885412329085\n",
      "\n",
      "i:  11400\n",
      "loss:  0.8957133513904958\n",
      "\n",
      "i:  11410\n",
      "loss:  0.895621185091812\n",
      "\n",
      "i:  11420\n",
      "loss:  0.8955869617457775\n",
      "\n",
      "i:  11430\n",
      "loss:  0.895537925941322\n",
      "\n",
      "i:  11440\n",
      "loss:  0.895398900609637\n",
      "\n",
      "i:  11450\n",
      "loss:  0.8953497707687624\n",
      "\n",
      "i:  11460\n",
      "loss:  0.8953930977548296\n",
      "\n",
      "i:  11470\n",
      "loss:  0.89538970367244\n",
      "\n",
      "i:  11480\n",
      "loss:  0.8953262387190263\n",
      "\n",
      "i:  11490\n",
      "loss:  0.8953106549289102\n",
      "\n",
      "i:  11500\n",
      "loss:  0.8952614619865406\n",
      "\n",
      "i:  11510\n",
      "loss:  0.8953088271572323\n",
      "\n",
      "i:  11520\n",
      "loss:  0.8953039786067752\n",
      "\n",
      "i:  11530\n",
      "loss:  0.8953063061273312\n",
      "\n",
      "i:  11540\n",
      "loss:  0.89531085365629\n",
      "\n",
      "i:  11550\n",
      "loss:  0.8952654499546727\n",
      "\n",
      "i:  11560\n",
      "loss:  0.8952672548740961\n",
      "\n",
      "i:  11570\n",
      "loss:  0.8952244744805867\n",
      "\n",
      "i:  11580\n",
      "loss:  0.8951978912013624\n",
      "\n",
      "i:  11590\n",
      "loss:  0.8951317944695135\n",
      "\n",
      "i:  11600\n",
      "loss:  0.8950482454009945\n",
      "\n",
      "i:  11610\n",
      "loss:  0.8950050599214058\n",
      "\n",
      "i:  11620\n",
      "loss:  0.8949117900433593\n",
      "\n",
      "i:  11630\n",
      "loss:  0.8949125581083452\n",
      "\n",
      "i:  11640\n",
      "loss:  0.8948562612019293\n",
      "\n",
      "i:  11650\n",
      "loss:  0.8947676077322657\n",
      "\n",
      "i:  11660\n",
      "loss:  0.8947836096894423\n",
      "\n",
      "i:  11670\n",
      "loss:  0.8947101731056645\n",
      "\n",
      "i:  11680\n",
      "loss:  0.8946936536213886\n",
      "\n",
      "i:  11690\n",
      "loss:  0.8946428106666457\n",
      "\n",
      "i:  11700\n",
      "loss:  0.8946477265457202\n",
      "\n",
      "i:  11710\n",
      "loss:  0.8947486468464271\n",
      "\n",
      "i:  11720\n",
      "loss:  0.8948209730012152\n",
      "\n",
      "i:  11730\n",
      "loss:  0.8948725313214977\n",
      "\n",
      "i:  11740\n",
      "loss:  0.8948581650460988\n",
      "\n",
      "i:  11750\n",
      "loss:  0.8948542680545377\n",
      "\n",
      "i:  11760\n",
      "loss:  0.8947856425048035\n",
      "\n",
      "i:  11770\n",
      "loss:  0.8946608786508612\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m log_softmax_output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_of_shifted_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Reshape the outputs and targets to match\u001b[39;00m\n\u001b[0;32m     30\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m log_softmax_output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[60], line 32\u001b[0m, in \u001b[0;36mGRULM.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 32\u001b[0m     gru_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     linear_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(gru_output)\n\u001b[0;32m     36\u001b[0m     log_softmax_output \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlog_softmax(linear_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch_test\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch_test\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1133\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1137\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the generator\n",
    "training_gen = shifted_inputs_and_NOT_shifted_targets_generator(shifted_inputs_=shifted_inputs, targets_=targets, batch_size_=batch_size)\n",
    "\n",
    "# Number of epochs and steps per epoch\n",
    "num_epochs = 10\n",
    "num_steps_per_epoch = len(tensor_list)/batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Reset hidden state for each epoch\n",
    "    hidden_state = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for batch_of_shifted_inputs, batch_of_targets in training_gen:\n",
    "        i += 1\n",
    "\n",
    "        # Ensure tensors are on the correct device\n",
    "        batch_of_shifted_inputs =  batch_of_shifted_inputs.to(device)\n",
    "        batch_of_targets        =  batch_of_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        log_softmax_output, _ = model(batch_of_shifted_inputs, hidden_state)\n",
    "\n",
    "        # Reshape the outputs and targets to match\n",
    "        num_classes        = log_softmax_output.size(-1)\n",
    "        log_softmax_output = log_softmax_output.view(-1, num_classes)\n",
    "        batch_of_targets   = batch_of_targets.view(-1)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(log_softmax_output, batch_of_targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "          print('i: ',i)\n",
    "          print('loss: ', total_loss / (i + 1))\n",
    "          print()\n",
    "\n",
    "    avg_loss = total_loss / (i + 1)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "kD8CgjdF0oyT",
   "metadata": {
    "id": "kD8CgjdF0oyT"
   },
   "outputs": [],
   "source": [
    "#torch.save(model,'GRULM.pt') # pt: pytorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186fc77-ed5c-493e-b3ee-5f98f7fb983b",
   "metadata": {
    "id": "n6t6Fjou0pB0"
   },
   "source": [
    "# Looking at inputs and outputs of each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c796f-db90-4376-b9f6-500aea4b13a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "mtxudHxqfJSj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtxudHxqfJSj",
    "outputId": "88332bea-b79f-459f-8de6-5d7cafa84c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original log_softmax_output shape: torch.Size([32, 64, 256])\n",
      "Original temp_targets shape: torch.Size([32, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define dimensions\n",
    "batch_size      = 32\n",
    "sequence_length = 64\n",
    "num_classes     = 256\n",
    "\n",
    "# Generate example tensors\n",
    "log_softmax_output = torch.randn(batch_size, sequence_length, num_classes)  # Random values\n",
    "temp_targets = torch.randint(0, num_classes, (batch_size, sequence_length))  # Random class indices\n",
    "\n",
    "print(\"Original log_softmax_output shape:\", log_softmax_output.shape)\n",
    "print(\"Original temp_targets shape:\", temp_targets.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "s1eriikwifND",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1eriikwifND",
    "outputId": "7dec6aed-f3d8-4813-9d23-234e1bd4147a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = log_softmax_output.size(-1)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "mnQ9PUbkifPW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnQ9PUbkifPW",
    "outputId": "84329d52-6d53-4f3c-a7a5-c90dc81c6b89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 256])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_output = log_softmax_output.view(-1, num_classes)\n",
    "log_softmax_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "K2wr2QPlifRm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K2wr2QPlifRm",
    "outputId": "c2557440-4737-45a8-a970-45997110299e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([129,  55,  65,  ..., 107, 161, 143]), torch.Size([2048]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_targets = temp_targets.view(-1)\n",
    "temp_targets, temp_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02034ecc-c869-449e-8d69-db8ea1442f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36eb1d-efc4-4833-99bb-89b69cd56e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc40e64-410a-4ac1-829b-ceb2909ab056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vksAd4WefJWG",
   "metadata": {
    "id": "vksAd4WefJWG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d6d8b-c5e0-4b9e-b30a-d055856a3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRULM(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GRULM, self).__init__()\n",
    "\n",
    "#         self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "#         self.gru = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "#         self.linear = nn.Linear(hidden_size, linear_output_size)\n",
    "\n",
    "#     def forward(self, x, hidden):\n",
    "\n",
    "#         x = self.embedding(x)\n",
    "\n",
    "#         gru_output, hidden = self.gru(x, hidden)\n",
    "\n",
    "#         linear_output = self.linear(gru_output)\n",
    "\n",
    "#         log_softmax_output = F.log_softmax(linear_output, dim=-1)\n",
    "#         return log_softmax_output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "R05HaHjMVTMK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R05HaHjMVTMK",
    "outputId": "22d40374-121d-461d-ab04-c0127740ffe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequences shape:\n",
      " torch.Size([32, 64])\n",
      "\n",
      "Embedded Sequences shape:\n",
      " torch.Size([32, 64, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Parameters\n",
    "vocab_size      = 256   # Number of unique tokens in the vocabulary\n",
    "emb_size        = 512   # Dimensionality of the embedding vectors\n",
    "batch_size      = 32    # Batch size\n",
    "sequence_length = 64    # Sequence length\n",
    "\n",
    "# Define the embedding layer\n",
    "embedding = nn.Embedding(vocab_size, emb_size)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create a batch of input sequences (indices)\n",
    "input_sequences = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
    "\n",
    "# Get the embedding representation of the sequences\n",
    "embedded_sequences = embedding(input_sequences)\n",
    "\n",
    "# Display shapes\n",
    "print(\"Input Sequences shape:\\n\", input_sequences.shape)\n",
    "print(\"\\nEmbedded Sequences shape:\\n\", embedded_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9N3bVyeKVTOp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9N3bVyeKVTOp",
    "outputId": "97b8072d-c690-42bc-b60a-d8c44b00c2c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Sequences shape:\n",
      " torch.Size([32, 64, 512])\n",
      "\n",
      "Initial Hidden State shape:\n",
      " torch.Size([2, 32, 512])\n",
      "\n",
      "GRU Output shape:\n",
      " torch.Size([32, 64, 512])\n",
      "\n",
      "Final Hidden State shape:\n",
      " torch.Size([2, 32, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Parameters\n",
    "hidden_size     = 512   # Number of features in the hidden state\n",
    "num_layers      = 2     # Number of recurrent layers\n",
    "batch_size      = 32    # Batch size\n",
    "sequence_length = 64    # Sequence length\n",
    "emb_size        = 512   # Dimensionality of the embedding vectors\n",
    "\n",
    "# Define the GRU layer with batch_first=True and 2 layers\n",
    "gru = nn.GRU(emb_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "# Initialize the hidden state (num_layers, batch_size, hidden_size)\n",
    "initial_hidden_state = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "# Forward pass through the GRU using the previously computed embeddings\n",
    "output, hidden_state = gru(embedded_sequences, initial_hidden_state)\n",
    "\n",
    "# Display shapes\n",
    "print(\"Embedded Sequences shape:\\n\", embedded_sequences.shape)\n",
    "print(\"\\nInitial Hidden State shape:\\n\", initial_hidden_state.shape)\n",
    "print(\"\\nGRU Output shape:\\n\", output.shape)\n",
    "print(\"\\nFinal Hidden State shape:\\n\", hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "U8YJbyu2VTRm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8YJbyu2VTRm",
    "outputId": "b6653f4c-ccc7-4c1a-8c22-f818076c4b9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU Output shape:\n",
      " torch.Size([32, 64, 512])\n",
      "\n",
      "Linear Output shape:\n",
      " torch.Size([32, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Parameters\n",
    "hidden_size        = 512  # Number of features in the hidden state (same as GRU output feature size)\n",
    "linear_output_size = 256  # Number of output features for the linear layer\n",
    "\n",
    "# Define the Linear layer\n",
    "linear = nn.Linear(hidden_size, linear_output_size)\n",
    "\n",
    "# Assume gru_output is available from the previous cell\n",
    "# For demonstration, creating a dummy gru_output tensor with the same shape as expected\n",
    "# If you are running this in sequence, remove this line\n",
    "gru_output = torch.randn(32, 64, 512)\n",
    "\n",
    "# Forward pass through the Linear layer\n",
    "linear_output = linear(gru_output)\n",
    "\n",
    "# Display shapes\n",
    "print(\"GRU Output shape:\\n\", gru_output.shape)\n",
    "print(\"\\nLinear Output shape:\\n\", linear_output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275034f2-58b9-47b8-b5c7-4bd36f400736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "NWybMn1vVTUL",
   "metadata": {
    "id": "NWybMn1vVTUL"
   },
   "outputs": [],
   "source": [
    "linear_output_soft_maxed = F.softmax(linear_output, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "HW02zZiQVTXk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HW02zZiQVTXk",
    "outputId": "9945b2bc-939d-4197-d3ad-5f7c9dfac5bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 256])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_soft_maxed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6Wj5eNR8MOjy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Wj5eNR8MOjy",
    "outputId": "b21696b7-a4e3-4add-c483-eacb76e7b2de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0074, 0.0042, 0.0041, 0.0012, 0.0033, 0.0063, 0.0107, 0.0034, 0.0024,\n",
       "        0.0017], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output_soft_maxed[0,0,:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "X7iqu91MMOmM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7iqu91MMOmM",
    "outputId": "77c7c56d-cad7-4068-d96f-31289fcddd20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(linear_output_soft_maxed[0,0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ncwIgJb9MOoP",
   "metadata": {
    "id": "ncwIgJb9MOoP"
   },
   "outputs": [],
   "source": [
    "log_linear_output_soft_maxed = torch.log(linear_output_soft_maxed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1tvtrc1OMOqx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tvtrc1OMOqx",
    "outputId": "db3b26d1-d42d-42ce-f3eb-42ae21629620"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.9077, -5.4785, -5.4887, -6.7558, -5.7147, -5.0720, -4.5364, -5.6715,\n",
       "        -6.0319, -6.3949, -5.4049, -5.5059, -5.3138, -6.0489, -5.8283],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_linear_output_soft_maxed[0,0,:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "_AMsvIMGMOsz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AMsvIMGMOsz",
    "outputId": "d3c720c0-220a-42bc-a56b-fd313f041289"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.9077, -5.4785, -5.4887, -6.7558, -5.7147, -5.0720, -4.5364, -5.6715,\n",
       "        -6.0319, -6.3949, -5.4049, -5.5059, -5.3138, -6.0489, -5.8283],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(linear_output, dim=-1)[0,0,:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TBL2Zhx3MOvA",
   "metadata": {
    "id": "TBL2Zhx3MOvA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fUTheFyMOyV",
   "metadata": {
    "id": "1fUTheFyMOyV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oprROTonMO1R",
   "metadata": {
    "id": "oprROTonMO1R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9M6j5tjQMO3U",
   "metadata": {
    "id": "9M6j5tjQMO3U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7E4j_vMO6s",
   "metadata": {
    "id": "db7E4j_vMO6s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61ffd4-42e4-458a-877e-c82bccbc210c",
   "metadata": {
    "id": "7d61ffd4-42e4-458a-877e-c82bccbc210c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "T3NxHd-VtTcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "T3NxHd-VtTcb",
    "outputId": "b945b175-3101-4600-ac2f-8c705c13d752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used lines from the dataset: 123034\n",
      "Batch size (a power of 2): 32\n",
      "Number of steps to cover one epoch: 3844\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "def n_used_lines(lines, max_length):\n",
    "    '''\n",
    "    Args:\n",
    "    lines: all lines of text an array of lines\n",
    "    max_length - max_length of a line in order to be considered an int\n",
    "    output_dir - folder to save your file an int\n",
    "    Return:\n",
    "    number of efective examples\n",
    "    '''\n",
    "\n",
    "    n_lines = 0\n",
    "    for l in lines:\n",
    "        if len(l) <= max_length:\n",
    "            n_lines += 1\n",
    "    return n_lines\n",
    "\n",
    "\n",
    "num_used_lines = n_used_lines(lines, 64)                          # onhoon nay max length 32 d\n",
    "print('Number of used lines from the dataset:', num_used_lines)\n",
    "print('Batch size (a power of 2):', int(batch_size))\n",
    "steps_per_epoch = int(num_used_lines/batch_size)\n",
    "print('Number of steps to cover one epoch:', steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abKPe7d4wt1C",
   "metadata": {
    "id": "abKPe7d4wt1C"
   },
   "source": [
    "## Evaluation  \n",
    "\n",
    "### Evaluating using the Deep Nets\n",
    "\n",
    "Now that you have learned how to train a model, you will learn how to evaluate it. To evaluate language models, we usually use perplexity which is a measure of how well a probability model predicts a sample. Note that perplexity is defined as:\n",
    "\n",
    "$$P(W) = \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}}$$\n",
    "\n",
    "As an implementation hack, you would usually take the log of that formula (to enable us to use the log probabilities we get as output of our `RNN`, convert exponents to products, and products into sums which makes computations less complicated and computationally more efficient). You should also take care of the padding, since you do not want to include the padding when calculating the perplexity (because we do not want to have a perplexity measure artificially good).\n",
    "\n",
    "\n",
    "$$\\log P(W) = {\\log\\left(\\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}}\\right)}$$$$ = \\log\\left(\\left(\\prod_{i=1}^{N} \\frac{1}{P(w_i| w_1,...,w_{n-1})}\\right)^{\\frac{1}{N}}\\right)$$\n",
    "$$ = \\log\\left(\\left({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{n-1})}}\\right)^{-\\frac{1}{N}}\\right)$$$$ = -\\frac{1}{N}{\\log\\left({\\prod_{i=1}^{N}{P(w_i| w_1,...,w_{n-1})}}\\right)} $$$$ = -\\frac{1}{N}{{\\sum_{i=1}^{N}{\\log P(w_i| w_1,...,w_{n-1})}}} $$\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### test_model\n",
    "**Instructions:** Write a program that will help evaluate your model. Implementation hack: your program takes in preds and target. Preds is a tensor of log probabilities. You can use `torch.nn.functional.one_hot(.....)` to transform the target into the same dimension. You then multiply them and sum.\n",
    "\n",
    "You also have to create a mask to only get the non-padded probabilities. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9PqIvySI6ZWb",
   "metadata": {
    "id": "9PqIvySI6ZWb"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li>To convert the target into the same dimension as the predictions tensor use tl.one.hot with target and preds.shape[-1].</li>\n",
    "    <li>You will also need the np.equal function in order to unpad the data and properly compute perplexity.</li>\n",
    "    <li>Keep in mind while implementing the formula above that <em> w<sub>i</sub></em> represents a letter from our 256 letter alphabet.</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c38a3-4d7c-4660-b1b4-b56b7fd59008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f67e8a-7fb2-4f0c-bb88-b017a311998c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8e444-a04d-479d-968d-f5de9621e170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261fa08-0cc4-4a4a-9ba8-b977e4bea59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf90e8-6b00-4995-a979-3318302cd7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3OtmlEuOwt1D",
   "metadata": {
    "id": "3OtmlEuOwt1D"
   },
   "outputs": [],
   "source": [
    "# UNQ_C5 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: test_model\n",
    "def test_model(preds, target):\n",
    "    \"\"\"Function to test the model.\n",
    "\n",
    "    Args:\n",
    "        preds (jax.interpreters.xla.DeviceArray): Predictions of a list of batches of tensors corresponding to lines of text.\n",
    "        target (jax.interpreters.xla.DeviceArray): Actual list of batches of tensors corresponding to lines of text.\n",
    "\n",
    "    Returns:\n",
    "        float: log_perplexity of the model.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    log_p = np.sum(preds * tl.one_hot(target, preds.shape[-1]), axis= -1) # HINT: tl.one_hot() should replace one of the Nones\n",
    "\n",
    "    non_pad = 1.0 - np.equal(target, 0)          # You should check if the target equals 0\n",
    "    log_p = log_p * non_pad                             # Get rid of the padding\n",
    "\n",
    "    log_ppx = np.sum(log_p, axis=1) / np.sum(non_pad, axis=1) # Remember to set the axis properly when summing up\n",
    "    log_ppx = np.mean(log_ppx) # Compute the mean of the previous expression\n",
    "\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return -log_ppx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xl8X0FPAwt1F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "deletable": false,
    "editable": false,
    "id": "xl8X0FPAwt1F",
    "outputId": "1dbfef92-c8ca-4cae-c92c-7b1b4adb6963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The log perplexity and perplexity of your model are respectively 1.7646704 5.8396473\n"
     ]
    }
   ],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# Testing\n",
    "model = GRULM()\n",
    "model.init_from_file('model.pkl.gz')\n",
    "batch = next(data_generator(batch_size, max_length, lines, shuffle=False))\n",
    "preds = model(batch[0])\n",
    "log_ppx = test_model(preds, batch[1])\n",
    "print('The log perplexity and perplexity of your model are respectively', log_ppx, np.exp(log_ppx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8PZdy1V2wt1H",
   "metadata": {
    "id": "8PZdy1V2wt1H"
   },
   "source": [
    "**Expected Output:** The log perplexity and perplexity of your model are respectively around 1.7 and 5.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kt9-Zb6p3ODY",
   "metadata": {
    "id": "kt9-Zb6p3ODY",
    "outputId": "fded5b7f-4c0b-4222-88a7-dfa8d23c5657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Test your function\n",
    "pretrained_model = GRULM()\n",
    "pretrained_model.init_from_file('model.pkl.gz')\n",
    "w2_unittest.unittest_test_model(test_model, pretrained_model)\n",
    "del pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15793283-7e7c-455d-a02a-cca799755e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cff229-be0d-4ffd-8963-836763a1a433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d5b6b2-7677-462c-8078-afb5511721b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b49115-4772-4084-8588-4620b6eb8310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480737a-14df-4ff9-905e-c1fab46df26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4-STC44Ywt1I",
   "metadata": {
    "id": "4-STC44Ywt1I"
   },
   "source": [
    "## Generating the Language with your Own Model\n",
    "\n",
    "We will now use your own language model to generate new sentences for that we need to make draws from a Gumbel distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AXdIBCGxtTdt",
   "metadata": {
    "id": "AXdIBCGxtTdt"
   },
   "source": [
    "The Gumbel Probability Density Function (PDF) is defined as:\n",
    "\n",
    "$$ f(z) = {1\\over{\\beta}}e^{(-z+e^{(-z)})} $$\n",
    "\n",
    "where: $$ z = {(x - \\mu)\\over{\\beta}}$$\n",
    "\n",
    "The maximum value, which is what we choose as the prediction in the last step of a Recursive Neural Network `RNN` we are using for text generation, in a sample of a random variable following an exponential distribution approaches the Gumbel distribution when the sample increases asymptotically. For that reason, the Gumbel distribution is used to sample from a categorical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eT4QyqZZ_P5s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT4QyqZZ_P5s",
    "outputId": "db1721ec-efd5-4ac1-a890-e04cc477c56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Gumbel sampling function for PyTorch tensors\n",
    "def gumbel_sample(log_probs, temperature=1.0):\n",
    "    u = torch.empty_like(log_probs).uniform_(1e-6, 1.0 - 1e-6)\n",
    "    g = -torch.log(-torch.log(u))\n",
    "    return torch.argmax(log_probs + g * temperature, dim=-1)\n",
    "\n",
    "# Prediction function\n",
    "def predict(model, num_chars, prefix, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    inp = [ord(c) for c in prefix]\n",
    "    result = [c for c in prefix]\n",
    "    max_len = len(prefix) + num_chars\n",
    "\n",
    "    inp_tensor = torch.tensor(inp, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "    hidden_state = torch.zeros(num_layers, 1, hidden_size).to(device)  # Initial hidden state\n",
    "\n",
    "    for _ in range(num_chars):\n",
    "        # Prepare input tensor by padding to max_len\n",
    "        cur_inp = torch.cat([inp_tensor, torch.zeros(1, max_len - inp_tensor.size(1), dtype=torch.long).to(device)], dim=1)\n",
    "\n",
    "        # Forward pass through the model\n",
    "        with torch.no_grad():\n",
    "            log_softmax_output, hidden_state = model(cur_inp, hidden_state)\n",
    "\n",
    "        # Get the output probabilities for the next character\n",
    "        next_char_log_probs = log_softmax_output[0, len(inp)-1, :]  # Shape: (num_classes,)\n",
    "\n",
    "        # Sample the next character using Gumbel sampling\n",
    "        next_char = gumbel_sample(next_char_log_probs, temperature=1.0).item()\n",
    "\n",
    "        # Append the next character to the input sequence\n",
    "        inp.append(next_char)\n",
    "        inp_tensor = torch.tensor(inp, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        # Break if EOS (end of sequence) token is encountered\n",
    "        if next_char == 1:\n",
    "            break\n",
    "\n",
    "        # Append the next character to the result\n",
    "        result.append(chr(next_char))\n",
    "\n",
    "    return \"\".join(result)\n",
    "\n",
    "# Example usage\n",
    "print(predict(model, 32, \"\", device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "eacd0427-a146-4917-870a-011bc78f50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " their cause may be,\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "print(predict(model, 32, \" \", device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "rWG3dvAr_TV0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWG3dvAr_TV0",
    "outputId": "74f61408-61c4-4d4e-c801-af1856aa902e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello work\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 32, \"Hello wor\", device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "A-x5Y3U0_The",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-x5Y3U0_The",
    "outputId": "9dce7cf6-fd90-4495-d8fa-e085f54a168d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is your night\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 32, \"what is your n\", device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "389f8fbd-6c1c-453a-a460-a7e782f331c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doubt, then i'll\n"
     ]
    }
   ],
   "source": [
    "print(predict(model, 32, \"do\", device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NAfV3l5Zwt1L",
   "metadata": {
    "id": "NAfV3l5Zwt1L"
   },
   "source": [
    "In the generated text above, you can see that the model generates text that makes sense capturing dependencies between words and without any input. A simple n-gram model would have not been able to capture all of that in one sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FsE8tdTLwt1M",
   "metadata": {
    "id": "FsE8tdTLwt1M"
   },
   "source": [
    "<a name='6'></a>\n",
    "###  <span style=\"color:blue\"> On statistical methods </span>\n",
    "\n",
    "Using a statistical method like the one you implemented in course 2 will not give you results that are as good. Your model will not be able to encode information seen previously in the data set and as a result, the perplexity will increase. Remember from course 2 that the higher the perplexity, the worse your model is. Furthermore, statistical ngram models take up too much space and memory. As a result, it will be inefficient and too slow. Conversely, with deepnets, you can get a better perplexity. Note, learning about n-gram language models is still important and allows you to better understand deepnets.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
