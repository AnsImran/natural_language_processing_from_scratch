{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khldx-vXk6WZ"
   },
   "source": [
    "works fine on google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EXN9KAtbOfk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# import Layer from the utils.py file\n",
    "from utils import load_tweets, process_tweet   # utils automaticaly data download kr lay ga, data kisi file main pass krnay ki zrurat nahi\n",
    "\n",
    "import random as rnd\n",
    "\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2A3-3rjby6Q"
   },
   "source": [
    "# Importing the data\n",
    "\n",
    "\n",
    "## Loading in the data\n",
    "\n",
    "Import the data set.  \n",
    "- You may recognize this from earlier assignments in the specialization.\n",
    "- Details of process_tweet function are available in utils.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39pkl1Mrb1Nd",
    "outputId": "b749b617-e302-4044-ef7d-773940b45207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive tweets: 5000\n",
      "The number of negative tweets: 5000\n",
      "length of train_x 8000\n",
      "length of val_x 2000\n"
     ]
    }
   ],
   "source": [
    "## DO NOT EDIT THIS CELL\n",
    "\n",
    "# Import functions from the utils.py file\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load positive and negative tweets\n",
    "all_positive_tweets, all_negative_tweets = load_tweets()\n",
    "\n",
    "# View the total number of positive and negative tweets.\n",
    "print(f\"The number of positive tweets: {len(all_positive_tweets)}\")\n",
    "print(f\"The number of negative tweets: {len(all_negative_tweets)}\")\n",
    "\n",
    "# Split positive set into validation and training\n",
    "val_pos   = all_positive_tweets[4000:] # generating validation set for positive tweets\n",
    "train_pos = all_positive_tweets[:4000]# generating training set for positive tweets\n",
    "\n",
    "# Split negative set into validation and training\n",
    "val_neg   = all_negative_tweets[4000:] # generating validation set for negative tweets\n",
    "train_neg = all_negative_tweets[:4000] # generating training set for nagative tweets\n",
    "\n",
    "# Combine training data into one set\n",
    "train_x = train_pos + train_neg\n",
    "\n",
    "# Combine validation data into one set\n",
    "val_x  = val_pos + val_neg\n",
    "\n",
    "# Set the labels for the training set (1 for positive, 0 for negative)\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "\n",
    "# Set the labels for the validation set (1 for positive, 0 for negative)\n",
    "val_y  = np.append(np.ones(len(val_pos)), np.zeros(len(val_neg)))\n",
    "\n",
    "print(f\"length of train_x {len(train_x)}\")\n",
    "print(f\"length of val_x {len(val_x)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FtL4_t1gdMOK"
   },
   "source": [
    "Now import a function that processes tweets (we've provided this in the utils.py file).\n",
    "- `process_tweets' removes unwanted characters e.g. hashtag, hyperlinks, stock tickers from tweet.\n",
    "- It also returns a list of words (it tokenizes the original string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHGBqCGsc1OC",
    "outputId": "58f892ea-f808-40ac-f2f0-3f2dad414eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original tweet at training position 0\n",
      "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "Tweet at training position 0 after processing:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a function that processes the tweets\n",
    "# from utils import process_tweet\n",
    "\n",
    "# Try out function that processes tweets\n",
    "print(\"original tweet at training position 0\")\n",
    "print(train_pos[0])\n",
    "\n",
    "print(\"Tweet at training position 0 after processing:\")\n",
    "process_tweet(train_pos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTF8Yh3ZdRQ8"
   },
   "source": [
    "## Building the vocabulary\n",
    "\n",
    "Now build the vocabulary.\n",
    "- Map each word in each tweet to an integer (an \"index\").\n",
    "- The following code does this for you, but please read it and understand what it's doing.\n",
    "- Note that you will build the vocabulary based on the training data.\n",
    "- To do so, you will assign an index to everyword by iterating over your training set.\n",
    "\n",
    "The vocabulary will also include some special tokens\n",
    "- `__PAD__`: padding\n",
    "- `</e>`: end of line\n",
    "- `__UNK__`: a token representing any word that is not in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "uczupNdndIVF",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a85c9d5e-2515-4cc7-854c-ff0edd977bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab are 9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__PAD__': 0,\n",
       " '__</e>__': 1,\n",
       " '__UNK__': 2,\n",
       " 'followfriday': 3,\n",
       " 'top': 4,\n",
       " 'engag': 5,\n",
       " 'member': 6,\n",
       " 'commun': 7,\n",
       " 'week': 8,\n",
       " ':)': 9,\n",
       " 'hey': 10,\n",
       " 'jame': 11,\n",
       " 'odd': 12,\n",
       " ':/': 13,\n",
       " 'pleas': 14,\n",
       " 'call': 15,\n",
       " 'contact': 16,\n",
       " 'centr': 17,\n",
       " '02392441234': 18,\n",
       " 'abl': 19,\n",
       " 'assist': 20,\n",
       " 'mani': 21,\n",
       " 'thank': 22,\n",
       " 'listen': 23,\n",
       " 'last': 24,\n",
       " 'night': 25,\n",
       " 'bleed': 26,\n",
       " 'amaz': 27,\n",
       " 'track': 28,\n",
       " 'scotland': 29,\n",
       " 'congrat': 30,\n",
       " 'yeaaah': 31,\n",
       " 'yipppi': 32,\n",
       " 'accnt': 33,\n",
       " 'verifi': 34,\n",
       " 'rqst': 35,\n",
       " 'succeed': 36,\n",
       " 'got': 37,\n",
       " 'blue': 38,\n",
       " 'tick': 39,\n",
       " 'mark': 40,\n",
       " 'fb': 41,\n",
       " 'profil': 42,\n",
       " '15': 43,\n",
       " 'day': 44,\n",
       " 'one': 45,\n",
       " 'irresist': 46,\n",
       " 'flipkartfashionfriday': 47,\n",
       " 'like': 48,\n",
       " 'keep': 49,\n",
       " 'love': 50,\n",
       " 'custom': 51,\n",
       " 'wait': 52,\n",
       " 'long': 53,\n",
       " 'hope': 54,\n",
       " 'enjoy': 55,\n",
       " 'happi': 56,\n",
       " 'friday': 57,\n",
       " 'lwwf': 58,\n",
       " 'second': 59,\n",
       " 'thought': 60,\n",
       " '‚Äô': 61,\n",
       " 'enough': 62,\n",
       " 'time': 63,\n",
       " 'dd': 64,\n",
       " 'new': 65,\n",
       " 'short': 66,\n",
       " 'enter': 67,\n",
       " 'system': 68,\n",
       " 'sheep': 69,\n",
       " 'must': 70,\n",
       " 'buy': 71,\n",
       " 'jgh': 72,\n",
       " 'go': 73,\n",
       " 'bayan': 74,\n",
       " ':d': 75,\n",
       " 'bye': 76,\n",
       " 'act': 77,\n",
       " 'mischiev': 78,\n",
       " 'etl': 79,\n",
       " 'layer': 80,\n",
       " 'in-hous': 81,\n",
       " 'wareh': 82,\n",
       " 'app': 83,\n",
       " 'katamari': 84,\n",
       " 'well': 85,\n",
       " '‚Ä¶': 86,\n",
       " 'name': 87,\n",
       " 'impli': 88,\n",
       " ':p': 89,\n",
       " 'influenc': 90,\n",
       " 'big': 91,\n",
       " '...': 92,\n",
       " 'juici': 93,\n",
       " 'selfi': 94,\n",
       " 'follow': 95,\n",
       " 'perfect': 96,\n",
       " 'alreadi': 97,\n",
       " 'know': 98,\n",
       " \"what'\": 99,\n",
       " 'great': 100,\n",
       " 'opportun': 101,\n",
       " 'junior': 102,\n",
       " 'triathlet': 103,\n",
       " 'age': 104,\n",
       " '12': 105,\n",
       " '13': 106,\n",
       " 'gatorad': 107,\n",
       " 'seri': 108,\n",
       " 'get': 109,\n",
       " 'entri': 110,\n",
       " 'lay': 111,\n",
       " 'greet': 112,\n",
       " 'card': 113,\n",
       " 'rang': 114,\n",
       " 'print': 115,\n",
       " 'today': 116,\n",
       " 'job': 117,\n",
       " ':-)': 118,\n",
       " \"friend'\": 119,\n",
       " 'lunch': 120,\n",
       " 'yummm': 121,\n",
       " 'nostalgia': 122,\n",
       " 'tb': 123,\n",
       " 'ku': 124,\n",
       " 'id': 125,\n",
       " 'conflict': 126,\n",
       " 'help': 127,\n",
       " \"here'\": 128,\n",
       " 'screenshot': 129,\n",
       " 'work': 130,\n",
       " 'hi': 131,\n",
       " 'liv': 132,\n",
       " 'hello': 133,\n",
       " 'need': 134,\n",
       " 'someth': 135,\n",
       " 'u': 136,\n",
       " 'fm': 137,\n",
       " 'twitter': 138,\n",
       " '‚Äî': 139,\n",
       " 'sure': 140,\n",
       " 'thing': 141,\n",
       " 'dm': 142,\n",
       " 'x': 143,\n",
       " \"i'v\": 144,\n",
       " 'heard': 145,\n",
       " 'four': 146,\n",
       " 'season': 147,\n",
       " 'pretti': 148,\n",
       " 'dope': 149,\n",
       " 'penthous': 150,\n",
       " 'obv': 151,\n",
       " 'gobigorgohom': 152,\n",
       " 'fun': 153,\n",
       " \"y'all\": 154,\n",
       " 'yeah': 155,\n",
       " 'suppos': 156,\n",
       " 'lol': 157,\n",
       " 'chat': 158,\n",
       " 'bit': 159,\n",
       " 'youth': 160,\n",
       " 'üíÖüèΩ': 161,\n",
       " 'üíã': 162,\n",
       " 'seen': 163,\n",
       " 'year': 164,\n",
       " 'rest': 165,\n",
       " 'goe': 166,\n",
       " 'quickli': 167,\n",
       " 'bed': 168,\n",
       " 'music': 169,\n",
       " 'fix': 170,\n",
       " 'dream': 171,\n",
       " 'spiritu': 172,\n",
       " 'ritual': 173,\n",
       " 'festiv': 174,\n",
       " 'n√©pal': 175,\n",
       " 'begin': 176,\n",
       " 'line-up': 177,\n",
       " 'left': 178,\n",
       " 'see': 179,\n",
       " 'sarah': 180,\n",
       " 'send': 181,\n",
       " 'us': 182,\n",
       " 'email': 183,\n",
       " 'bitsy@bitdefender.com': 184,\n",
       " \"we'll\": 185,\n",
       " 'asap': 186,\n",
       " 'kik': 187,\n",
       " 'hatessuc': 188,\n",
       " '32429': 189,\n",
       " 'kikm': 190,\n",
       " 'lgbt': 191,\n",
       " 'tinder': 192,\n",
       " 'nsfw': 193,\n",
       " 'akua': 194,\n",
       " 'cumshot': 195,\n",
       " 'come': 196,\n",
       " 'hous': 197,\n",
       " 'nsn_supplement': 198,\n",
       " 'effect': 199,\n",
       " 'press': 200,\n",
       " 'releas': 201,\n",
       " 'distribut': 202,\n",
       " 'result': 203,\n",
       " 'link': 204,\n",
       " 'remov': 205,\n",
       " 'pressreleas': 206,\n",
       " 'newsdistribut': 207,\n",
       " 'bam': 208,\n",
       " 'bestfriend': 209,\n",
       " 'lot': 210,\n",
       " 'warsaw': 211,\n",
       " '<3': 212,\n",
       " 'x46': 213,\n",
       " 'everyon': 214,\n",
       " 'watch': 215,\n",
       " 'documentari': 216,\n",
       " 'earthl': 217,\n",
       " 'youtub': 218,\n",
       " 'support': 219,\n",
       " 'buuut': 220,\n",
       " 'oh': 221,\n",
       " 'look': 222,\n",
       " 'forward': 223,\n",
       " 'visit': 224,\n",
       " 'next': 225,\n",
       " 'letsgetmessi': 226,\n",
       " 'jo': 227,\n",
       " 'make': 228,\n",
       " 'feel': 229,\n",
       " 'better': 230,\n",
       " 'never': 231,\n",
       " 'anyon': 232,\n",
       " 'kpop': 233,\n",
       " 'flesh': 234,\n",
       " 'good': 235,\n",
       " 'girl': 236,\n",
       " 'best': 237,\n",
       " 'wish': 238,\n",
       " 'reason': 239,\n",
       " 'epic': 240,\n",
       " 'soundtrack': 241,\n",
       " 'shout': 242,\n",
       " 'ad': 243,\n",
       " 'video': 244,\n",
       " 'playlist': 245,\n",
       " 'would': 246,\n",
       " 'dear': 247,\n",
       " 'jordan': 248,\n",
       " 'okay': 249,\n",
       " 'fake': 250,\n",
       " 'gameplay': 251,\n",
       " ';)': 252,\n",
       " 'haha': 253,\n",
       " 'im': 254,\n",
       " 'kid': 255,\n",
       " 'stuff': 256,\n",
       " 'exactli': 257,\n",
       " 'product': 258,\n",
       " 'line': 259,\n",
       " 'etsi': 260,\n",
       " 'shop': 261,\n",
       " 'check': 262,\n",
       " 'vacat': 263,\n",
       " 'recharg': 264,\n",
       " 'normal': 265,\n",
       " 'charger': 266,\n",
       " 'asleep': 267,\n",
       " 'talk': 268,\n",
       " 'sooo': 269,\n",
       " 'someon': 270,\n",
       " 'text': 271,\n",
       " 'ye': 272,\n",
       " 'bet': 273,\n",
       " \"he'll\": 274,\n",
       " 'fit': 275,\n",
       " 'hear': 276,\n",
       " 'speech': 277,\n",
       " 'piti': 278,\n",
       " 'green': 279,\n",
       " 'garden': 280,\n",
       " 'midnight': 281,\n",
       " 'sun': 282,\n",
       " 'beauti': 283,\n",
       " 'canal': 284,\n",
       " 'dasvidaniya': 285,\n",
       " 'till': 286,\n",
       " 'scout': 287,\n",
       " 'sg': 288,\n",
       " 'futur': 289,\n",
       " 'wlan': 290,\n",
       " 'pro': 291,\n",
       " 'confer': 292,\n",
       " 'asia': 293,\n",
       " 'chang': 294,\n",
       " 'lollipop': 295,\n",
       " 'üç≠': 296,\n",
       " 'nez': 297,\n",
       " 'agnezmo': 298,\n",
       " 'oley': 299,\n",
       " 'mama': 300,\n",
       " 'stand': 301,\n",
       " 'stronger': 302,\n",
       " 'god': 303,\n",
       " 'misti': 304,\n",
       " 'babi': 305,\n",
       " 'cute': 306,\n",
       " 'woohoo': 307,\n",
       " \"can't\": 308,\n",
       " 'sign': 309,\n",
       " 'yet': 310,\n",
       " 'still': 311,\n",
       " 'think': 312,\n",
       " 'mka': 313,\n",
       " 'liam': 314,\n",
       " 'access': 315,\n",
       " 'welcom': 316,\n",
       " 'stat': 317,\n",
       " 'arriv': 318,\n",
       " '1': 319,\n",
       " 'unfollow': 320,\n",
       " 'via': 321,\n",
       " 'surpris': 322,\n",
       " 'figur': 323,\n",
       " 'happybirthdayemilybett': 324,\n",
       " 'sweet': 325,\n",
       " 'talent': 326,\n",
       " '2': 327,\n",
       " 'plan': 328,\n",
       " 'drain': 329,\n",
       " 'gotta': 330,\n",
       " 'timezon': 331,\n",
       " 'parent': 332,\n",
       " 'proud': 333,\n",
       " 'least': 334,\n",
       " 'mayb': 335,\n",
       " 'sometim': 336,\n",
       " 'grade': 337,\n",
       " 'al': 338,\n",
       " 'grand': 339,\n",
       " 'manila_bro': 340,\n",
       " 'chosen': 341,\n",
       " 'let': 342,\n",
       " 'around': 343,\n",
       " '..': 344,\n",
       " 'side': 345,\n",
       " 'world': 346,\n",
       " 'eh': 347,\n",
       " 'take': 348,\n",
       " 'care': 349,\n",
       " 'final': 350,\n",
       " 'fuck': 351,\n",
       " 'weekend': 352,\n",
       " 'real': 353,\n",
       " 'x45': 354,\n",
       " 'join': 355,\n",
       " 'hushedcallwithfraydo': 356,\n",
       " 'gift': 357,\n",
       " 'yeahhh': 358,\n",
       " 'hushedpinwithsammi': 359,\n",
       " 'event': 360,\n",
       " 'might': 361,\n",
       " 'luv': 362,\n",
       " 'realli': 363,\n",
       " 'appreci': 364,\n",
       " 'share': 365,\n",
       " 'wow': 366,\n",
       " 'tom': 367,\n",
       " 'gym': 368,\n",
       " 'monday': 369,\n",
       " 'invit': 370,\n",
       " 'scope': 371,\n",
       " 'friend': 372,\n",
       " 'nude': 373,\n",
       " 'sleep': 374,\n",
       " 'birthday': 375,\n",
       " 'want': 376,\n",
       " 't-shirt': 377,\n",
       " 'cool': 378,\n",
       " 'haw': 379,\n",
       " 'phela': 380,\n",
       " 'mom': 381,\n",
       " 'obvious': 382,\n",
       " 'princ': 383,\n",
       " 'charm': 384,\n",
       " 'stage': 385,\n",
       " 'luck': 386,\n",
       " 'tyler': 387,\n",
       " 'hipster': 388,\n",
       " 'glass': 389,\n",
       " 'marti': 390,\n",
       " 'glad': 391,\n",
       " 'done': 392,\n",
       " 'afternoon': 393,\n",
       " 'read': 394,\n",
       " 'kahfi': 395,\n",
       " 'finish': 396,\n",
       " 'ohmyg': 397,\n",
       " 'yaya': 398,\n",
       " 'dub': 399,\n",
       " 'stalk': 400,\n",
       " 'ig': 401,\n",
       " 'gondooo': 402,\n",
       " 'moo': 403,\n",
       " 'tologooo': 404,\n",
       " 'becom': 405,\n",
       " 'detail': 406,\n",
       " 'zzz': 407,\n",
       " 'xx': 408,\n",
       " 'physiotherapi': 409,\n",
       " 'hashtag': 410,\n",
       " 'üí™': 411,\n",
       " 'monica': 412,\n",
       " 'miss': 413,\n",
       " 'sound': 414,\n",
       " 'morn': 415,\n",
       " \"that'\": 416,\n",
       " 'x43': 417,\n",
       " 'definit': 418,\n",
       " 'tri': 419,\n",
       " 'tonight': 420,\n",
       " 'took': 421,\n",
       " 'advic': 422,\n",
       " 'treviso': 423,\n",
       " 'concert': 424,\n",
       " 'citi': 425,\n",
       " 'countri': 426,\n",
       " \"i'll\": 427,\n",
       " 'start': 428,\n",
       " 'fine': 429,\n",
       " 'gorgeou': 430,\n",
       " 'xo': 431,\n",
       " 'oven': 432,\n",
       " 'roast': 433,\n",
       " 'garlic': 434,\n",
       " 'oliv': 435,\n",
       " 'oil': 436,\n",
       " 'dri': 437,\n",
       " 'tomato': 438,\n",
       " 'basil': 439,\n",
       " 'centuri': 440,\n",
       " 'tuna': 441,\n",
       " 'right': 442,\n",
       " 'back': 443,\n",
       " 'atchya': 444,\n",
       " 'even': 445,\n",
       " 'almost': 446,\n",
       " 'chanc': 447,\n",
       " 'cheer': 448,\n",
       " 'po': 449,\n",
       " 'ice': 450,\n",
       " 'cream': 451,\n",
       " 'agre': 452,\n",
       " '100': 453,\n",
       " 'heheheh': 454,\n",
       " 'that': 455,\n",
       " 'point': 456,\n",
       " 'stay': 457,\n",
       " 'home': 458,\n",
       " 'soon': 459,\n",
       " 'promis': 460,\n",
       " 'web': 461,\n",
       " 'whatsapp': 462,\n",
       " 'volta': 463,\n",
       " 'funcionar': 464,\n",
       " 'com': 465,\n",
       " 'iphon': 466,\n",
       " 'jailbroken': 467,\n",
       " 'later': 468,\n",
       " '34': 469,\n",
       " 'min': 470,\n",
       " 'leia': 471,\n",
       " 'appear': 472,\n",
       " 'hologram': 473,\n",
       " 'r2d2': 474,\n",
       " 'w': 475,\n",
       " 'messag': 476,\n",
       " 'obi': 477,\n",
       " 'wan': 478,\n",
       " 'sit': 479,\n",
       " 'luke': 480,\n",
       " 'inter': 481,\n",
       " '3': 482,\n",
       " 'ucl': 483,\n",
       " 'arsen': 484,\n",
       " 'small': 485,\n",
       " 'team': 486,\n",
       " 'pass': 487,\n",
       " 'üöÇ': 488,\n",
       " 'dewsburi': 489,\n",
       " 'railway': 490,\n",
       " 'station': 491,\n",
       " 'dew': 492,\n",
       " 'west': 493,\n",
       " 'yorkshir': 494,\n",
       " '430': 495,\n",
       " 'smh': 496,\n",
       " '9:25': 497,\n",
       " 'live': 498,\n",
       " 'strang': 499,\n",
       " 'imagin': 500,\n",
       " 'megan': 501,\n",
       " 'masaantoday': 502,\n",
       " 'a4': 503,\n",
       " 'shweta': 504,\n",
       " 'tripathi': 505,\n",
       " '5': 506,\n",
       " '20': 507,\n",
       " 'kurta': 508,\n",
       " 'half': 509,\n",
       " 'number': 510,\n",
       " 'wsalelov': 511,\n",
       " 'ah': 512,\n",
       " 'larri': 513,\n",
       " 'anyway': 514,\n",
       " 'kinda': 515,\n",
       " 'goood': 516,\n",
       " 'life': 517,\n",
       " 'enn': 518,\n",
       " 'could': 519,\n",
       " 'warmup': 520,\n",
       " '15th': 521,\n",
       " 'bath': 522,\n",
       " 'dum': 523,\n",
       " 'andar': 524,\n",
       " 'ram': 525,\n",
       " 'sampath': 526,\n",
       " 'sona': 527,\n",
       " 'mohapatra': 528,\n",
       " 'samantha': 529,\n",
       " 'edward': 530,\n",
       " 'mein': 531,\n",
       " 'tulan': 532,\n",
       " 'razi': 533,\n",
       " 'wah': 534,\n",
       " 'josh': 535,\n",
       " 'alway': 536,\n",
       " 'smile': 537,\n",
       " 'pictur': 538,\n",
       " '16.20': 539,\n",
       " 'giveitup': 540,\n",
       " 'given': 541,\n",
       " 'ga': 542,\n",
       " 'subsidi': 543,\n",
       " 'initi': 544,\n",
       " 'propos': 545,\n",
       " 'delight': 546,\n",
       " 'yesterday': 547,\n",
       " 'x42': 548,\n",
       " 'lmaoo': 549,\n",
       " 'song': 550,\n",
       " 'ever': 551,\n",
       " 'shall': 552,\n",
       " 'littl': 553,\n",
       " 'throwback': 554,\n",
       " 'outli': 555,\n",
       " 'island': 556,\n",
       " 'cheung': 557,\n",
       " 'chau': 558,\n",
       " 'mui': 559,\n",
       " 'wo': 560,\n",
       " 'total': 561,\n",
       " 'differ': 562,\n",
       " 'kfckitchentour': 563,\n",
       " 'kitchen': 564,\n",
       " 'clean': 565,\n",
       " \"i'm\": 566,\n",
       " 'cusp': 567,\n",
       " 'test': 568,\n",
       " 'water': 569,\n",
       " 'reward': 570,\n",
       " 'arummzz': 571,\n",
       " \"let'\": 572,\n",
       " 'drive': 573,\n",
       " 'travel': 574,\n",
       " 'yogyakarta': 575,\n",
       " 'jeep': 576,\n",
       " 'indonesia': 577,\n",
       " 'instamood': 578,\n",
       " 'wanna': 579,\n",
       " 'skype': 580,\n",
       " 'may': 581,\n",
       " 'nice': 582,\n",
       " 'friendli': 583,\n",
       " 'pretend': 584,\n",
       " 'film': 585,\n",
       " 'congratul': 586,\n",
       " 'winner': 587,\n",
       " 'cheesydelight': 588,\n",
       " 'contest': 589,\n",
       " 'address': 590,\n",
       " 'guy': 591,\n",
       " 'market': 592,\n",
       " '24/7': 593,\n",
       " '14': 594,\n",
       " 'hour': 595,\n",
       " 'leav': 596,\n",
       " 'without': 597,\n",
       " 'delay': 598,\n",
       " 'actual': 599,\n",
       " 'easi': 600,\n",
       " 'guess': 601,\n",
       " 'train': 602,\n",
       " 'wd': 603,\n",
       " 'shift': 604,\n",
       " 'engin': 605,\n",
       " 'etc': 606,\n",
       " 'sunburn': 607,\n",
       " 'peel': 608,\n",
       " 'blog': 609,\n",
       " 'huge': 610,\n",
       " 'warm': 611,\n",
       " '‚òÜ': 612,\n",
       " 'complet': 613,\n",
       " 'triangl': 614,\n",
       " 'northern': 615,\n",
       " 'ireland': 616,\n",
       " 'sight': 617,\n",
       " 'smthng': 618,\n",
       " 'fr': 619,\n",
       " 'hug': 620,\n",
       " 'xoxo': 621,\n",
       " 'uu': 622,\n",
       " 'jaann': 623,\n",
       " 'topnewfollow': 624,\n",
       " 'connect': 625,\n",
       " 'wonder': 626,\n",
       " 'made': 627,\n",
       " 'fluffi': 628,\n",
       " 'insid': 629,\n",
       " 'pirouett': 630,\n",
       " 'moos': 631,\n",
       " 'trip': 632,\n",
       " 'philli': 633,\n",
       " 'decemb': 634,\n",
       " \"i'd\": 635,\n",
       " 'dude': 636,\n",
       " 'x41': 637,\n",
       " 'question': 638,\n",
       " 'flaw': 639,\n",
       " 'pain': 640,\n",
       " 'negat': 641,\n",
       " 'strength': 642,\n",
       " 'went': 643,\n",
       " 'solo': 644,\n",
       " 'move': 645,\n",
       " 'fav': 646,\n",
       " 'nirvana': 647,\n",
       " 'smell': 648,\n",
       " 'teen': 649,\n",
       " 'spirit': 650,\n",
       " 'rip': 651,\n",
       " 'ami': 652,\n",
       " 'winehous': 653,\n",
       " 'coupl': 654,\n",
       " 'tomhiddleston': 655,\n",
       " 'elizabetholsen': 656,\n",
       " 'yaytheylookgreat': 657,\n",
       " 'goodnight': 658,\n",
       " 'vid': 659,\n",
       " 'wake': 660,\n",
       " 'gonna': 661,\n",
       " 'shoot': 662,\n",
       " 'itti': 663,\n",
       " 'bitti': 664,\n",
       " 'teeni': 665,\n",
       " 'bikini': 666,\n",
       " 'much': 667,\n",
       " '4th': 668,\n",
       " 'togeth': 669,\n",
       " 'end': 670,\n",
       " 'xfile': 671,\n",
       " 'content': 672,\n",
       " 'rain': 673,\n",
       " 'fabul': 674,\n",
       " 'fantast': 675,\n",
       " '‚ô°': 676,\n",
       " 'jb': 677,\n",
       " 'forev': 678,\n",
       " 'belieb': 679,\n",
       " 'nighti': 680,\n",
       " 'bug': 681,\n",
       " 'bite': 682,\n",
       " 'bracelet': 683,\n",
       " 'idea': 684,\n",
       " 'foundri': 685,\n",
       " 'game': 686,\n",
       " 'sens': 687,\n",
       " 'pic': 688,\n",
       " 'ef': 689,\n",
       " 'phone': 690,\n",
       " 'woot': 691,\n",
       " 'derek': 692,\n",
       " 'use': 693,\n",
       " 'parkshar': 694,\n",
       " 'gloucestershir': 695,\n",
       " 'aaaahhh': 696,\n",
       " 'man': 697,\n",
       " 'traffic': 698,\n",
       " 'stress': 699,\n",
       " 'reliev': 700,\n",
       " \"how'r\": 701,\n",
       " 'arbeloa': 702,\n",
       " 'turn': 703,\n",
       " '17': 704,\n",
       " 'omg': 705,\n",
       " 'say': 706,\n",
       " 'europ': 707,\n",
       " 'rise': 708,\n",
       " 'find': 709,\n",
       " 'hard': 710,\n",
       " 'believ': 711,\n",
       " 'uncount': 712,\n",
       " 'coz': 713,\n",
       " 'unlimit': 714,\n",
       " 'cours': 715,\n",
       " 'teamposit': 716,\n",
       " 'aldub': 717,\n",
       " '‚òï': 718,\n",
       " 'rita': 719,\n",
       " 'info': 720,\n",
       " \"we'd\": 721,\n",
       " 'way': 722,\n",
       " 'boy': 723,\n",
       " 'x40': 724,\n",
       " 'true': 725,\n",
       " 'sethi': 726,\n",
       " 'high': 727,\n",
       " 'exe': 728,\n",
       " 'skeem': 729,\n",
       " 'saam': 730,\n",
       " 'peopl': 731,\n",
       " 'polit': 732,\n",
       " 'izzat': 733,\n",
       " 'wese': 734,\n",
       " 'trust': 735,\n",
       " 'khawateen': 736,\n",
       " 'k': 737,\n",
       " 'sath': 738,\n",
       " 'mana': 739,\n",
       " 'kar': 740,\n",
       " 'deya': 741,\n",
       " 'sort': 742,\n",
       " 'smart': 743,\n",
       " 'hair': 744,\n",
       " 'tbh': 745,\n",
       " 'jacob': 746,\n",
       " 'g': 747,\n",
       " 'upgrad': 748,\n",
       " 'tee': 749,\n",
       " 'famili': 750,\n",
       " 'person': 751,\n",
       " 'two': 752,\n",
       " 'convers': 753,\n",
       " 'onlin': 754,\n",
       " 'mclaren': 755,\n",
       " 'fridayfeel': 756,\n",
       " 'tgif': 757,\n",
       " 'squar': 758,\n",
       " 'enix': 759,\n",
       " 'bissmillah': 760,\n",
       " 'ya': 761,\n",
       " 'allah': 762,\n",
       " \"we'r\": 763,\n",
       " 'socent': 764,\n",
       " 'startup': 765,\n",
       " 'drop': 766,\n",
       " 'your': 767,\n",
       " 'arnd': 768,\n",
       " 'town': 769,\n",
       " 'basic': 770,\n",
       " 'piss': 771,\n",
       " 'cup': 772,\n",
       " 'also': 773,\n",
       " 'terribl': 774,\n",
       " 'complic': 775,\n",
       " 'discuss': 776,\n",
       " 'snapchat': 777,\n",
       " 'lynettelow': 778,\n",
       " 'kikmenow': 779,\n",
       " 'snapm': 780,\n",
       " 'hot': 781,\n",
       " 'amazon': 782,\n",
       " 'kikmeguy': 783,\n",
       " 'defin': 784,\n",
       " 'grow': 785,\n",
       " 'sport': 786,\n",
       " 'rt': 787,\n",
       " 'rakyat': 788,\n",
       " 'write': 789,\n",
       " 'sinc': 790,\n",
       " 'mention': 791,\n",
       " 'fli': 792,\n",
       " 'fish': 793,\n",
       " 'promot': 794,\n",
       " 'post': 795,\n",
       " 'cyber': 796,\n",
       " 'ourdaughtersourprid': 797,\n",
       " 'mypapamyprid': 798,\n",
       " 'papa': 799,\n",
       " 'coach': 800,\n",
       " 'posit': 801,\n",
       " 'kha': 802,\n",
       " 'atleast': 803,\n",
       " 'x39': 804,\n",
       " 'mango': 805,\n",
       " \"lassi'\": 806,\n",
       " \"monty'\": 807,\n",
       " 'marvel': 808,\n",
       " 'though': 809,\n",
       " 'suspect': 810,\n",
       " 'meant': 811,\n",
       " '24': 812,\n",
       " 'hr': 813,\n",
       " 'touch': 814,\n",
       " 'kepler': 815,\n",
       " '452b': 816,\n",
       " 'chalna': 817,\n",
       " 'hai': 818,\n",
       " 'thankyou': 819,\n",
       " 'hazel': 820,\n",
       " 'food': 821,\n",
       " 'brooklyn': 822,\n",
       " 'pta': 823,\n",
       " 'awak': 824,\n",
       " 'okayi': 825,\n",
       " 'awww': 826,\n",
       " 'ha': 827,\n",
       " 'doc': 828,\n",
       " 'splendid': 829,\n",
       " 'spam': 830,\n",
       " 'folder': 831,\n",
       " 'amount': 832,\n",
       " 'nigeria': 833,\n",
       " 'claim': 834,\n",
       " 'rted': 835,\n",
       " 'leg': 836,\n",
       " 'hurt': 837,\n",
       " 'bad': 838,\n",
       " 'mine': 839,\n",
       " 'saturday': 840,\n",
       " 'thaaank': 841,\n",
       " 'puhon': 842,\n",
       " 'happinesss': 843,\n",
       " 'tnc': 844,\n",
       " 'prior': 845,\n",
       " 'notif': 846,\n",
       " 'fat': 847,\n",
       " 'co': 848,\n",
       " 'probabl': 849,\n",
       " 'ate': 850,\n",
       " 'yuna': 851,\n",
       " 'tamesid': 852,\n",
       " '¬¥': 853,\n",
       " 'googl': 854,\n",
       " 'account': 855,\n",
       " 'scouser': 856,\n",
       " 'everyth': 857,\n",
       " 'zoe': 858,\n",
       " 'mate': 859,\n",
       " 'liter': 860,\n",
       " \"they'r\": 861,\n",
       " 'samee': 862,\n",
       " 'edgar': 863,\n",
       " 'updat': 864,\n",
       " 'log': 865,\n",
       " 'bring': 866,\n",
       " 'abe': 867,\n",
       " 'meet': 868,\n",
       " 'x38': 869,\n",
       " 'sigh': 870,\n",
       " 'dreamili': 871,\n",
       " 'pout': 872,\n",
       " 'eye': 873,\n",
       " 'quacketyquack': 874,\n",
       " 'funni': 875,\n",
       " 'happen': 876,\n",
       " 'phil': 877,\n",
       " 'em': 878,\n",
       " 'del': 879,\n",
       " 'rodder': 880,\n",
       " 'els': 881,\n",
       " 'play': 882,\n",
       " 'newest': 883,\n",
       " 'gamejam': 884,\n",
       " 'irish': 885,\n",
       " 'literatur': 886,\n",
       " 'inaccess': 887,\n",
       " \"kareena'\": 888,\n",
       " 'fan': 889,\n",
       " 'brain': 890,\n",
       " 'dot': 891,\n",
       " 'braindot': 892,\n",
       " 'fair': 893,\n",
       " 'rush': 894,\n",
       " 'either': 895,\n",
       " 'brandi': 896,\n",
       " '18': 897,\n",
       " 'carniv': 898,\n",
       " 'men': 899,\n",
       " 'put': 900,\n",
       " 'mask': 901,\n",
       " 'xavier': 902,\n",
       " 'forneret': 903,\n",
       " 'jennif': 904,\n",
       " 'site': 905,\n",
       " 'free': 906,\n",
       " '50.000': 907,\n",
       " '8': 908,\n",
       " 'ball': 909,\n",
       " 'pool': 910,\n",
       " 'coin': 911,\n",
       " 'edit': 912,\n",
       " 'trish': 913,\n",
       " '‚ô•': 914,\n",
       " 'grate': 915,\n",
       " 'three': 916,\n",
       " 'comment': 917,\n",
       " 'wakeup': 918,\n",
       " 'besid': 919,\n",
       " 'dirti': 920,\n",
       " 'sex': 921,\n",
       " 'lmaooo': 922,\n",
       " 'üò§': 923,\n",
       " 'loui': 924,\n",
       " \"he'\": 925,\n",
       " 'throw': 926,\n",
       " 'caus': 927,\n",
       " 'inspir': 928,\n",
       " 'ff': 929,\n",
       " 'twoof': 930,\n",
       " 'gr8': 931,\n",
       " 'wkend': 932,\n",
       " 'kind': 933,\n",
       " 'exhaust': 934,\n",
       " 'word': 935,\n",
       " 'cheltenham': 936,\n",
       " 'area': 937,\n",
       " 'kale': 938,\n",
       " 'crisp': 939,\n",
       " 'ruin': 940,\n",
       " 'x37': 941,\n",
       " 'open': 942,\n",
       " 'worldwid': 943,\n",
       " 'outta': 944,\n",
       " 'sfvbeta': 945,\n",
       " 'vantast': 946,\n",
       " 'xcylin': 947,\n",
       " 'bundl': 948,\n",
       " 'show': 949,\n",
       " 'internet': 950,\n",
       " 'price': 951,\n",
       " 'realisticli': 952,\n",
       " 'pay': 953,\n",
       " 'net': 954,\n",
       " 'educ': 955,\n",
       " 'power': 956,\n",
       " 'weapon': 957,\n",
       " 'nelson': 958,\n",
       " 'mandela': 959,\n",
       " 'recent': 960,\n",
       " 'j': 961,\n",
       " 'chenab': 962,\n",
       " 'flow': 963,\n",
       " 'pakistan': 964,\n",
       " 'incredibleindia': 965,\n",
       " 'teenchoic': 966,\n",
       " 'choiceinternationalartist': 967,\n",
       " 'superjunior': 968,\n",
       " 'caught': 969,\n",
       " 'first': 970,\n",
       " 'salmon': 971,\n",
       " 'super-blend': 972,\n",
       " 'project': 973,\n",
       " 'youth@bipolaruk.org.uk': 974,\n",
       " 'awesom': 975,\n",
       " 'stream': 976,\n",
       " 'alma': 977,\n",
       " 'mater': 978,\n",
       " 'highschoolday': 979,\n",
       " 'clientvisit': 980,\n",
       " 'faith': 981,\n",
       " 'christian': 982,\n",
       " 'school': 983,\n",
       " 'lizaminnelli': 984,\n",
       " 'upcom': 985,\n",
       " 'uk': 986,\n",
       " 'üòÑ': 987,\n",
       " 'singl': 988,\n",
       " 'hill': 989,\n",
       " 'everi': 990,\n",
       " 'beat': 991,\n",
       " 'wrong': 992,\n",
       " 'readi': 993,\n",
       " 'natur': 994,\n",
       " 'pefumeri': 995,\n",
       " 'workshop': 996,\n",
       " 'neal': 997,\n",
       " 'yard': 998,\n",
       " 'covent': 999,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the vocabulary\n",
    "# Unit Test Note - There is no test set here only train/val\n",
    "\n",
    "# Include special tokens\n",
    "# started with pad, end of line and unk tokens\n",
    "Vocab = {'__PAD__': 0, '__</e>__': 1, '__UNK__': 2}\n",
    "\n",
    "# Note that we build vocab using training data\n",
    "for tweet in train_x:\n",
    "    processed_tweet = process_tweet(tweet)\n",
    "    for word in processed_tweet:\n",
    "        if word not in Vocab:\n",
    "            Vocab[word] = len(Vocab)\n",
    "\n",
    "print(\"Total words in vocab are\",len(Vocab))\n",
    "display(Vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fmN8RnVvyU5d",
    "outputId": "518e84a2-5d4f-427a-80ae-e06bddc4289f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9088"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lauYFvmxeFAu"
   },
   "source": [
    "The dictionary `Vocab` will look like this:\n",
    "```CPP\n",
    "{'__PAD__': 0,\n",
    " '__</e>__': 1,\n",
    " '__UNK__': 2,\n",
    " 'followfriday': 3,\n",
    " 'top': 4,\n",
    " 'engag': 5,\n",
    " ...\n",
    "```\n",
    "\n",
    "- Each unique word has a unique integer associated with it.\n",
    "- The total number of words in Vocab: 9088"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NPj72TmeNbK"
   },
   "source": [
    "## Converting a tweet to a tensor\n",
    "\n",
    "Write a function that will convert each tweet to a tensor (a list of unique integer IDs representing the processed tweet).\n",
    "- Note, the returned data type will be a **regular Python `list()`**\n",
    "    - You won't use TensorFlow in this function\n",
    "    - You also won't use a numpy array\n",
    "    - You also won't use trax.fastmath.numpy array\n",
    "- For words in the tweet that are not in the vocabulary, set them to the unique ID for the token `__UNK__`.\n",
    "\n",
    "##### Example\n",
    "Input a tweet:\n",
    "```CPP\n",
    "'@happypuppy, is Maria happy?'\n",
    "```\n",
    "\n",
    "The tweet_to_tensor will first conver the tweet into a list of tokens (including only relevant words)\n",
    "```CPP\n",
    "['maria', 'happi']\n",
    "```\n",
    "\n",
    "Then it will convert each word into its unique integer\n",
    "\n",
    "```CPP\n",
    "[2, 56]\n",
    "```\n",
    "- Notice that the word \"maria\" is not in the vocabulary, so it is assigned the unique integer associated with the `__UNK__` token, because it is considered \"unknown.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-_tm_2ledGd"
   },
   "source": [
    "### Exercise\n",
    "**Instructions:** Write a program `tweet_to_tensor` that takes in a tweet and converts it to an array of numbers. You can use the `Vocab` dictionary you just found to help create the tensor.\n",
    "\n",
    "- Use the vocab_dict parameter and not a global variable.\n",
    "- Do not hard code the integer value for the `__UNK__` token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dPpC4udqddNr"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: tweet_to_tensor\n",
    "def tweet_to_tensor(tweet, vocab_dict, unk_token='__UNK__', verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        tweet - A string containing a tweet\n",
    "        vocab_dict - The words dictionary\n",
    "        unk_token - The special string for unknown tokens\n",
    "        verbose - Print info durign runtime\n",
    "    Output:\n",
    "        tensor_l - A python list with\n",
    "\n",
    "    '''\n",
    "\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # Process the tweet into a list of words\n",
    "    # where only important words are kept (stop words removed)\n",
    "    word_l = process_tweet(tweet)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"List of words from the processed tweet:\")\n",
    "        print(word_l)\n",
    "\n",
    "    # Initialize the list that will contain the unique integer IDs of each word\n",
    "    tensor_l = []              # tensor lsit\n",
    "\n",
    "    # Get the unique integer ID of the __UNK__ token\n",
    "    unk_ID = vocab_dict[unk_token]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"The unique integer ID for the unk_token is {unk_ID}\")\n",
    "\n",
    "    # for each word in the list:\n",
    "    for word in word_l:\n",
    "\n",
    "        # Get the unique integer ID.\n",
    "        # If the word doesn't exist in the vocab dictionary,\n",
    "        # use the unique ID for __UNK__ instead.\n",
    "        word_ID = vocab_dict[word] if word in vocab_dict else unk_ID    # could have also used    vocab_dict.get(word, unk_ID)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "        # Append the unique integer ID to the tensor list.\n",
    "        tensor_l.append(word_ID)\n",
    "\n",
    "    return tensor_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XdiWuDM0elzi",
    "outputId": "a306126f-6329-4424-a1ec-6fffb62bab26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual tweet is\n",
      " Bro:U wan cut hair anot,ur hair long Liao bo\n",
      "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
      "Bro:LOL Sibei xialan\n",
      "\n",
      "Tensor of tweet:\n",
      " [1064, 136, 478, 2351, 744, 8148, 1122, 744, 53, 2, 2671, 790, 2, 2, 348, 600, 2, 3488, 1016, 596, 4558, 9, 1064, 157, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual tweet is\\n\", val_pos[0])         # validation positive\n",
    "print(\"\\nTensor of tweet:\\n\", tweet_to_tensor(val_pos[0], vocab_dict=Vocab))          # tweet not tweetS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s07wxbbAgd2I"
   },
   "source": [
    "##### Expected output\n",
    "\n",
    "```CPP\n",
    "Actual tweet is\n",
    " Bro:U wan cut hair anot,ur hair long Liao bo\n",
    "Me:since ord liao,take it easy lor treat as save $ leave it longer :)\n",
    "Bro:LOL Sibei xialan\n",
    "\n",
    "Tensor of tweet:\n",
    " [1065, 136, 479, 2351, 745, 8148, 1123, 745, 53, 2, 2672, 791, 2, 2, 349, 601, 2, 3489, 1017, 597, 4559, 9, 1065, 157, 2, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fz7TgQRnitP2"
   },
   "source": [
    "# issue!\n",
    "\n",
    "note, the word that is 1064 in my vocab, it is 1065 in their vocab.\n",
    "\n",
    "problem is somewhere b/w 136 and 480. in my vocab there is one less word, and it then changes the unique ids of all the next words, that is the reason (most probably), why the  next test will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xS0BYe_df6ZJ",
    "outputId": "f4171aaa-e25f-4622-930d-43b3932b997c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The function gives bad output for val_pos[1]. Test failed\n",
      "2  Tests passed out of 3\n"
     ]
    }
   ],
   "source": [
    "# test tweet_to_tensor\n",
    "\n",
    "def test_tweet_to_tensor():\n",
    "    test_cases = [\n",
    "\n",
    "        {\n",
    "            \"name\":\"simple_test_check\",\n",
    "            \"input\": [val_pos[1], Vocab],\n",
    "            \"expected\":[444, 2, 304, 567, 56, 9],\n",
    "            \"error\":\"The function gives bad output for val_pos[1]. Test failed\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"datatype_check\",\n",
    "            \"input\":[val_pos[1], Vocab],\n",
    "            \"expected\":type([]),\n",
    "            \"error\":\"Datatype mismatch. Need only list not np.array\"\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"without_unk_check\",\n",
    "            \"input\":[val_pos[1], Vocab],\n",
    "            \"expected\":6,\n",
    "            \"error\":\"Unk word check not done- Please check if you included mapping for unknown word\"\n",
    "        }\n",
    "    ]\n",
    "    count = 0\n",
    "    for test_case in test_cases:\n",
    "\n",
    "        try:\n",
    "            if test_case['name'] == \"simple_test_check\":\n",
    "                assert test_case[\"expected\"] == tweet_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"datatype_check\":\n",
    "                assert isinstance(tweet_to_tensor(*test_case['input']), test_case[\"expected\"])\n",
    "                count += 1\n",
    "            if test_case['name'] == \"without_unk_check\":\n",
    "                assert None not in tweet_to_tensor(*test_case['input'])\n",
    "                count += 1\n",
    "\n",
    "\n",
    "\n",
    "        except:\n",
    "            print(test_case['error'])\n",
    "    if count == 3:\n",
    "        print(\"\\033[92m All tests passed\")\n",
    "    else:\n",
    "        print(count,\" Tests passed out of 3\")\n",
    "test_tweet_to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpQmTTNOimzV"
   },
   "source": [
    "## Creating a batch generator\n",
    "\n",
    "### However, I won't use this one\n",
    "\n",
    "Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets.\n",
    "- If instead of training with batches of examples, you were to train a model with one example at a time, it would take a very long time to train the model.\n",
    "- You will now build a data generator that takes in the positive/negative tweets and returns a batch of training examples. It returns the model inputs, the targets (positive or negative labels) and the weight for each target (ex: this allows us to can treat some examples as more important to get right than others, but commonly this will all be 1.0).\n",
    "\n",
    "Once you create the generator, you could include it in a for loop\n",
    "\n",
    "```CPP\n",
    "for batch_inputs, batch_targets, batch_example_weights in data_generator:\n",
    "    ...\n",
    "```\n",
    "\n",
    "You can also get a single batch like this:\n",
    "\n",
    "```CPP\n",
    "batch_inputs, batch_targets, batch_example_weights = next(data_generator)\n",
    "```\n",
    "The generator returns the next batch each time it's called.\n",
    "- This generator returns the data in a format (tensors) that you could directly use in your model.\n",
    "- It returns a triple: the inputs, targets, and loss weights:\n",
    "-- Inputs is a tensor that contains the batch of tweets we put into the model.\n",
    "-- Targets is the corresponding batch of labels that we train to generate.\n",
    "-- Loss weights here are just 1s with same shape as targets. Next week, you will use it to mask input padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgl7vVMkpkOJ"
   },
   "source": [
    "### Exercise\n",
    "Implement `data_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYUNnck-goav"
   },
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED: Data generator\n",
    "def data_generator(data_pos, data_neg, batch_size, loop, vocab_dict, shuffle=False):\n",
    "    '''\n",
    "    Input:\n",
    "        data_pos - Set of posstive examples\n",
    "        data_neg - Set of negative examples\n",
    "        batch_size - number of samples per batch. Must be even\n",
    "        loop - True or False\n",
    "        vocab_dict - The words dictionary\n",
    "        shuffle - Shuffle the data order\n",
    "    Yield:\n",
    "        inputs - Subset of positive and negative examples\n",
    "        targets - The corresponding labels for the subset\n",
    "        example_weights - An array specifying the importance of each example\n",
    "\n",
    "    '''\n",
    "### START GIVEN CODE ###\n",
    "    # make sure the batch size is an even number\n",
    "    # to allow an equal number of positive and negative samples\n",
    "    assert batch_size % 2 == 0\n",
    "\n",
    "    # Number of positive examples in each batch is half of the batch size\n",
    "    # same with number of negative examples in each batch\n",
    "    n_to_take = batch_size // 2\n",
    "\n",
    "    # Use pos_index to walk through the data_pos array\n",
    "    # same with neg_index and data_neg\n",
    "    pos_index = 0\n",
    "    neg_index = 0\n",
    "\n",
    "    len_data_pos = len(data_pos)\n",
    "    len_data_neg = len(data_neg)\n",
    "\n",
    "    # Get and array with the data indexes\n",
    "    pos_index_lines = list(range(len_data_pos))\n",
    "    neg_index_lines = list(range(len_data_neg))\n",
    "\n",
    "    # shuffle lines if shuffle is set to True\n",
    "    if shuffle:\n",
    "        rnd.shuffle(pos_index_lines)\n",
    "        rnd.shuffle(neg_index_lines)\n",
    "\n",
    "    stop = False\n",
    "\n",
    "    # Loop indefinitely\n",
    "    while not stop:\n",
    "\n",
    "        # create a batch with positive and negative examples\n",
    "        batch = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First part: Pack n_to_take positive examples\n",
    "        # Start from pos_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "\n",
    "\n",
    "\n",
    "   # jab aik dfa saari ki saari +ive examples k number k equal number of times, loop chal gai, phir ye block chlay ga\n",
    "            # If the positive index goes past the positive dataset lenght,\n",
    "            if pos_index >= len_data_pos:\n",
    "\n",
    "\n",
    "   # agar function call krtay vaqt kaha tha k, loop = True, tu phir infinitely data generate hota jaye ga\n",
    "   # otherwise, agar loop = False hay tu sirf aik bar hi +ive examples k number k equal number of times examples hi output aayain gi, randomly (maybe)\n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "\n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                pos_index = 0\n",
    "\n",
    "\n",
    "   # ab choon k data par dobara iterate krnay lga hun so, ab indices reset kr dain gay aik bar, or new config k mutabiq batches generate hoon gay\n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the positive sample\n",
    "                    rnd.shuffle(pos_index_lines)\n",
    "\n",
    "\n",
    "\n",
    "            # get the tweet as pos_index\n",
    "            tweet = data_pos[pos_index_lines[pos_index]]\n",
    "\n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "\n",
    "   # batch main shuru main saari +ive example pri hoon gi maybe shuffled and repeated as well.\n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "\n",
    "            # Increment pos_index by one\n",
    "            pos_index = pos_index + 1\n",
    "\n",
    "### END GIVEN CODE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "\n",
    "# Second part: Pack n_to_take negative examples\n",
    "\n",
    "        # Using the same batch list, start from neg_index and increment i up to n_to_take\n",
    "        for i in range(n_to_take):\n",
    "\n",
    "            # If the negative index goes past the negative dataset length,\n",
    "            if neg_index >= len_data_neg:\n",
    "\n",
    "                # If loop is set to False, break once we reach the end of the dataset\n",
    "                if not loop:\n",
    "                    stop = True;\n",
    "                    break;\n",
    "\n",
    "                # If user wants to keep re-using the data, reset the index\n",
    "                neg_index = 0\n",
    "\n",
    "                if shuffle:\n",
    "                    # Shuffle the index of the negative sample\n",
    "                    rnd.shuffle(neg_index_lines)\n",
    "            # get the tweet as pos_index\n",
    "            tweet = data_neg[neg_index_lines[neg_index]]\n",
    "\n",
    "            # convert the tweet into tensors of integers representing the processed words\n",
    "            tensor = tweet_to_tensor(tweet, vocab_dict)\n",
    "\n",
    "            # append the tensor to the batch list\n",
    "            batch.append(tensor)\n",
    "\n",
    "            # Increment neg_index by one\n",
    "            neg_index += 1\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### START GIVEN CODE ###\n",
    "        if stop:\n",
    "            break;\n",
    "\n",
    "        # Update the start index for positive data\n",
    "        # so that it's n_to_take positions after the current pos_index\n",
    "        pos_index += n_to_take\n",
    "\n",
    "        # Update the start index for negative data\n",
    "        # so that it's n_to_take positions after the current neg_index\n",
    "        neg_index += n_to_take\n",
    "\n",
    "        # Get the max tweet length (the length of the longest tweet)\n",
    "        # (you will pad all shorter tweets to have this length)\n",
    "        max_len = max([len(t) for t in batch])                 # ye length tu os tweet ki length k equal hoti jo training set main sb say bari hoti, isay current batch ki sab say lambi tweet ki length k brarbar q rakah?\n",
    "\n",
    "\n",
    "        # Initialize the input_l, which will\n",
    "        # store the padded versions of the tensors\n",
    "        tensor_pad_l = []\n",
    "        # Pad shorter tweets with zeros\n",
    "        for tensor in batch:\n",
    "### END GIVEN CODE ###\n",
    "\n",
    "\n",
    "### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "            # Get the number of positions to pad for this tensor so that it will be max_len long\n",
    "            n_pad = max_len - len(tensor)\n",
    "\n",
    "            # Generate a list of zeros, with length n_pad\n",
    "            pad_l = [0]*n_pad\n",
    "\n",
    "            # concatenate the tensor and the list of padded zeros\n",
    "            tensor_pad = tensor + pad_l\n",
    "\n",
    "            # append the padded tensor to the list of padded tensors\n",
    "            tensor_pad_l.append(tensor_pad)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # convert the list of padded tensors to a numpy array\n",
    "        # and store this as the model inputs\n",
    "        inputs = np.array(tensor_pad_l)\n",
    "\n",
    "        # Generate the list of targets for the positive examples (a list of ones)\n",
    "        # The length is the number of positive examples in the batch\n",
    "        target_pos = [1]*n_to_take\n",
    "\n",
    "        # Generate the list of targets for the negative examples (a list of ones)\n",
    "        # The length is the number of negative examples in the batch\n",
    "        target_neg = [0]*n_to_take\n",
    "\n",
    "        # Concatenate the positve and negative targets\n",
    "        target_l = target_pos + target_neg\n",
    "\n",
    "        # Convert the target list into a numpy array\n",
    "        targets = np.array(target_l)\n",
    "\n",
    "        # Example weights: Treat all examples equally importantly.\n",
    "        example_weights = np.ones(len(targets))\n",
    "\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### GIVEN CODE ###\n",
    "        # note we use yield and not return\n",
    "        yield inputs, targets, example_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3Dm1IGNwsCF"
   },
   "source": [
    "Now you can use your data generator to create a data generator for the training data, and another data generator for the validation data.\n",
    "\n",
    "We will create a third data generator that does not loop, for testing the final accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mMMuTFj7psbl",
    "outputId": "61d488d0-e7e8-4042-cfcf-8ac1ecb93898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [[2005 4450 3200    9    0    0    0    0    0    0    0]\n",
      " [4953  566 2000 1453 5173 3498  141 3498  130  458    9]\n",
      " [3760  109  136  582 2929 3968    0    0    0    0    0]\n",
      " [ 249 3760    0    0    0    0    0    0    0    0    0]]\n",
      "Targets: [1 1 0 0]\n",
      "Example Weights: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Set the random number generator for the shuffle procedure\n",
    "rnd.seed(30)\n",
    "\n",
    "# Create the training data generator\n",
    "def train_generator(batch_size, shuffle = False):\n",
    "    return data_generator(train_pos, train_neg, batch_size, True, Vocab, shuffle)########\n",
    "\n",
    "# Create the validation data generator\n",
    "def val_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, True, Vocab, shuffle)##########\n",
    "\n",
    "# Create the validation data generator\n",
    "def test_generator(batch_size, shuffle = False):\n",
    "    return data_generator(val_pos, val_neg, batch_size, False, Vocab, shuffle)\n",
    "\n",
    "# Get a batch from the train_generator and inspect.\n",
    "inputs, targets, example_weights = next(train_generator(4, shuffle=True))\n",
    "\n",
    "# this will print a list of 4 tensors padded with zeros\n",
    "print(f'Inputs: {inputs}')\n",
    "print(f'Targets: {targets}')\n",
    "print(f'Example Weights: {example_weights}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFSmzZ_jwu90",
    "outputId": "5e8e4d5d-08d2-4176-8ae3-f7410d90b5c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs shape is (4, 14)\n",
      "The targets shape is (4,)\n",
      "The example weights shape is (4,)\n",
      "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1; example weights 1.0\n",
      "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1; example weights 1.0\n",
      "input tensor: [5736 2900 3760    0    0    0    0    0    0    0    0    0    0    0]; target 0; example weights 1.0\n",
      "input tensor: [ 857  255 3651 5737  306 4457  566 1229 2766  327 1201 3760    0    0]; target 0; example weights 1.0\n"
     ]
    }
   ],
   "source": [
    "# Test the train_generator\n",
    "\n",
    "# Create a data generator for training data,\n",
    "# which produces batches of size 4 (for tensors and their respective targets)\n",
    "tmp_data_gen = train_generator(batch_size = 4)\n",
    "\n",
    "# Call the data generator to get one batch and its targets\n",
    "tmp_inputs, tmp_targets, tmp_example_weights = next(tmp_data_gen)\n",
    "\n",
    "print(f\"The inputs shape is {tmp_inputs.shape}\")\n",
    "print(f\"The targets shape is {tmp_targets.shape}\")\n",
    "print(f\"The example weights shape is {tmp_example_weights.shape}\")\n",
    "\n",
    "for i,t in enumerate(tmp_inputs):\n",
    "    print(f\"input tensor: {t}; target {tmp_targets[i]}; example weights {tmp_example_weights[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sSWZo60x_Au"
   },
   "source": [
    "##### Expected output\n",
    "\n",
    "```CPP\n",
    "The inputs shape is (4, 14)\n",
    "The targets shape is (4,)\n",
    "The example weights shape is (4,)\n",
    "input tensor: [3 4 5 6 7 8 9 0 0 0 0 0 0 0]; target 1; example weights 1\n",
    "input tensor: [10 11 12 13 14 15 16 17 18 19 20  9 21 22]; target 1; example weights 1\n",
    "input tensor: [5738 2901 3761    0    0    0    0    0    0    0    0    0    0    0]; target 0; example weights 1\n",
    "input tensor: [ 858  256 3652 5739  307 4458  567 1230 2767  328 1202 3761    0    0]; target 0; example weights 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkJVQrNGyvtP"
   },
   "source": [
    "Now that you have your train/val generators, you can just call them and they will return tensors which correspond to your tweets in the first column and their corresponding labels in the second column. Now you can go ahead and start building your neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVDaGhG8vGNg"
   },
   "source": [
    "# Creating train and val datasets from my logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXt0o4N8FT_9"
   },
   "source": [
    "## train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0l_WeTYWxEFT",
    "outputId": "7e2f75bb-0085-458e-b7ee-6b2831fcda4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZS4CFc3vxEIS",
    "outputId": "31da13a4-3705-46c9-b015-35930795f6c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "4v44w7SjxEK2",
    "outputId": "82caf271-c5ca-449d-879a-4148c5973a32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyWeurO8FoGm"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHHFPieTxENy"
   },
   "outputs": [],
   "source": [
    "tensor_tweet = tweet_to_tensor(train_pos[1900], Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yp0tnA0LxEP1",
    "outputId": "dd67ab3f-78a2-4a00-bac0-34b2c7e58b74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[415, 3398, 118]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "id": "56K2IIwRxESk",
    "outputId": "f8640e49-51b2-4843-e6e3-cc3f64a84e29"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'@hayleybrown750 morning Hayley :-)'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos[1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROETKLlTzC3p",
    "outputId": "08fdad57-df53-4024-973e-3dc5673caa1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(len(train_pos)):\n",
    "  current_len = len(tweet_to_tensor(train_pos[i], Vocab))\n",
    "  if current_len > a:\n",
    "    a= current_len\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqoenKnr1MLc",
    "outputId": "0ca6c309-cbae-43c4-b2d4-543c8a92e2a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(len(train_neg)):\n",
    "  current_len = len(tweet_to_tensor(train_neg[i], Vocab))\n",
    "  if current_len > a:\n",
    "    a= current_len\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QreAsVqVzC5-"
   },
   "outputs": [],
   "source": [
    "all_pos_int_tweets = []\n",
    "\n",
    "for i in range(len(train_pos)):\n",
    "  current_tweet = tweet_to_tensor(train_pos[i], Vocab)\n",
    "  all_pos_int_tweets.append(current_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AwMajqazC8j",
    "outputId": "d210614f-6084-45d3-e27b-afc9d4e16dde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_int_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAqbzA47zDAO",
    "outputId": "f2e18f76-4b92-4e56-da6d-4e51baef5ae8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 60)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_int_tweets_matrix = np.zeros((len(train_pos), 60))\n",
    "all_pos_int_tweets_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQPuS71e06sr",
    "outputId": "e926e988-3910-4608-bc6a-4d26f8ec7777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.,  0.,  0.,  0.,\n",
       "         0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]\n",
    "b = np.zeros((2,15))\n",
    "\n",
    "b[0, : len(a)] = a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEKKw2b-xEXg"
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_pos_int_tweets)):\n",
    "  all_pos_int_tweets_matrix[i, :len(all_pos_int_tweets[i])] = all_pos_int_tweets[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PcFmajFxEaR",
    "outputId": "8b601841-3887-4e26-ff29-48b4aeaf5750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.000e+00, 4.000e+00, 5.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.000e+01, 1.100e+01, 1.200e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [2.300e+01, 2.400e+01, 2.500e+01, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       ...,\n",
       "       [2.200e+01, 7.910e+02, 7.150e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [4.160e+02, 5.735e+03, 8.010e+02, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00],\n",
       "       [1.790e+02, 7.300e+01, 9.000e+00, ..., 0.000e+00, 0.000e+00,\n",
       "        0.000e+00]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pos_int_tweets_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XuA22MO1-MO"
   },
   "outputs": [],
   "source": [
    "pos_true_labels = np.ones(len(train_pos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8jRdwRa2LM1",
    "outputId": "0c3d6abd-9744-4795-d9b7-637ee2ce0e2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paAWLZ_Y2LQe",
    "outputId": "f56db6e4-6f74-45bd-8ede-128aa8e44918"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000,)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_true_labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yagynXO-10zQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AUQWV3TbxEcm"
   },
   "outputs": [],
   "source": [
    "all_neg_int_tweets = []\n",
    "\n",
    "for i in range(len(train_neg)):\n",
    "  current_tweet = tweet_to_tensor(train_neg[i], Vocab)\n",
    "  all_neg_int_tweets.append(current_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0O_55m_1TgW",
    "outputId": "fd9a2bd6-104d-412f-861d-a746cb448830"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5736, 2900, 3760]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_int_tweets[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cx0j1vj11Tim",
    "outputId": "b7c77e5b-6916-44ea-d97c-8992a9d0e9b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 60)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_int_tweets_matrix = np.zeros((len(train_neg), 60))\n",
    "all_neg_int_tweets_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSehWLVe1TlG"
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_neg_int_tweets)):\n",
    "  all_neg_int_tweets_matrix[i, :len(all_neg_int_tweets[i])] = all_neg_int_tweets[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnqeM4ue1Tnb",
    "outputId": "5869a6ea-5582-4519-8778-5698d2a0ba24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5736., 2900., 3760., ...,    0.,    0.,    0.],\n",
       "       [ 857.,  255., 3651., ...,    0.,    0.,    0.],\n",
       "       [1035., 5738., 1428., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [ 363.,  308.,  976., ...,    0.,    0.,    0.],\n",
       "       [ 134., 1594.,  222., ...,    0.,    0.,    0.],\n",
       "       [  37., 1308.,  117., ...,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_int_tweets_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJNpfuh91Tp3",
    "outputId": "8e042692-65d9-4459-9607-ee6ed56bfa1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 60)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_neg_int_tweets_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vM7aLj8R1TsV"
   },
   "outputs": [],
   "source": [
    "neg_true_labels = np.zeros(len(train_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4H0mvh6g1Tud",
    "outputId": "ebad0185-d8cb-4844-c67a-8502092f437b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_true_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOq8Q_K5FY7X"
   },
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NINjkFlnRcnh",
    "outputId": "f8d1d133-6217-48b1-98f7-40b52ad06ce3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-eUIAXmRh5G",
    "outputId": "2ef7d9ad-fb3d-4eb7-c6dd-84c65aac81d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vat44Ppl1TyG"
   },
   "outputs": [],
   "source": [
    "def list_of_sentences_to_numpy_sequences(list_of_sentences, vocab, labels_of_sentences):\n",
    "\n",
    "  len_of_list_of_sentences = len(list_of_sentences)\n",
    "\n",
    "  # extracting the length of largest sequence\n",
    "  max_len = 0\n",
    "  for i in range(len_of_list_of_sentences):\n",
    "    current_len = len(tweet_to_tensor(list_of_sentences[i], vocab))\n",
    "    if current_len > max_len:\n",
    "      max_len = current_len\n",
    "\n",
    "\n",
    "  #\n",
    "  all_int_sequences = []\n",
    "  for i in range(len_of_list_of_sentences):\n",
    "    current_tweet = tweet_to_tensor(list_of_sentences[i], vocab)\n",
    "    all_int_sequences.append(current_tweet)\n",
    "\n",
    "\n",
    "  all_int_sequences_matrix = np.zeros((len(list_of_sentences), max_len))\n",
    "\n",
    "  for i in range(len_of_list_of_sentences):\n",
    "    all_int_sequences_matrix[i, :len(all_int_sequences[i])] = all_int_sequences[i]\n",
    "\n",
    "    # labels_of_sentences = int(label_of_sentences)\n",
    "\n",
    "    # labels = np.full(len_of_list_of_sentences, fill_value=label_of_sentences)                      # np.full(shape, fill_value, dtype=None, order='C')\n",
    "\n",
    "#  return max_len, all_int_sequences, all_int_sequences_matrix, labels_of_sentences\n",
    "  return all_int_sequences_matrix, labels_of_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cwq209W8JbTi",
    "outputId": "39a8e88b-5228-486c-f4d2-403257c67ef7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51,\n",
       " 8000,\n",
       " array([[   3.,    4.,    5., ...,    0.,    0.,    0.],\n",
       "        [  10.,   11.,   12., ...,    0.,    0.,    0.],\n",
       "        [  23.,   24.,   25., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [ 363.,  308.,  976., ...,    0.,    0.,    0.],\n",
       "        [ 134., 1594.,  222., ...,    0.,    0.,    0.],\n",
       "        [  37., 1308.,  117., ...,    0.,    0.,    0.]]),\n",
       " array([1., 1., 1., ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a, b, c, d = list_of_sentences_to_numpy_sequences(train_x, Vocab, train_y)\n",
    "\n",
    "# a, len(b), c, d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAo1F7hDxEfV",
    "outputId": "508357d9-e1ec-4a07-f774-9a1218834b3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c[0,:] == all_pos_int_tweets_matrix[0,:51]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvirgF6mxEh4",
    "outputId": "f29a9c83-5a06-4181-d865-e4963143e7cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c[1000,:] == all_pos_int_tweets_matrix[1000,:51]\n",
    "# #perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mPwTI32dxEkL",
    "outputId": "237b6903-2e46-425a-91a5-ba26dd240c8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d[:4001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L56HvVW8S0Xm",
    "outputId": "a657a9be-8fbe-4f7f-aebb-d9124fc2e1c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 0.])"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_y[:4001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UaVqTXdRxEmV",
    "outputId": "804134f0-7f6d-44e5-dc3e-712c7695fd98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-IKGC0xNDlK"
   },
   "outputs": [],
   "source": [
    "# neg_true_labels\n",
    "# pos_true_labels\n",
    "\n",
    "# all_neg_int_tweets_matrix\n",
    "# all_pos_int_tweets_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWArATAKNDnQ"
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = list_of_sentences_to_numpy_sequences(train_x, Vocab, train_y)\n",
    "# train_neg_int_tweets_matrix, train_neg_labels = list_of_sentences_to_numpy_sequences(train_neg, Vocab, 0)\n",
    "\n",
    "val_X, val_Y = list_of_sentences_to_numpy_sequences(val_x, Vocab, val_y)\n",
    "# val_neg_int_tweets_matrix, val_neg_labels = list_of_sentences_to_numpy_sequences(val_neg, Vocab, 0)\n",
    "\n",
    "# test data bnaya hi nahi, bas train and val hay\n",
    "# test_pos_int_tweets_matrix, test_pos_labels = list_of_sentences_to_numpy_sequences(test_pos, Vocab, 1)\n",
    "# test_neg_int_tweets_matrix, test_neg_labels = list_of_sentences_to_numpy_sequences(test_neg, Vocab, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obQ4LoaGNDpy",
    "outputId": "d57addbe-754a-440e-9856-b58022e17aab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, (8000, 51))"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y), train_X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQ4atKcjPVvw",
    "outputId": "b943a8d3-47a1-4814-9c6c-5b493d8acfcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, (2000, 31))"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_X), val_X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FogSqyWdNDsY",
    "outputId": "0651a1e7-0fbf-4374-c37e-97845cec1f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, (1000, 31))"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(val_pos_labels), val_pos_int_tweets_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kV76GntNDu3",
    "outputId": "09bf64a5-dd96-498e-f9f0-2cd52be993db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, (1000, 24))"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(val_neg_labels), val_neg_int_tweets_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PKvPKNUrNDxN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_ItTL0QNDzg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRXwJ0t6ND17"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYJx4uNwND4V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgYIrGOKND6l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhKco5k5ND8-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35YHeFPuND_l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZECt1mqyNEC3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDvPgy5-vUQo"
   },
   "source": [
    "# Creating custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHalVjpBxaED"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# Define the custom ReLU class\n",
    "class Relu(nn.Module):\n",
    "    \"\"\"Relu activation function implementation\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Input:\n",
    "            - x (a torch.Tensor): the input tensor\n",
    "        Output:\n",
    "            - activation (torch.Tensor): all positive or 0 version of x\n",
    "        '''\n",
    "        ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "\n",
    "        activation = torch.maximum(x, torch.tensor(0.0))\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        return activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cP66ict3x-U"
   },
   "source": [
    "### Explanation\n",
    "1. **Custom ReLU Class**: Define a class `Relu` that inherits from `nn.Module`. This class implements the ReLU activation function.\n",
    "2. **Forward Method**: The `forward` method takes a tensor `x` as input and applies the ReLU function using `torch.maximum`.\n",
    "3. **Testing**: Create a sample tensor `x`, instantiate the `Relu` class, and print the output after applying the custom ReLU function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_mDKBEL2_aG",
    "outputId": "7695261e-132b-4ad2-c035-a86182bed1c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data is:\n",
      "tensor([[-2., -1.,  0.],\n",
      "        [ 0.,  1.,  2.]], dtype=torch.float64)\n",
      "Output of Relu is:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 1., 2.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Test your relu function\n",
    "\n",
    "x = np.array([[-2.0, -1.0, 0.0], [0.0, 1.0, 2.0]], dtype=float)\n",
    "x = torch.from_numpy(x)\n",
    "\n",
    "relu_layer = Relu()\n",
    "print(\"Test data is:\")\n",
    "print(x)\n",
    "print(\"Output of Relu is:\")\n",
    "print(relu_layer(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rf0h6orpBXbG",
    "outputId": "297dc1f1-24eb-4846-bafc-7cc1137a233b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a matrix with 2 rows and 3 columns\n",
      "(2, 3)\n",
      "Weight matrix generated with a normal distribution with mean 0 and stdev of 1\n",
      "tensor([[ 0.6614,  0.2669,  0.0617],\n",
      "        [ 0.6213, -0.4519, -0.1661]])\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "\n",
    "print(\"Choose a matrix with 2 rows and 3 columns\")\n",
    "tmp_shape = (2, 3)\n",
    "print(tmp_shape)\n",
    "\n",
    "# Generate a specific random generator\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(1)  # Seed the generator\n",
    "\n",
    "# Generate a weight matrix with a normal distribution (mean=0, std=1) using the generator\n",
    "tmp_weight = torch.randn(tmp_shape, generator=generator)\n",
    "\n",
    "print(\"Weight matrix generated with a normal distribution with mean 0 and stdev of 1\")\n",
    "print(tmp_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCjYr5mHDWfM",
    "outputId": "c6a75b80-698f-4110-9557-853a26448db6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6614,  0.2669,  0.0617],\n",
       "        [ 0.6213, -0.4519, -0.1661]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 2\n",
    "generator.manual_seed(1)  # Reset the seed\n",
    "# This ensures that the random numbers generated are the\n",
    "# same every time you reset the seed of the generator before generating the tensor.\n",
    "\n",
    "\n",
    "tmp_weight_2 = torch.randn(tmp_shape, generator=generator)\n",
    "tmp_weight_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt66mmNA3BTB"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qlXcQo-7AIC"
   },
   "source": [
    "Define the Dense class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zObe_WJD64Ro"
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \"\"\"\n",
    "    A dense (fully-connected) layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_units, init_stdev=0.1):\n",
    "        super(Dense, self).__init__()\n",
    "\n",
    "        # Set the number of units in this layer\n",
    "        self._n_units    = n_units\n",
    "        self._init_stdev = init_stdev\n",
    "#        self.weights = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Matrix multiply x and the weight matrix\n",
    "        return torch.matmul(x, self.weights)\n",
    "\n",
    "    def init_weights_and_state(self, input_signature, generator):\n",
    "        # The input_signature has a .shape attribute that gives the shape as a tuple\n",
    "        input_shape = input_signature.shape\n",
    "\n",
    "        # Generate the weight matrix from a normal distribution, with standard deviation of 'stdev'\n",
    "        w = self._init_stdev * torch.randn((input_shape[-1], self._n_units), generator=generator)\n",
    "\n",
    "        self.weights = w                   #nn.Parameter(w)  # Convert weights to a parameter so that they are trainable\n",
    "\n",
    "        return self.weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7psZrGvveikg"
   },
   "source": [
    "### from chat gpt\n",
    "\n",
    "In Python, when you define a class that inherits from another class, it‚Äôs important to call the parent class‚Äôs initialization method. This is done using super(). In the context of PyTorch's nn.Module, here‚Äôs why calling super(Dense, self).__init__() is necessary:\n",
    "Why Call super() in PyTorch Modules\n",
    "\n",
    "    Initialization of Parent Class (nn.Module):\n",
    "        Base Functionality: nn.Module provides essential functionality for all neural network layers in PyTorch, including parameter management, device handling, and state dict management.\n",
    "        Internal Mechanisms: The __init__ method of nn.Module initializes internal data structures and mechanisms needed for PyTorch to properly manage and train the network.\n",
    "\n",
    "    Registering Submodules and Parameters:\n",
    "        Parameter Registration: By calling super().__init__(), the parent class's initialization code ensures that any parameters or submodules you define in your class are properly registered with PyTorch‚Äôs internal mechanisms. This is crucial for the parameters to be included in the model‚Äôs list of parameters for optimization and gradient computation.\n",
    "        Hooks and Other Features: PyTorch‚Äôs nn.Module also sets up hooks and other features needed for model training and evaluation. Calling super().__init__() ensures these features are properly initialized.\n",
    "\n",
    "    Consistency and Best Practices:\n",
    "        Consistent Behavior: By calling super().__init__(), you ensure that your custom module behaves consistently with other PyTorch modules. This helps avoid issues that might arise from incomplete initialization.\n",
    "        Avoiding Bugs: Failing to call super().__init__() can lead to bugs and unexpected behavior, as the base class‚Äôs initialization code might not run, leaving the object in an incomplete state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_u0rr9S7RYd"
   },
   "source": [
    " Testing Dense Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZEqzZuC7E9G",
    "outputId": "2fd2a624-455b-4eea-ab1a-8f42cc30b4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights are\n",
      " tensor([[-0.1526, -0.0750, -0.0654, -0.1609, -0.0100, -0.0609, -0.0980, -0.1609,\n",
      "         -0.0712,  0.0304],\n",
      "        [-0.0777, -0.0251, -0.0222,  0.1687, -0.0321, -0.0299,  0.1879, -0.0072,\n",
      "          0.0158, -0.0773],\n",
      "        [ 0.0199,  0.0046, -0.1392,  0.2689, -0.0111,  0.0293, -0.0158, -0.0029,\n",
      "          0.2357, -0.1037]])\n",
      "Forward function output is tensor([[-0.3516, -0.2118, -3.7673,  7.5818, -0.5220,  0.4005,  0.7250, -0.4443,\n",
      "          5.8608, -3.0740]])\n"
     ]
    }
   ],
   "source": [
    "# Define the Dense layer with a specified number of units\n",
    "dense_layer = Dense(n_units=10)  # Sets number of units in dense layer\n",
    "\n",
    "generator.manual_seed(1)\n",
    "# Define the input tensor\n",
    "z = torch.tensor([[2.0, 7.0, 25.0]])  # Input array\n",
    "\n",
    "# Initialize weights\n",
    "dense_layer.init_weights_and_state(z, generator)\n",
    "\n",
    "# Print the weights\n",
    "print(\"Weights are\\n\", dense_layer.weights)\n",
    "\n",
    "# Forward pass\n",
    "output = dense_layer(z)\n",
    "\n",
    "# Print the forward function output\n",
    "print(\"Forward function output is\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMRy31KZ7DDc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b6kn0097DPE",
    "outputId": "1164247d-706b-42d7-d0fc-46974a6ce752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor:\n",
      " tensor([[-11.9407,  -9.6725,  13.0987, -10.7307, -15.5369,   2.3867,  -0.9074,\n",
      "         -14.1406,  -7.2472,   9.6960],\n",
      "        [ -1.6553,  -2.2163,   1.4720,  -1.5027,  -2.3124,   0.6033,  -0.3181,\n",
      "          -1.9201,  -0.9589,   0.9671]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# Define a Linear layer\n",
    "linear_layer = nn.Linear(in_features=3, out_features=10)\n",
    "\n",
    "# Example input tensor\n",
    "input_tensor = torch.tensor([[2.0, 7.0, 25.0], [1,2,3]])\n",
    "\n",
    "# Get the output tensor\n",
    "output_tensor = linear_layer(input_tensor)\n",
    "\n",
    "print(\"Output tensor:\\n\", output_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5pTYuQDvtWk"
   },
   "source": [
    "### Testing against assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZeq6-dyNSLb"
   },
   "outputs": [],
   "source": [
    "# dense_layer.weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LyCuyR2H7ijX"
   },
   "outputs": [],
   "source": [
    "# # import torch\n",
    "# # import torch.nn as nn\n",
    "\n",
    "# class Dense(nn.Module):\n",
    "#     \"\"\"\n",
    "#     A dense (fully-connected) layer.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, n_units, init_stdev=0.1):\n",
    "#         super(Dense, self).__init__()\n",
    "\n",
    "#         # Set the number of units in this layer\n",
    "#         self._n_units = n_units\n",
    "#         self._init_stdev = init_stdev\n",
    "# #        self.weights = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Matrix multiply x and the weight matrix\n",
    "#         return torch.matmul(x, self.weights)\n",
    "\n",
    "#     def init_weights_and_state(self, w):\n",
    "#         self.weights = w\n",
    "\n",
    "#         return self.weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuSG4yS8M1AS"
   },
   "outputs": [],
   "source": [
    "w = torch.tensor([[-0.02837107,  0.09368163, -0.10050073,  0.14165013,  0.10543301,0.09108127, -0.04265671,  0.0986188 , -0.05575324,  0.0015325 ],\n",
    "       [-0.2078568 ,  0.05548371,  0.09142365,  0.05744596,  0.07227863, 0.01210618, -0.03237354,  0.16234998,  0.02450039, -0.13809781],\n",
    "       [-0.06111237,  0.01403725,  0.08410043, -0.10943579, -0.1077502 , -0.11396457, -0.0593338 , -0.01557651, -0.03832145, -0.11144515]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACdNYcA0NJbo"
   },
   "outputs": [],
   "source": [
    "# w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qefm24-1NKaQ"
   },
   "outputs": [],
   "source": [
    "# # Define the Dense layer with a specified number of units\n",
    "# dense_layer = Dense(n_units=10)  # Sets number of units in dense layer\n",
    "\n",
    "# # Initialize weights\n",
    "# dense_layer.init_weights_and_state(w)\n",
    "\n",
    "# # Print the weights\n",
    "# print(\"Weights are\\n\", dense_layer.weights)\n",
    "\n",
    "# # Forward pass\n",
    "# output = dense_layer(z)\n",
    "\n",
    "# # Print the forward function output\n",
    "# print(\"Forward function output is\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrb7fHanfOEv"
   },
   "source": [
    "## Model\n",
    "\n",
    "Now you will implement a classifier using neural networks. Here is the model architecture you will be implementing.\n",
    "\n",
    "<img src = \"nn.jpg\" style=\"width:400px;height:250px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "Please use the `help` function to view documentation for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YjxYJhmINoBW",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a6a4d346-2246-464c-b785-2ca9cd1fae22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Linear in module torch.nn.modules.linear:\n",
      "\n",
      "class Linear(torch.nn.modules.module.Module)\n",
      " |  Linear(in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None\n",
      " |  \n",
      " |  Applies a linear transformation to the incoming data: :math:`y = xA^T + b`.\n",
      " |  \n",
      " |  This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
      " |  \n",
      " |  On certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n",
      " |  \n",
      " |  Args:\n",
      " |      in_features: size of each input sample\n",
      " |      out_features: size of each output sample\n",
      " |      bias: If set to ``False``, the layer will not learn an additive bias.\n",
      " |          Default: ``True``\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
      " |        dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
      " |      - Output: :math:`(*, H_{out})` where all but the last dimension\n",
      " |        are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight: the learnable weights of the module of shape\n",
      " |          :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
      " |          initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
      " |          :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      " |      bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
      " |              If :attr:`bias` is ``True``, the values are initialized from\n",
      " |              :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      " |              :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.Linear(20, 30)\n",
      " |      >>> input = torch.randn(128, 20)\n",
      " |      >>> output = m(input)\n",
      " |      >>> print(output.size())\n",
      " |      torch.Size([128, 30])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Linear\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None) -> None\n",
      " |      Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module.\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Define the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'in_features': <class 'int'>, 'out_features': <clas...\n",
      " |  \n",
      " |  __constants__ = ['in_features', 'out_features']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Any\n",
      " |      # On the return type:\n",
      " |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n",
      " |      # This is done for better interop with various type checkers for the end users.\n",
      " |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n",
      " |      # people to excessively use type-ignores, asserts, casts, etc.\n",
      " |      # See full discussion on the problems with returning `Union` here\n",
      " |      # https://github.com/microsoft/pyright/issues/4213\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Add a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\n",
      " |      \n",
      " |      Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Return an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |      \n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |      \n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Move all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Set the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Return the buffer given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Return any extra state to include in the module's state_dict.\n",
      " |      \n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Return the parameter given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Return the submodule given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n",
      " |      Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\n",
      " |      \n",
      " |      If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict` unless\n",
      " |          :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): When ``False``, the properties of the tensors\n",
      " |              in the current module are preserved while when ``True``, the\n",
      " |              properties of the Tensors in the state dict are preserved. The only\n",
      " |              exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s\n",
      " |              for which the value from the module is preserved.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Return an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Add a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Register a post hook to be run after module's ``load_state_dict`` is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Add a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      Register a pre-hook for the :meth:`~torch.nn.Module.state_dict` method.\n",
      " |      \n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any) -> None\n",
      " |      Set extra state contained in the loaded `state_dict`.\n",
      " |      \n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`.\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Return a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Move and/or cast the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[int, str, torch.device, NoneType], recurse: bool = True) -> ~T\n",
      " |      Move the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Set the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Reset gradients of all model parameters.\n",
      " |      \n",
      " |      See similar function under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View documentation on nn.Linear\n",
    "help(nn.Linear)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "oqPQEb6wgvZd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3a0bf4fc-5930-4bd2-9b70-0770ee71a2a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Embedding in module torch.nn.modules.sparse:\n",
      "\n",
      "class Embedding(torch.nn.modules.module.Module)\n",
      " |  Embedding(num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, _freeze: bool = False, device=None, dtype=None) -> None\n",
      " |  \n",
      " |  A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
      " |  \n",
      " |  This module is often used to store word embeddings and retrieve them using indices.\n",
      " |  The input to the module is a list of indices, and the output is the corresponding\n",
      " |  word embeddings.\n",
      " |  \n",
      " |  Args:\n",
      " |      num_embeddings (int): size of the dictionary of embeddings\n",
      " |      embedding_dim (int): the size of each embedding vector\n",
      " |      padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      " |                                   therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      " |                                   i.e. it remains as a fixed \"pad\". For a newly constructed Embedding,\n",
      " |                                   the embedding vector at :attr:`padding_idx` will default to all zeros,\n",
      " |                                   but can be updated to another value to be used as the padding vector.\n",
      " |      max_norm (float, optional): If given, each embedding vector with norm larger than :attr:`max_norm`\n",
      " |                                  is renormalized to have norm :attr:`max_norm`.\n",
      " |      norm_type (float, optional): The p of the p-norm to compute for the :attr:`max_norm` option. Default ``2``.\n",
      " |      scale_grad_by_freq (bool, optional): If given, this will scale gradients by the inverse of frequency of\n",
      " |                                              the words in the mini-batch. Default ``False``.\n",
      " |      sparse (bool, optional): If ``True``, gradient w.r.t. :attr:`weight` matrix will be a sparse tensor.\n",
      " |                               See Notes for more details regarding sparse gradients.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      weight (Tensor): the learnable weights of the module of shape (num_embeddings, embedding_dim)\n",
      " |                       initialized from :math:`\\mathcal{N}(0, 1)`\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*)`, IntTensor or LongTensor of arbitrary shape containing the indices to extract\n",
      " |      - Output: :math:`(*, H)`, where `*` is the input shape and :math:`H=\\text{embedding\\_dim}`\n",
      " |  \n",
      " |  .. note::\n",
      " |      Keep in mind that only a limited number of optimizers support\n",
      " |      sparse gradients: currently it's :class:`optim.SGD` (`CUDA` and `CPU`),\n",
      " |      :class:`optim.SparseAdam` (`CUDA` and `CPU`) and :class:`optim.Adagrad` (`CPU`)\n",
      " |  \n",
      " |  .. note::\n",
      " |      When :attr:`max_norm` is not ``None``, :class:`Embedding`'s forward method will modify the\n",
      " |      :attr:`weight` tensor in-place. Since tensors needed for gradient computations cannot be\n",
      " |      modified in-place, performing a differentiable operation on ``Embedding.weight`` before\n",
      " |      calling :class:`Embedding`'s forward method requires cloning ``Embedding.weight`` when\n",
      " |      :attr:`max_norm` is not ``None``. For example::\n",
      " |  \n",
      " |          n, d, m = 3, 5, 7\n",
      " |          embedding = nn.Embedding(n, d, max_norm=True)\n",
      " |          W = torch.randn((m, d), requires_grad=True)\n",
      " |          idx = torch.tensor([1, 2])\n",
      " |          a = embedding.weight.clone() @ W.t()  # weight must be cloned for this to be differentiable\n",
      " |          b = embedding(idx) @ W.t()  # modifies weight in-place\n",
      " |          out = (a.unsqueeze(0) + b.unsqueeze(1))\n",
      " |          loss = out.sigmoid().prod()\n",
      " |          loss.backward()\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> # an Embedding module containing 10 tensors of size 3\n",
      " |      >>> embedding = nn.Embedding(10, 3)\n",
      " |      >>> # a batch of 2 samples of 4 indices each\n",
      " |      >>> input = torch.LongTensor([[1, 2, 4, 5], [4, 3, 2, 9]])\n",
      " |      >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[-0.0251, -1.6902,  0.7172],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 1.4970,  1.3448, -0.9685],\n",
      " |               [-0.3677, -2.7265, -0.1685]],\n",
      " |  \n",
      " |              [[ 1.4970,  1.3448, -0.9685],\n",
      " |               [ 0.4362, -0.4004,  0.9400],\n",
      " |               [-0.6431,  0.0748,  0.6969],\n",
      " |               [ 0.9124, -2.3616,  1.1151]]])\n",
      " |  \n",
      " |  \n",
      " |      >>> # example with padding_idx\n",
      " |      >>> embedding = nn.Embedding(10, 3, padding_idx=0)\n",
      " |      >>> input = torch.LongTensor([[0, 2, 0, 5]])\n",
      " |      >>> embedding(input)\n",
      " |      tensor([[[ 0.0000,  0.0000,  0.0000],\n",
      " |               [ 0.1535, -2.0309,  0.9315],\n",
      " |               [ 0.0000,  0.0000,  0.0000],\n",
      " |               [-0.1655,  0.9897,  0.0635]]])\n",
      " |  \n",
      " |      >>> # example of changing `pad` vector\n",
      " |      >>> padding_idx = 0\n",
      " |      >>> embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
      " |      >>> embedding.weight\n",
      " |      Parameter containing:\n",
      " |      tensor([[ 0.0000,  0.0000,  0.0000],\n",
      " |              [-0.7895, -0.7089, -0.0364],\n",
      " |              [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      " |      >>> with torch.no_grad():\n",
      " |      ...     embedding.weight[padding_idx] = torch.ones(3)\n",
      " |      >>> embedding.weight\n",
      " |      Parameter containing:\n",
      " |      tensor([[ 1.0000,  1.0000,  1.0000],\n",
      " |              [-0.7895, -0.7089, -0.0364],\n",
      " |              [ 0.6778,  0.5803,  0.2678]], requires_grad=True)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Embedding\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, num_embeddings: int, embedding_dim: int, padding_idx: Optional[int] = None, max_norm: Optional[float] = None, norm_type: float = 2.0, scale_grad_by_freq: bool = False, sparse: bool = False, _weight: Optional[torch.Tensor] = None, _freeze: bool = False, device=None, dtype=None) -> None\n",
      " |      Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module.\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Define the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  reset_parameters(self) -> None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_pretrained(embeddings, freeze=True, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False) from builtins.type\n",
      " |      Create Embedding instance from given 2-dimensional FloatTensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          embeddings (Tensor): FloatTensor containing weights for the Embedding.\n",
      " |              First dimension is being passed to Embedding as ``num_embeddings``, second as ``embedding_dim``.\n",
      " |          freeze (bool, optional): If ``True``, the tensor does not get updated in the learning process.\n",
      " |              Equivalent to ``embedding.weight.requires_grad = False``. Default: ``True``\n",
      " |          padding_idx (int, optional): If specified, the entries at :attr:`padding_idx` do not contribute to the gradient;\n",
      " |                                       therefore, the embedding vector at :attr:`padding_idx` is not updated during training,\n",
      " |                                       i.e. it remains as a fixed \"pad\".\n",
      " |          max_norm (float, optional): See module initialization documentation.\n",
      " |          norm_type (float, optional): See module initialization documentation. Default ``2``.\n",
      " |          scale_grad_by_freq (bool, optional): See module initialization documentation. Default ``False``.\n",
      " |          sparse (bool, optional): See module initialization documentation.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # FloatTensor containing pretrained weights\n",
      " |          >>> weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
      " |          >>> embedding = nn.Embedding.from_pretrained(weight)\n",
      " |          >>> # Get embeddings for index 1\n",
      " |          >>> input = torch.LongTensor([1])\n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> embedding(input)\n",
      " |          tensor([[ 4.0000,  5.1000,  6.3000]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'embedding_dim': <class 'int'>, 'freeze': <class 'b...\n",
      " |  \n",
      " |  __constants__ = ['num_embeddings', 'embedding_dim', 'padding_idx', 'ma...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Any\n",
      " |      # On the return type:\n",
      " |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n",
      " |      # This is done for better interop with various type checkers for the end users.\n",
      " |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n",
      " |      # people to excessively use type-ignores, asserts, casts, etc.\n",
      " |      # See full discussion on the problems with returning `Union` here\n",
      " |      # https://github.com/microsoft/pyright/issues/4213\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Add a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\n",
      " |      \n",
      " |      Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Return an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |      \n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |      \n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Move all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Set the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Return the buffer given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Return any extra state to include in the module's state_dict.\n",
      " |      \n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Return the parameter given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Return the submodule given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n",
      " |      Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\n",
      " |      \n",
      " |      If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict` unless\n",
      " |          :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): When ``False``, the properties of the tensors\n",
      " |              in the current module are preserved while when ``True``, the\n",
      " |              properties of the Tensors in the state dict are preserved. The only\n",
      " |              exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s\n",
      " |              for which the value from the module is preserved.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Return an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Add a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Register a post hook to be run after module's ``load_state_dict`` is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Add a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      Register a pre-hook for the :meth:`~torch.nn.Module.state_dict` method.\n",
      " |      \n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any) -> None\n",
      " |      Set extra state contained in the loaded `state_dict`.\n",
      " |      \n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`.\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Return a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Move and/or cast the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[int, str, torch.device, NoneType], recurse: bool = True) -> ~T\n",
      " |      Move the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Set the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Reset gradients of all model parameters.\n",
      " |      \n",
      " |      See similar function under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# View documentation on nn.Embedding\n",
    "help(nn.Embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAo2Fj5149oP",
    "outputId": "bf8ecbfa-af69-4e68-ab47-e749fd4d34c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output embeddings:\n",
      " tensor([[[ 0.1366, -0.4204, -0.4233],\n",
      "         [-0.2332,  0.7853, -3.5290],\n",
      "         [ 0.5739, -1.1590,  0.8263],\n",
      "         [ 1.1203,  1.0225,  0.4271],\n",
      "         [-1.9306, -0.3250, -0.4264],\n",
      "         [-0.4470, -0.6684, -0.7939],\n",
      "         [-0.0971, -0.6128,  2.5988],\n",
      "         [-1.2032,  1.9522, -0.2459],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577]],\n",
      "\n",
      "        [[ 0.1366, -0.4204, -0.4233],\n",
      "         [-0.2332,  0.7853, -3.5290],\n",
      "         [ 0.5739, -1.1590,  0.8263],\n",
      "         [ 1.1203,  1.0225,  0.4271],\n",
      "         [-1.9306, -0.3250, -0.4264],\n",
      "         [-0.4470, -0.6684, -0.7939],\n",
      "         [-0.0971, -0.6128,  2.5988],\n",
      "         [-1.2032,  1.9522, -0.2459],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577],\n",
      "         [ 1.1688,  1.3003,  0.2577]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# Define an Embedding layer\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)        # num_embeddings: maximum possible unique id integer of a word possible to input\n",
    "\n",
    "# Example input (indices)\n",
    "input_indices = torch.tensor([[1, 2, 3, 4, 5, 6 ,7 ,8,9,9,9,9,9,9], [1, 2, 3, 4, 5, 6 ,7 ,8,9,9,9,9,9,9]])\n",
    "\n",
    "# Get embeddings for the input indices\n",
    "output_embeddings = embedding(input_indices)\n",
    "\n",
    "print(\"Output embeddings:\\n\", output_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "820rzFUZhlDb",
    "outputId": "e3359095-09bf-4399-fa85-9a28b249b24c"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-748-e569b7e3daa2>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Get embeddings for the input indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutput_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output embeddings:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2264\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "# # erro expected\n",
    "\n",
    "# # import torch\n",
    "# # import torch.nn as nn\n",
    "\n",
    "# # Define an Embedding layer\n",
    "# embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)\n",
    "\n",
    "# # Example input (indices)\n",
    "# input_indices = torch.tensor([1,10])    # 10 was not possible!\n",
    "\n",
    "# # Get embeddings for the input indices\n",
    "# output_embeddings = embedding(input_indices)\n",
    "\n",
    "# print(\"Output embeddings:\\n\", output_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdBNWrhTiCPF"
   },
   "source": [
    "- [tl.Mean](https://github.com/google/trax/blob/1372b903bb66b0daccee19fd0b1fdf44f659330b/trax/layers/core.py#L276): Calculates means across an axis.  In this case, please choose axis = 1 to get an average embedding vector (an embedding vector that is an average of all words in the vocabulary).  \n",
    "- For example, if the embedding matrix is 300 elements and vocab size is 10,000 words, taking the mean of the embedding matrix along axis=1 will yield a vector of 300 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgrpYIn2ibiw"
   },
   "outputs": [],
   "source": [
    "# # error expected, pytorch main mean layer nahi hay\n",
    "\n",
    "# # View documentation on nn.Embedding\n",
    "# help(nn.mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mnv2rbyKh0Qq",
    "outputId": "bade4367-ab8a-41e5-e3c3-88cef17f05f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Mean of all elements:\n",
      " tensor(3.5000)\n",
      "Mean along dimension 0:\n",
      " tensor([2.5000, 3.5000, 4.5000])\n",
      "Mean along dimension 1:\n",
      " tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# Create a sample tensor\n",
    "tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(tensor)\n",
    "\n",
    "# Compute the mean of the tensor along a specified dimension\n",
    "mean_all  = torch.mean(tensor)                # Mean of all elements\n",
    "mean_dim0 = torch.mean(tensor, dim=0)        # Mean along the rows (dimension 0)\n",
    "mean_dim1 = torch.mean(tensor, dim=1)        # Mean along the columns (dimension 1)\n",
    "\n",
    "\n",
    "print(\"Mean of all elements:\\n\", mean_all)\n",
    "print(\"Mean along dimension 0:\\n\", mean_dim0)\n",
    "print(\"Mean along dimension 1:\\n\", mean_dim1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ybi8ML3wkU3",
    "outputId": "d2479d65-ae6d-4dec-bd40-ffecf7272332"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkphLyxTwwBH",
    "outputId": "437c9edf-4f86-4454-aafe-9606ab94cca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 3.5000, 4.5000])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.mean(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_G5nCXtbl9UJ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "36572e9c-d392-4287-b70f-1d78c8400aaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogSoftmax in module torch.nn.modules.activation object:\n",
      "\n",
      "class LogSoftmax(torch.nn.modules.module.Module)\n",
      " |  LogSoftmax(dim: Optional[int] = None) -> None\n",
      " |  \n",
      " |  Applies the :math:`\\log(\\text{Softmax}(x))` function to an n-dimensional input Tensor.\n",
      " |  \n",
      " |  The LogSoftmax formulation can be simplified as:\n",
      " |  \n",
      " |  .. math::\n",
      " |      \\text{LogSoftmax}(x_{i}) = \\log\\left(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} \\right)\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*)` where `*` means, any number of additional\n",
      " |        dimensions\n",
      " |      - Output: :math:`(*)`, same shape as the input\n",
      " |  \n",
      " |  Args:\n",
      " |      dim (int): A dimension along which LogSoftmax will be computed.\n",
      " |  \n",
      " |  Returns:\n",
      " |      a Tensor of the same dimension and shape as the input with\n",
      " |      values in the range [-inf, 0)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.LogSoftmax(dim=1)\n",
      " |      >>> input = torch.randn(2, 3)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogSoftmax\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, dim: Optional[int] = None) -> None\n",
      " |      Initialize internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module.\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Define the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'dim': typing.Optional[int]}\n",
      " |  \n",
      " |  __constants__ = ['dim']\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _wrapped_call_impl(self, *args, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Any\n",
      " |      # On the return type:\n",
      " |      # We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\n",
      " |      # This is done for better interop with various type checkers for the end users.\n",
      " |      # Having a stricter return type doesn't play nicely with `register_buffer()` and forces\n",
      " |      # people to excessively use type-ignores, asserts, casts, etc.\n",
      " |      # See full discussion on the problems with returning `Union` here\n",
      " |      # https://github.com/microsoft/pyright/issues/4213\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Add a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\n",
      " |      \n",
      " |      Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[1., 1.],\n",
      " |                  [1., 1.]], requires_grad=True)\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Return an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  compile(self, *args, **kwargs)\n",
      " |      Compile this Module's forward using :func:`torch.compile`.\n",
      " |      \n",
      " |      This Module's `__call__` method is compiled and all arguments are passed as-is\n",
      " |      to :func:`torch.compile`.\n",
      " |      \n",
      " |      See :func:`torch.compile` for details on the arguments for this function.\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Move all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Set the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Return the buffer given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Return any extra state to include in the module's state_dict.\n",
      " |      \n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be picklable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Return the parameter given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Return the submodule given by ``target`` if it exists, otherwise throw an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block:: text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  ipu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the IPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on IPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Mapping[str, Any], strict: bool = True, assign: bool = False)\n",
      " |      Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\n",
      " |      \n",
      " |      If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          If :attr:`assign` is ``True`` the optimizer must be created after\n",
      " |          the call to :attr:`load_state_dict` unless\n",
      " |          :func:`~torch.__future__.get_swap_module_params_on_conversion` is ``True``.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |          assign (bool, optional): When ``False``, the properties of the tensors\n",
      " |              in the current module are preserved while when ``True``, the\n",
      " |              properties of the Tensors in the state dict are preserved. The only\n",
      " |              exception is the ``requires_grad`` field of :class:`~torch.nn.Parameter`s\n",
      " |              for which the value from the module is preserved.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Return an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Return an iterator over module buffers, yielding both the name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool, optional): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module. Defaults to True.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated buffers in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>     if name in ['running_var']:\n",
      " |          >>>         print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Return an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Return an iterator over all modules in the network, yielding both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          ...     print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True, remove_duplicate: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |          remove_duplicate (bool, optional): whether to remove the duplicated\n",
      " |              parameters in the result. Defaults to True.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (str, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>     if name in ['bias']:\n",
      " |          >>>         print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Return an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Add a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...], Any], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], *, prepend: bool = False, with_kwargs: bool = False, always_call: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``False`` or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      output. It can modify the input inplace but it will not have effect on\n",
      " |      forward since this is called after :func:`forward` is called. The hook\n",
      " |      should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, output) -> None or modified output\n",
      " |      \n",
      " |      If ``with_kwargs`` is ``True``, the forward hook will be passed the\n",
      " |      ``kwargs`` given to the forward function and be expected to return the\n",
      " |      output possibly modified. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs, output) -> None or modified output\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If ``True``, the provided ``hook`` will be fired\n",
      " |              before all existing ``forward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward`` hooks registered with\n",
      " |              :func:`register_module_forward_hook` will fire before all hooks\n",
      " |              registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If ``True``, the ``hook`` will be passed the\n",
      " |              kwargs given to the forward function.\n",
      " |              Default: ``False``\n",
      " |          always_call (bool): If ``True`` the ``hook`` will be run regardless of\n",
      " |              whether an exception is raised while calling the Module.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Union[Callable[[~T, Tuple[Any, ...]], Optional[Any]], Callable[[~T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], *, prepend: bool = False, with_kwargs: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      \n",
      " |      \n",
      " |      If ``with_kwargs`` is false or not specified, the input contains only\n",
      " |      the positional arguments given to the module. Keyword arguments won't be\n",
      " |      passed to the hooks and only to the ``forward``. The hook can modify the\n",
      " |      input. User can either return a tuple or a single modified value in the\n",
      " |      hook. We will wrap the value into a tuple if a single value is returned\n",
      " |      (unless that value is already a tuple). The hook should have the\n",
      " |      following signature::\n",
      " |      \n",
      " |          hook(module, args) -> None or modified input\n",
      " |      \n",
      " |      If ``with_kwargs`` is true, the forward pre-hook will be passed the\n",
      " |      kwargs given to the forward function. And if the hook modifies the\n",
      " |      input, both the args and kwargs should be returned. The hook should have\n",
      " |      the following signature::\n",
      " |      \n",
      " |          hook(module, args, kwargs) -> None or a tuple of modified input and kwargs\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``forward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``forward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``forward_pre`` hooks registered with\n",
      " |              :func:`register_module_forward_pre_hook` will fire before all\n",
      " |              hooks registered by this method.\n",
      " |              Default: ``False``\n",
      " |          with_kwargs (bool): If true, the ``hook`` will be passed the kwargs\n",
      " |              given to the forward function.\n",
      " |              Default: ``False``\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to a module\n",
      " |      are computed, i.e. the hook will execute if and only if the gradients with\n",
      " |      respect to module outputs are computed. The hook should have the following\n",
      " |      signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward`` hooks on\n",
      " |              this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward`` hooks registered with\n",
      " |              :func:`register_module_full_backward_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_pre_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, Tuple[torch.Tensor, ...], torch.Tensor]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
      " |      Register a backward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients for the module are computed.\n",
      " |      The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_output) -> tuple[Tensor] or None\n",
      " |      \n",
      " |      The :attr:`grad_output` is a tuple. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the output that will be used in place of :attr:`grad_output` in\n",
      " |      subsequent computations. Entries in :attr:`grad_output` will be ``None`` for\n",
      " |      all non-Tensor arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Args:\n",
      " |          hook (Callable): The user-defined hook to be registered.\n",
      " |          prepend (bool): If true, the provided ``hook`` will be fired before\n",
      " |              all existing ``backward_pre`` hooks on this\n",
      " |              :class:`torch.nn.modules.Module`. Otherwise, the provided\n",
      " |              ``hook`` will be fired after all existing ``backward_pre`` hooks\n",
      " |              on this :class:`torch.nn.modules.Module`. Note that global\n",
      " |              ``backward_pre`` hooks registered with\n",
      " |              :func:`register_module_full_backward_pre_hook` will fire before\n",
      " |              all hooks registered by this method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_load_state_dict_post_hook(self, hook)\n",
      " |      Register a post hook to be run after module's ``load_state_dict`` is called.\n",
      " |      \n",
      " |      It should have the following signature::\n",
      " |          hook(module, incompatible_keys) -> None\n",
      " |      \n",
      " |      The ``module`` argument is the current module that this hook is registered\n",
      " |      on, and the ``incompatible_keys`` argument is a ``NamedTuple`` consisting\n",
      " |      of attributes ``missing_keys`` and ``unexpected_keys``. ``missing_keys``\n",
      " |      is a ``list`` of ``str`` containing the missing keys and\n",
      " |      ``unexpected_keys`` is a ``list`` of ``str`` containing the unexpected keys.\n",
      " |      \n",
      " |      The given incompatible_keys can be modified inplace if needed.\n",
      " |      \n",
      " |      Note that the checks performed when calling :func:`load_state_dict` with\n",
      " |      ``strict=True`` are affected by modifications the hook makes to\n",
      " |      ``missing_keys`` or ``unexpected_keys``, as expected. Additions to either\n",
      " |      set of keys will result in an error being thrown when ``strict=True``, and\n",
      " |      clearing out both missing and unexpected keys will avoid an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Add a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (str): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  register_state_dict_pre_hook(self, hook)\n",
      " |      Register a pre-hook for the :meth:`~torch.nn.Module.state_dict` method.\n",
      " |      \n",
      " |      These hooks will be called with arguments: ``self``, ``prefix``,\n",
      " |      and ``keep_vars`` before calling ``state_dict`` on ``self``. The registered\n",
      " |      hooks can be used to perform pre-processing before the ``state_dict``\n",
      " |      call is made.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any) -> None\n",
      " |      Set extra state contained in the loaded `state_dict`.\n",
      " |      \n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`.\n",
      " |  \n",
      " |  state_dict(self, *args, destination=None, prefix='', keep_vars=False)\n",
      " |      Return a dictionary containing references to the whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      .. note::\n",
      " |          The returned object is a shallow copy. It contains references\n",
      " |          to the module's parameters and buffers.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Currently ``state_dict()`` also accepts positional arguments for\n",
      " |          ``destination``, ``prefix`` and ``keep_vars`` in order. However,\n",
      " |          this is being deprecated and keyword arguments will be enforced in\n",
      " |          future releases.\n",
      " |      \n",
      " |      .. warning::\n",
      " |          Please avoid the use of argument ``destination`` as it is not\n",
      " |          designed for end-users.\n",
      " |      \n",
      " |      Args:\n",
      " |          destination (dict, optional): If provided, the state of module will\n",
      " |              be updated into the dict and the same object is returned.\n",
      " |              Otherwise, an ``OrderedDict`` will be created and returned.\n",
      " |              Default: ``None``.\n",
      " |          prefix (str, optional): a prefix added to parameter and buffer\n",
      " |              names to compose the keys in state_dict. Default: ``''``.\n",
      " |          keep_vars (bool, optional): by default the :class:`~torch.Tensor` s\n",
      " |              returned in the state dict are detached from autograd. If it's\n",
      " |              set to ``True``, detaching will not be performed.\n",
      " |              Default: ``False``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Move and/or cast the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> # xdoctest: +IGNORE_WANT(\"non-deterministic\")\n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> # xdoctest: +REQUIRES(env:TORCH_DOCTEST_CUDA1)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[int, str, torch.device, NoneType], recurse: bool = True) -> ~T\n",
      " |      Move the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |          recurse (bool): Whether parameters and buffers of submodules should\n",
      " |              be recursively moved to the specified device.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Set the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Move all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = True) -> None\n",
      " |      Reset gradients of all model parameters.\n",
      " |      \n",
      " |      See similar function under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  call_super_init = False\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5at_TjXzZim"
   },
   "source": [
    "# Creating the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlfBKX450E02"
   },
   "source": [
    "### Creating generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "ofWo_spD4mAc",
    "outputId": "edd1dc22-3484-4c2b-de41-e9a212ff2697"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_pos_int_tweets_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-907cc418f936>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Combine positive and negative samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mall_tweets_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_pos_int_tweets_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_neg_int_tweets_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_true_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_true_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_pos_int_tweets_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Combine positive and negative samples\n",
    "all_tweets_matrix = np.concatenate((all_pos_int_tweets_matrix, all_neg_int_tweets_matrix), axis=0)\n",
    "all_labels = np.concatenate((pos_true_labels, neg_true_labels), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tweets_tensor = torch.tensor(all_tweets_matrix, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(all_labels, dtype=torch.long)\n",
    "\n",
    "# Create a dataset and dataloader\n",
    "dataset = TensorDataset(tweets_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3wHh94czz0wY",
    "outputId": "239af5f7-dbb8-484d-af04-ea59f659ecc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 60)"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjTdzLhiCS9j",
    "outputId": "26b44eee-a83e-4109-ba64-afc4404b6276"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRzQbvtPCS_9",
    "outputId": "65f578a2-f737-4e3d-cef6-4f7bc29b49b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7beaba403e20>"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQerKOlACTCl",
    "outputId": "7e19fc97-b1c3-4b48-99f6-f8da81a32f2f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8339, 3760,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset)[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTCnHbCWCTFK",
    "outputId": "54970f85-cfcd-4b34-db9a-9befa1818c23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   7, 2100,    9,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset)[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_Jmz72ZCTHj",
    "outputId": "7606cece-5d51-4ff9-cead-ec1bd3040138"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(dataset)[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etg77ck-CTJ8",
    "outputId": "58f118bb-d717-4dbe-80d2-4a6ea013b50c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7beac2511ae0>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "AE0ePgCcDBh3",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "1bff3304-71da-4198-868f-ba653287f135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[7570,  116, 3760,  ...,    0,    0,    0],\n",
       "          [ 387,  388,  389,  ...,    0,    0,    0],\n",
       "          [ 498, 1392, 1673,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 246,  551, 3510,  ...,    0,    0,    0],\n",
       "          [ 130, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 566,  838,  933,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[ 705,   60, 3227,  ...,    0,    0,    0],\n",
       "          [2724,  566,  352,  ...,    0,    0,    0],\n",
       "          [2597, 8839, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6066, 1613, 1329,  ...,    0,    0,    0],\n",
       "          [ 458,  873, 5679,  ...,    0,    0,    0],\n",
       "          [ 599,  319, 1868,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[1001,    9,    0,  ...,    0,    0,    0],\n",
       "          [  73,    0,    0,  ...,    0,    0,    0],\n",
       "          [2494, 1909,   63,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2573,  136,  100,  ...,    0,    0,    0],\n",
       "          [  50,   38,    9,  ...,    0,    0,    0],\n",
       "          [ 425, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[1007,  134, 3333,  ...,    0,    0,    0],\n",
       "          [2533,  929,    9,  ...,    0,    0,    0],\n",
       "          [ 970,  419,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [  50,  270,  722,  ...,    0,    0,    0],\n",
       "          [2336, 2337,  355,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 1., 0., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[ 487,    9,  488,  ...,    0,    0,    0],\n",
       "          [ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [3305,  327, 1747,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4186, 1943, 3760,  ...,    0,    0,    0],\n",
       "          [7096,  104, 3760,  ...,    0,    0,    0],\n",
       "          [8409,  566,  363,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 0., 0.])],\n",
       " [tensor([[7863, 3219, 3760,  ...,    0,    0,    0],\n",
       "          [ 620, 7361, 4362,  ...,    0,    0,    0],\n",
       "          [1909, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2177,  601,  139,  ...,    0,    0,    0],\n",
       "          [  45,  357, 3760,  ...,    0,    0,    0],\n",
       "          [ 153,  852,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[3760,  620,   54,  ...,    0,    0,    0],\n",
       "          [ 100,   62,  239,  ...,    0,    0,    0],\n",
       "          [ 131, 4670, 4671,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 566,  889,  855,  ...,    0,    0,    0],\n",
       "          [ 134, 7497, 7498,  ...,    0,    0,    0],\n",
       "          [  70, 6279, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 1., 0., 0.])],\n",
       " [tensor([[1750, 1017, 1751,  ...,    0,    0,    0],\n",
       "          [ 566, 3223,  889,  ...,    0,    0,    0],\n",
       "          [ 235,  276,  222,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2517, 7495, 3760,  ...,    0,    0,    0],\n",
       "          [  49,  419,  109,  ...,    0,    0,    0],\n",
       "          [  10,  236,   70,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 1., 0., 0., 1., 0.])],\n",
       " [tensor([[  85,   92, 6943,  ...,    0,    0,    0],\n",
       "          [7507, 3760, 1446,  ...,    0,    0,    0],\n",
       "          [ 854,  855,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6698, 1917, 3760,  ...,    0,    0,    0],\n",
       "          [ 929, 1379, 2819,  ...,    0,    0,    0],\n",
       "          [ 693,  136,  118,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 1., 1.])],\n",
       " [tensor([[  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [  22,  626, 1209,  ...,    0,    0,    0],\n",
       "          [1980,  236,   75,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 927,  376, 3419,  ...,    0,    0,    0],\n",
       "          [ 270, 1791, 6529,  ...,    0,    0,    0],\n",
       "          [1160,  136, 3423,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 1., 0., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[2813, 7241, 7242,  ...,    0,    0,    0],\n",
       "          [2671, 2672, 2673,  ...,    0,    0,    0],\n",
       "          [1380, 1027,   98,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2688, 2689, 8849,  ...,    0,    0,    0],\n",
       "          [  45,  751,  311,  ...,    0,    0,    0],\n",
       "          [  14,  196, 8954,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 1., 1., 0., 0., 0., 0., 0., 0.])],\n",
       " [tensor([[ 133,  398,    9,  ...,    0,    0,    0],\n",
       "          [8727, 4764, 6911,  ...,    0,    0,    0],\n",
       "          [ 182, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 421, 2741,  595,  ...,    0,    0,    0],\n",
       "          [ 960,  632,  961,  ...,    0,    0,    0],\n",
       "          [ 566,  661,  413,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[ 929,   65,    6,  ...,    0,    0,    0],\n",
       "          [ 566, 1963, 3924,  ...,    0,    0,    0],\n",
       "          [2081, 1013, 2855,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  44,    9,    0,  ...,    0,    0,    0],\n",
       "          [1178,  992,  731,  ...,    0,    0,    0],\n",
       "          [1013,  352, 2197,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[1341,   22,   95,  ...,    0,    0,    0],\n",
       "          [1424, 7767, 5879,  ...,    0,    0,    0],\n",
       "          [8288, 8289, 8290,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 757,    9,  212,  ...,    0,    0,    0],\n",
       "          [ 363,  376, 3760,  ...,    0,    0,    0],\n",
       "          [ 144,  976,  595,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 1., 0., 0.])],\n",
       " [tensor([[ 171,  343, 7282,  ...,    0,    0,    0],\n",
       "          [7548, 8657, 3760,  ...,    0,    0,    0],\n",
       "          [ 416, 4457,  363,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 709,  466,   83,  ...,    0,    0,    0],\n",
       "          [1013,  136, 4581,  ...,    0,    0,    0],\n",
       "          [1156, 5007, 5008,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 0., 0., 1.])],\n",
       " [tensor([[8508, 8509,  536,  ...,    0,    0,    0],\n",
       "          [6402,  498, 6403,  ...,    0,    0,    0],\n",
       "          [1047, 6019,  837,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 249,  249,    9,  ...,    0,    0,    0],\n",
       "          [ 155,  312, 3760,  ...,    0,    0,    0],\n",
       "          [6028, 6029, 6030,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 1., 0., 0.])],\n",
       " [tensor([[ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          [ 566, 3840, 3841,  ...,    0,    0,    0],\n",
       "          [1692,  970, 1693,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 308, 6866, 3760,  ...,    0,    0,    0],\n",
       "          [1086, 4492, 3760,  ...,    0,    0,    0],\n",
       "          [1379,   54,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[ 427, 1852,  983,  ...,    0,    0,    0],\n",
       "          [ 239,  246, 2795,  ...,    0,    0,    0],\n",
       "          [ 976, 1831,  355,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1707,   52,  286,  ...,    0,    0,    0],\n",
       "          [ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [1044, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[1172, 1706,    9,  ...,    0,    0,    0],\n",
       "          [2448, 1016,   44,  ...,    0,    0,    0],\n",
       "          [3093, 3094,  566,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2270, 2271, 2272,  ...,    0,    0,    0],\n",
       "          [3258, 3683, 3684,  ...,    0,    0,    0],\n",
       "          [ 413,  214,  667,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[ 579, 6651,  579,  ...,    0,    0,    0],\n",
       "          [ 232,  376,  243,  ...,    0,    0,    0],\n",
       "          [ 308,  374, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5785, 2678,  688,  ...,    0,    0,    0],\n",
       "          [1254, 4534,    9,  ...,    0,    0,    0],\n",
       "          [ 269,  148,   75,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 0., 0., 0., 1., 1.])],\n",
       " [tensor([[1868,  118,  537,  ...,    0,    0,    0],\n",
       "          [  65,  690,  116,  ...,    0,    0,    0],\n",
       "          [ 416, 2601, 6378,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  48,  244,    0,  ...,    0,    0,    0],\n",
       "          [ 709, 2664, 2665,  ...,    0,    0,    0],\n",
       "          [  55, 3488, 1616,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 1., 0., 1., 0.])],\n",
       " [tensor([[2026, 1747,    9,  ...,    0,    0,    0],\n",
       "          [4636,  276, 7421,  ...,    0,    0,    0],\n",
       "          [ 246,  363,  364,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1254,  418,  311,  ...,    0,    0,    0],\n",
       "          [ 626,  638, 4495,  ...,    0,    0,    0],\n",
       "          [ 363, 5577, 8748,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 1., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[1706, 6284, 1634,  ...,    0,    0,    0],\n",
       "          [ 875, 1960, 1961,  ...,    0,    0,    0],\n",
       "          [ 238, 4670,  519,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4153, 1334, 3760,  ...,    0,    0,    0],\n",
       "          [  85, 2109, 8934,  ...,    0,    0,    0],\n",
       "          [3760,    0,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 0., 0., 0.])],\n",
       " [tensor([[ 131,  850, 3760,  ...,    0,    0,    0],\n",
       "          [ 134, 5689, 3760,  ...,    0,    0,    0],\n",
       "          [1073, 1074,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  37,    9,    0,  ...,    0,    0,    0],\n",
       "          [5661, 1411, 1266,  ...,    0,    0,    0],\n",
       "          [  47, 4869, 4302,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 1., 1., 1.])],\n",
       " [tensor([[ 212,  136,  297,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [ 372,  131, 1008,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 303, 3760, 3760,  ...,    0,    0,    0],\n",
       "          [ 246,  566,  311,  ...,    0,    0,    0],\n",
       "          [ 268, 1402, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 0., 1., 0., 0., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[ 610,   22, 1230,  ...,    0,    0,    0],\n",
       "          [  92, 1034,  752,  ...,    0,    0,    0],\n",
       "          [5711, 8040, 8041,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 566,  222,  223,  ...,    0,    0,    0],\n",
       "          [2271, 5564,  693,  ...,    0,    0,    0],\n",
       "          [ 155, 7784, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 1., 1., 0.])],\n",
       " [tensor([[ 838,  235,  332,  ...,    0,    0,    0],\n",
       "          [ 272,  715,   50,  ...,    0,    0,    0],\n",
       "          [6629, 3760,  168,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,  667,   50,  ...,    0,    0,    0],\n",
       "          [ 940, 5882,    0,  ...,    0,    0,    0],\n",
       "          [ 272,   91,  272,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 1., 0., 1.])],\n",
       " [tensor([[  60, 2238, 7545,  ...,    0,    0,    0],\n",
       "          [4129,  629,  116,  ...,    0,    0,    0],\n",
       "          [1281,  363,  100,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3392,   75, 4510,  ...,    0,    0,    0],\n",
       "          [3329, 2895, 3760,  ...,    0,    0,    0],\n",
       "          [ 355, 1351, 1324,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "          0., 1., 1., 1., 1., 0., 0., 1., 0., 1.])],\n",
       " [tensor([[  52,  286,  703,  ...,    0,    0,    0],\n",
       "          [6236, 5864, 3760,  ...,    0,    0,    0],\n",
       "          [ 537,  537,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1254, 1254,  230,  ...,    0,    0,    0],\n",
       "          [ 658,  314,   54,  ...,    0,    0,    0],\n",
       "          [3760,  130, 1909,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[ 229,  838, 3363,  ...,    0,    0,    0],\n",
       "          [ 581,  762, 1312,  ...,    0,    0,    0],\n",
       "          [1472,  777, 7031,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8109, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 146,  595, 5501,  ...,    0,    0,    0],\n",
       "          [2449,  196, 5638,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 0., 1., 1.])],\n",
       " [tensor([[ 155, 1008, 1243,  ...,    0,    0,    0],\n",
       "          [ 988, 1958,  942,  ...,    0,    0,    0],\n",
       "          [ 164,  790, 6272,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3192,    9, 4354,  ...,    0,    0,    0],\n",
       "          [  22,    9, 3770,  ...,    0,    0,    0],\n",
       "          [  56,  375, 3584,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "          0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 1., 1., 1.])],\n",
       " [tensor([[ 254, 8256, 3423,  ...,    0,    0,    0],\n",
       "          [ 136,  316,  118,  ...,    0,    0,    0],\n",
       "          [ 131,  692,  519,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1594,  882,  229,  ...,    0,    0,    0],\n",
       "          [ 582, 4691,   24,  ...,    0,    0,    0],\n",
       "          [1959,  581,  183,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "          1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[ 924, 2929,  537,  ...,    0,    0,    0],\n",
       "          [1636,  970, 1637,  ...,    0,    0,    0],\n",
       "          [  22,   98, 2446,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1476,  344,    9,  ...,    0,    0,    0],\n",
       "          [2479,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 523,  523,  524,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "          1., 1., 1., 0., 1., 1., 0., 1., 1., 1.])],\n",
       " [tensor([[6960,  709,   96,  ...,    0,    0,    0],\n",
       "          [1014,   52, 1467,  ...,    0,    0,    0],\n",
       "          [7461, 3760, 1665,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  48,  118,    0,  ...,    0,    0,    0],\n",
       "          [ 224,  609,    0,  ...,    0,    0,    0],\n",
       "          [ 461,  462,  463,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 1., 0., 1., 1., 1.])],\n",
       " [tensor([[  95,  457,  864,  ...,    0,    0,    0],\n",
       "          [ 415,   22,  787,  ...,    0,    0,    0],\n",
       "          [5119,   38, 3016,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1084,  135, 6291,  ...,    0,    0,    0],\n",
       "          [ 368,    8,  134,  ...,    0,    0,    0],\n",
       "          [ 376,   73,  498,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[3505, 1909, 3506,  ...,    0,    0,    0],\n",
       "          [ 566, 1044,  830,  ...,    0,    0,    0],\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6312,  237, 5747,  ...,    0,    0,    0],\n",
       "          [ 566,  882,  890,  ...,    0,    0,    0],\n",
       "          [  23,   24,   25,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 1., 0., 1., 1.])],\n",
       " [tensor([[5135, 3877,  935,  ...,    0,    0,    0],\n",
       "          [3444,   75,    0,  ...,    0,    0,    0],\n",
       "          [ 222,  153,  777,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1043,  311,  626,  ...,    0,    0,    0],\n",
       "          [ 413,  547,  118,  ...,    0,    0,    0],\n",
       "          [  97,  413,  667,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          0., 1., 0., 0., 0., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[ 429, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  50, 1704,    9,  ...,    0,    0,    0],\n",
       "          [8166,   65, 8167,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 710, 2650,   45,  ...,    0,    0,    0],\n",
       "          [  14,  582, 1000,  ...,    0,    0,    0],\n",
       "          [ 849,  272,   89,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[  65,  258,  259,  ...,    0,    0,    0],\n",
       "          [4075, 3760,   99,  ...,    0,    0,    0],\n",
       "          [ 599,   55, 3973,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 873,  790,  428,  ...,    0,    0,    0],\n",
       "          [ 376, 8663, 3760,  ...,    0,    0,    0],\n",
       "          [ 308,   19, 2878,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 0., 0.])],\n",
       " [tensor([[2611,  485, 3437,  ...,    0,    0,    0],\n",
       "          [  22,  667,  365,  ...,    0,    0,    0],\n",
       "          [1006, 1396, 4341,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1772,  276, 8966,  ...,    0,    0,    0],\n",
       "          [1288, 6614, 2295,  ...,    0,    0,    0],\n",
       "          [1204,   65,  659,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 0., 0., 1.])],\n",
       " [tensor([[ 566, 1044, 3110,  ...,    0,    0,    0],\n",
       "          [  22,  667, 2197,  ...,    0,    0,    0],\n",
       "          [ 418,  820,  821,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6045,  230, 1371,  ...,    0,    0,    0],\n",
       "          [6685, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 272,  344, 1014,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[  22,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 690,  363,  378,  ...,    0,    0,    0],\n",
       "          [4050,  375,  238,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1959,   22,  204,  ...,    0,    0,    0],\n",
       "          [2795,  837, 3760,  ...,    0,    0,    0],\n",
       "          [5977,   92,   14,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 0., 1., 1., 1., 1., 0., 0.])],\n",
       " [tensor([[  95,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 157,  751,  376,  ...,    0,    0,    0],\n",
       "          [ 350, 5397,  731,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 574, 3583,  118,  ...,    0,    0,    0],\n",
       "          [ 311, 1283, 1284,  ...,    0,    0,    0],\n",
       "          [1467,    8, 2218,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 1., 1., 0.])],\n",
       " [tensor([[  98, 1460,   98,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [3161, 3162, 3032,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4474, 2655,    9,  ...,    0,    0,    0],\n",
       "          [  55, 1436,   75,  ...,    0,    0,    0],\n",
       "          [1691, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 0., 1., 1., 0.])],\n",
       " [tensor([[2180,  255, 1444,  ...,    0,    0,    0],\n",
       "          [1891, 6024,   16,  ...,    0,    0,    0],\n",
       "          [4585, 2885, 6790,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 350, 5832,  351,  ...,    0,    0,    0],\n",
       "          [1121,  138,  690,  ...,    0,    0,    0],\n",
       "          [ 134,  900, 3538,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 0., 1., 0.])],\n",
       " [tensor([[ 376, 1084,   45,  ...,    0,    0,    0],\n",
       "          [5912,  693, 3760,  ...,    0,    0,    0],\n",
       "          [5763,  230,  229,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1874, 1875, 1141,  ...,    0,    0,    0],\n",
       "          [ 272, 1037,  351,  ...,    0,    0,    0],\n",
       "          [1070,  727, 5215,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 0., 1., 1., 1., 1.])],\n",
       " [tensor([[1380, 6735, 6736,  ...,    0,    0,    0],\n",
       "          [  22, 1521,    9,  ...,    0,    0,    0],\n",
       "          [ 240, 4259, 6702,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 705,  579,  276,  ...,    0,    0,    0],\n",
       "          [  14,  917,  312,  ...,    0,    0,    0],\n",
       "          [4601,   99,  447,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 1., 0., 1., 0.])],\n",
       " [tensor([[  50, 1389,    9,  ...,    0,    0,    0],\n",
       "          [ 130,   49,  537,  ...,    0,    0,    0],\n",
       "          [  23, 1466, 1467,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,  416,  933,  ...,    0,    0,    0],\n",
       "          [  22,   95,    9,  ...,    0,    0,    0],\n",
       "          [ 415,    9,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 1., 1., 1.])],\n",
       " [tensor([[ 725,  517, 1014,  ...,    0,    0,    0],\n",
       "          [1044, 8645,  566,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 705,   92,  283,  ...,    0,    0,    0],\n",
       "          [  22,  305,  236,  ...,    0,    0,    0],\n",
       "          [ 229,  178, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 1., 0., 0., 1., 0.])],\n",
       " [tensor([[ 155, 3760,  249,  ...,    0,    0,    0],\n",
       "          [8678, 8679, 3760,  ...,    0,    0,    0],\n",
       "          [ 391,   24,   45,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 235,  229,  235,  ...,    0,    0,    0],\n",
       "          [ 819,  143,    9,  ...,    0,    0,    0],\n",
       "          [6768, 7963, 1572,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 0., 1., 0., 0., 1., 0.])],\n",
       " [tensor([[  50, 1094,  925,  ...,    0,    0,    0],\n",
       "          [8823,  344, 8824,  ...,    0,    0,    0],\n",
       "          [8064, 3442,  566,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3760,  229,  230,  ...,    0,    0,    0],\n",
       "          [1360, 1507, 4352,  ...,    0,    0,    0],\n",
       "          [  65, 2326, 6525,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 1., 0., 1., 0., 1., 0.])],\n",
       " [tensor([[ 392,    9,    0,  ...,    0,    0,    0],\n",
       "          [  22,    9,    0,  ...,    0,    0,    0],\n",
       "          [  22,  196,   24,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 133, 1577,    9,  ...,    0,    0,    0],\n",
       "          [1411,  873,    9,  ...,    0,    0,    0],\n",
       "          [ 635,  328,  582,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 0., 1., 1., 1., 1.])],\n",
       " [tensor([[1559,  970, 3760,  ...,    0,    0,    0],\n",
       "          [ 413, 7891, 2501,  ...,    0,    0,    0],\n",
       "          [ 179,  369, 5112,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6096, 4640, 6097,  ...,    0,    0,    0],\n",
       "          [ 661,  413, 3760,  ...,    0,    0,    0],\n",
       "          [ 566, 3767, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "          1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 0., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[ 136,  414, 3528,  ...,    0,    0,    0],\n",
       "          [ 498,  976, 2068,  ...,    0,    0,    0],\n",
       "          [ 130, 5740, 5741,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5942, 3760, 5529,  ...,    0,    0,    0],\n",
       "          [ 351,  838,  204,  ...,    0,    0,    0],\n",
       "          [   9,  495,  496,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "          1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 0., 1.])],\n",
       " [tensor([[ 196, 1819,   50,  ...,    0,    0,    0],\n",
       "          [  95,    0,    0,  ...,    0,    0,    0],\n",
       "          [  10,  312,  566,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 413, 2047, 3760,  ...,    0,    0,    0],\n",
       "          [6769, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 270,  181,  129,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])],\n",
       " [tensor([[  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [ 235,  415,   22,  ...,    0,    0,    0],\n",
       "          [  53,   44,    8,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 511, 1546, 2892,  ...,    0,    0,    0],\n",
       "          [1000, 3363, 1868,  ...,    0,    0,    0],\n",
       "          [  56,  375, 3911,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "          1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 0., 1., 1.])],\n",
       " [tensor([[2848, 8055, 5561,  ...,    0,    0,    0],\n",
       "          [1329,  179,   73,  ...,    0,    0,    0],\n",
       "          [1936, 9037, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 566,  661, 1504,  ...,    0,    0,    0],\n",
       "          [4075,  837, 3760,  ...,    0,    0,    0],\n",
       "          [ 566, 2306,  673,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])],\n",
       " [tensor([[ 758,  759,  760,  ...,    0,    0,    0],\n",
       "          [6242, 1257, 3760,  ...,    0,    0,    0],\n",
       "          [ 111,  112,  113,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7204, 8688, 3760,  ...,    0,    0,    0],\n",
       "          [4953,  566, 2000,  ...,    0,    0,    0],\n",
       "          [ 684,   75, 3888,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 0., 1., 1.])],\n",
       " [tensor([[ 376,  109, 2541,  ...,    0,    0,    0],\n",
       "          [2197, 2813, 3760,  ...,    0,    0,    0],\n",
       "          [1925, 5828,  413,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 819,  667,   56,  ...,    0,    0,    0],\n",
       "          [ 134,  165, 5881,  ...,    0,    0,    0],\n",
       "          [  73,   85, 1798,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 0., 0., 1., 1., 1., 0., 1.])],\n",
       " [tensor([[  72,  619, 1403,  ...,    0,    0,    0],\n",
       "          [1084, 8369, 8261,  ...,    0,    0,    0],\n",
       "          [7066, 4046, 7067,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 159,  153,   92,  ...,    0,    0,    0],\n",
       "          [  22,  859,  667,  ...,    0,    0,    0],\n",
       "          [ 448, 2579, 2580,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 1., 1., 1.])],\n",
       " [tensor([[  63,  374,    9,  ...,    0,    0,    0],\n",
       "          [2290, 1334, 1737,  ...,    0,    0,    0],\n",
       "          [ 635,   50, 1472,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 235,   25,  118,  ...,    0,    0,    0],\n",
       "          [2501, 1512, 2984,  ...,    0,    0,    0],\n",
       "          [ 249,  428,   75,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[5752, 5753, 3760,  ...,    0,    0,    0],\n",
       "          [ 270, 3743, 3760,  ...,    0,    0,    0],\n",
       "          [ 246,  774, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2593,  626, 2594,  ...,    0,    0,    0],\n",
       "          [8416,  515,  940,  ...,    0,    0,    0],\n",
       "          [ 134,   73,  983,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 1., 1., 1., 0., 0.])],\n",
       " [tensor([[  92, 1086,   92,  ...,    0,    0,    0],\n",
       "          [2144,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 222,  153,  187,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1396,  443,  130,  ...,    0,    0,    0],\n",
       "          [  48,  244,    0,  ...,    0,    0,    0],\n",
       "          [5482, 1576,   70,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 0., 0., 1.])],\n",
       " [tensor([[ 135, 1329,  838,  ...,    0,    0,    0],\n",
       "          [5933, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1933,  731, 6598,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6819, 3760,    0,  ...,    0,    0,    0],\n",
       "          [5591, 1891,   73,  ...,    0,    0,    0],\n",
       "          [  54, 5860, 5861,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[ 134,  374, 4341,  ...,    0,    0,    0],\n",
       "          [  22, 1230,    9,  ...,    0,    0,    0],\n",
       "          [ 826,  363,  413,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 392,    9,    0,  ...,    0,    0,    0],\n",
       "          [  16, 7513, 5913,  ...,    0,    0,    0],\n",
       "          [ 221,   85,   73,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[ 272,  272,  272,  ...,    0,    0,    0],\n",
       "          [ 582,  179, 5526,  ...,    0,    0,    0],\n",
       "          [  14,   95,  676,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  246,   48,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [ 235,  153,   63,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[4551,   30,  344,  ...,    0,    0,    0],\n",
       "          [ 970,  573, 2792,  ...,    0,    0,    0],\n",
       "          [ 230, 4679, 4680,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 993, 5065,   52,  ...,    0,    0,    0],\n",
       "          [ 819, 4122,  100,  ...,    0,    0,    0],\n",
       "          [ 970,   44,  130,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 1., 1., 1., 1.])],\n",
       " [tensor([[ 109, 1436, 3538,  ...,    0,    0,    0],\n",
       "          [ 572,  268, 3762,  ...,    0,    0,    0],\n",
       "          [ 100, 1576, 7810,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3736,   63,   89,  ...,    0,    0,    0],\n",
       "          [  50,   71,   45,  ...,    0,    0,    0],\n",
       "          [1472,  777, 5956,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1.,\n",
       "          1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          0., 1., 0., 1., 1., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[  56,  375,  863,  ...,    0,    0,    0],\n",
       "          [2576, 1224, 1398,  ...,    0,    0,    0],\n",
       "          [2185,  109,  771,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1909, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  24,   44, 3760,  ...,    0,    0,    0],\n",
       "          [2197,  566, 5702,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 1., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[1396,  235,    9,  ...,    0,    0,    0],\n",
       "          [ 876, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  37,  244,  993,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  246,   48,  ...,    0,    0,    0],\n",
       "          [ 196,  376, 6702,  ...,    0,    0,    0],\n",
       "          [7403,  751,  855,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 0., 1., 0., 1., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[ 349,   75,  253,  ...,    0,    0,    0],\n",
       "          [   0,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 222, 4581, 4582,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 222,  223,  105,  ...,    0,    0,    0],\n",
       "          [  56,   53,   63,  ...,    0,    0,    0],\n",
       "          [1943, 9031, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[1943,  761,    9,  ...,    0,    0,    0],\n",
       "          [  22,  365,    9,  ...,    0,    0,    0],\n",
       "          [8292, 1380,  312,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1014,   73,  374,  ...,    0,    0,    0],\n",
       "          [  24, 1371,  263,  ...,    0,    0,    0],\n",
       "          [ 536,  316,  247,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          0., 1., 1., 1., 0., 1., 0., 0., 0., 1.])],\n",
       " [tensor([[ 131,  242, 1017,  ...,    0,    0,    0],\n",
       "          [5898, 5899, 1032,  ...,    0,    0,    0],\n",
       "          [ 443,  458, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5747,  566, 1044,  ...,    0,    0,    0],\n",
       "          [1044,  519, 6305,  ...,    0,    0,    0],\n",
       "          [ 235, 1507, 8225,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[ 279,   45, 1669,  ...,    0,    0,    0],\n",
       "          [6371,  925, 5697,  ...,    0,    0,    0],\n",
       "          [ 262, 8418, 7568,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 925,  306, 3760,  ...,    0,    0,    0],\n",
       "          [2265, 1737,  385,  ...,    0,    0,    0],\n",
       "          [  22,  365,   55,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 0., 0., 1.])],\n",
       " [tensor([[  56,  750,  263,  ...,    0,    0,    0],\n",
       "          [ 416,  893,  876,  ...,    0,    0,    0],\n",
       "          [ 109,    0,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7892,  895, 6598,  ...,    0,    0,    0],\n",
       "          [3159, 5307,  109,  ...,    0,    0,    0],\n",
       "          [  22, 3312,   92,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 0., 1., 1.])],\n",
       " [tensor([[1095,   50,   50,  ...,    0,    0,    0],\n",
       "          [ 737,  891, 3760,  ...,    0,    0,    0],\n",
       "          [ 222,  223,  224,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2291,   92, 6734,  ...,    0,    0,    0],\n",
       "          [ 415,   92,   57,  ...,    0,    0,    0],\n",
       "          [ 134, 5689, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 1., 0.])],\n",
       " [tensor([[3833, 1373,  333,  ...,    0,    0,    0],\n",
       "          [1225,  669,   22,  ...,    0,    0,    0],\n",
       "          [5699,  272, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1121,   65,  550,  ...,    0,    0,    0],\n",
       "          [3349,  311, 3350,  ...,    0,    0,    0],\n",
       "          [ 777, 8920,  777,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 1., 1., 0.])],\n",
       " [tensor([[ 312,  214,  118,  ...,    0,    0,    0],\n",
       "          [ 427,  789, 2946,  ...,    0,    0,    0],\n",
       "          [1204, 1618, 3971,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4703, 2368,  319,  ...,    0,    0,    0],\n",
       "          [2895, 2396, 1173,  ...,    0,    0,    0],\n",
       "          [ 581, 1017, 1535,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 1., 0., 0., 0.])],\n",
       " [tensor([[  22,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 975,   22,  667,  ...,    0,    0,    0],\n",
       "          [ 536, 1005,  348,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6633,  767, 5747,  ...,    0,    0,    0],\n",
       "          [  22,  542,   75,  ...,    0,    0,    0],\n",
       "          [ 219,   75,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])],\n",
       " [tensor([[7481,   70, 1387,  ...,    0,    0,    0],\n",
       "          [ 710,   16,  376,  ...,    0,    0,    0],\n",
       "          [ 970, 3655, 2695,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 549, 3078,  486,  ...,    0,    0,    0],\n",
       "          [2479,  536,  118,  ...,    0,    0,    0],\n",
       "          [ 572,  882,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.,\n",
       "          0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 1., 1., 1.])],\n",
       " [tensor([[1439,    9,    0,  ...,    0,    0,    0],\n",
       "          [3880, 2828,  587,  ...,    0,    0,    0],\n",
       "          [9062, 9063,  165,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 214,  268, 8876,  ...,    0,    0,    0],\n",
       "          [1807, 3945, 1014,  ...,    0,    0,    0],\n",
       "          [ 222,  223, 7638,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[2229, 2230, 2231,  ...,    0,    0,    0],\n",
       "          [ 363,  127,    9,  ...,    0,    0,    0],\n",
       "          [  22,  118,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1013,  136, 5882,  ...,    0,    0,    0],\n",
       "          [1044,  976,  670,  ...,    0,    0,    0],\n",
       "          [2901, 2936,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 1., 0., 0., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[ 109, 1329,  990,  ...,    0,    0,    0],\n",
       "          [  56,  375, 1064,  ...,    0,    0,    0],\n",
       "          [ 335,   92,  254,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7614,  246, 1329,  ...,    0,    0,    0],\n",
       "          [ 254, 6756,  976,  ...,    0,    0,    0],\n",
       "          [   9,    0,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 0., 0., 1.])],\n",
       " [tensor([[7385,  222,  934,  ...,    0,    0,    0],\n",
       "          [ 777, 9030,  897,  ...,    0,    0,    0],\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3760,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 228,  229,  838,  ...,    0,    0,    0],\n",
       "          [3108, 2597, 2815,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])],\n",
       " [tensor([[1811,  255, 1812,  ...,    0,    0,    0],\n",
       "          [ 667,  413, 5747,  ...,    0,    0,    0],\n",
       "          [1001,    9,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4586,  670,  130,  ...,    0,    0,    0],\n",
       "          [1008, 5834, 5835,  ...,    0,    0,    0],\n",
       "          [ 715, 3760, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[ 276,  210,  179,  ...,    0,    0,    0],\n",
       "          [ 272,  156,  273,  ...,    0,    0,    0],\n",
       "          [ 155,  153,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3348, 1523,  244,  ...,    0,    0,    0],\n",
       "          [ 413, 3188, 3760,  ...,    0,    0,    0],\n",
       "          [2380,  432,  118,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[ 448,    9,  408,  ...,    0,    0,    0],\n",
       "          [ 363,  312,  566,  ...,    0,    0,    0],\n",
       "          [ 229, 7929,  116,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2211, 2212,  318,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [ 363,   48, 6650,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 0., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[ 416,  562, 2105,  ...,    0,    0,    0],\n",
       "          [  23,  420, 1096,  ...,    0,    0,    0],\n",
       "          [2848, 2607,   44,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4141,   99,   48,  ...,    0,    0,    0],\n",
       "          [ 566,  889,  744,  ...,    0,    0,    0],\n",
       "          [5969,  579,   71,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[7687, 3760,    0,  ...,    0,    0,    0],\n",
       "          [3326,   94,   57,  ...,    0,    0,    0],\n",
       "          [1560, 1807,  127,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1193, 2907, 2908,  ...,    0,    0,    0],\n",
       "          [ 109, 2287, 1435,  ...,    0,    0,    0],\n",
       "          [ 566,  774, 5237,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[ 640, 8009, 8010,  ...,    0,    0,    0],\n",
       "          [ 222,   48,  661,  ...,    0,    0,    0],\n",
       "          [5432,  566,  311,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  50, 3025, 3273,  ...,    0,    0,    0],\n",
       "          [6068, 3760,    0,  ...,    0,    0,    0],\n",
       "          [2396, 8955,  669,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 1., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[ 427,  419,  789,  ...,    0,    0,    0],\n",
       "          [ 253,  446, 2557,  ...,    0,    0,    0],\n",
       "          [5655,  343,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5747,  134, 7598,  ...,    0,    0,    0],\n",
       "          [1044,  276, 5747,  ...,    0,    0,    0],\n",
       "          [  22,   11, 3494,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "          1., 0., 0., 0., 1., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[ 138, 1869, 3760,  ...,    0,    0,    0],\n",
       "          [7801, 7798, 3760,  ...,    0,    0,    0],\n",
       "          [ 136, 1014,  294,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4208,  596,  442,  ...,    0,    0,    0],\n",
       "          [2525,  375,   54,  ...,    0,    0,    0],\n",
       "          [8903,  414, 8904,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[  45,  237,  654,  ...,    0,    0,    0],\n",
       "          [  22, 4103, 1038,  ...,    0,    0,    0],\n",
       "          [ 582,  693, 3314,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [   9,   22,  667,  ...,    0,    0,    0],\n",
       "          [  98,  411,  412,  ...,    0,    0,    0],\n",
       "          [ 536,  670, 1352,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 0., 0., 1., 1., 1.])],\n",
       " [tensor([[6374, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1594, 1014,   73,  ...,    0,    0,    0],\n",
       "          [ 305, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 224,  609,    0,  ...,    0,    0,    0],\n",
       "          [ 448, 3405,   50,  ...,    0,    0,    0],\n",
       "          [  73,  353,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 1., 1., 1.])],\n",
       " [tensor([[ 579,  179, 7844,  ...,    0,    0,    0],\n",
       "          [3976, 3976, 3976,  ...,    0,    0,    0],\n",
       "          [ 774,   44,  144,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4041,  228, 3269,  ...,    0,    0,    0],\n",
       "          [6202, 3083,  308,  ...,    0,    0,    0],\n",
       "          [1259,   99,  196,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "          1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 1., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[ 376, 4502, 3760,  ...,    0,    0,    0],\n",
       "          [  98, 1803,  566,  ...,    0,    0,    0],\n",
       "          [ 705, 4351, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 448,  118,    0,  ...,    0,    0,    0],\n",
       "          [ 221,  303, 1036,  ...,    0,    0,    0],\n",
       "          [8303, 8304, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0.,\n",
       "          1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 0., 0., 1., 1., 1., 0.])],\n",
       " [tensor([[ 221,  303, 3760,  ...,    0,    0,    0],\n",
       "          [3083, 8195,  130,  ...,    0,    0,    0],\n",
       "          [  92,  853, 1286,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1398,  136,  118,  ...,    0,    0,    0],\n",
       "          [ 220,  376, 3760,  ...,    0,    0,    0],\n",
       "          [ 196,   45,  990,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 0., 0., 1., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[  48, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1233, 1234, 1235,  ...,    0,    0,    0],\n",
       "          [5127, 1613, 6829,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  97,  413, 1057,  ...,    0,    0,    0],\n",
       "          [1099, 5703,    9,  ...,    0,    0,    0],\n",
       "          [ 133, 1208,   37,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 0., 0., 1., 1.])],\n",
       " [tensor([[ 975,  391,  130,  ...,    0,    0,    0],\n",
       "          [8690,  864,  178,  ...,    0,    0,    0],\n",
       "          [7048,  837,  838,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3129, 5276,  419,  ...,    0,    0,    0],\n",
       "          [3953,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 316,  750,  344,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 0., 1., 0., 1., 0., 1., 1., 1.])],\n",
       " [tensor([[  50,  553,  159,  ...,    0,    0,    0],\n",
       "          [ 582,   91,  889,  ...,    0,    0,    0],\n",
       "          [ 860,   63,  215,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [1116,  136,  179,  ...,    0,    0,    0],\n",
       "          [ 673,   48, 1523,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [ 566, 7622, 3760,  ...,    0,    0,    0],\n",
       "          [ 661,  926,  684,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  179,  136,  ...,    0,    0,    0],\n",
       "          [ 413, 7792, 1585,  ...,    0,    0,    0],\n",
       "          [  75, 2056, 2057,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.,\n",
       "          0., 1., 1., 0., 0., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[  47,   50,   92,  ...,    0,    0,    0],\n",
       "          [ 705, 5747,    0,  ...,    0,    0,    0],\n",
       "          [ 109, 7110,  183,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5970, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 413,  486, 2466,  ...,    0,    0,    0],\n",
       "          [1579,  860,  753,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "          1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 0., 0., 0., 1.])],\n",
       " [tensor([[2411, 3606, 3266,  ...,    0,    0,    0],\n",
       "          [ 316, 1677,    9,  ...,    0,    0,    0],\n",
       "          [ 376,   45,  159,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 224,  609,    0,  ...,    0,    0,    0],\n",
       "          [1551,  706,   75,  ...,    0,    0,    0],\n",
       "          [ 413, 7502,  372,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "          1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 1., 0., 0., 1., 1., 0., 1., 1., 0.])],\n",
       " [tensor([[  50,  118,    0,  ...,    0,    0,    0],\n",
       "          [  37,  130,  367,  ...,    0,    0,    0],\n",
       "          [ 196, 1944,  970,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1891,  940,  857,  ...,    0,    0,    0],\n",
       "          [ 235,   25,    9,  ...,    0,    0,    0],\n",
       "          [ 303,  328,  182,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "          0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 1., 0., 1., 0., 1., 1.])],\n",
       " [tensor([[ 929,   95, 1381,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [1496,    9, 1497,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5585,  582,  912,  ...,    0,    0,    0],\n",
       "          [1583, 2035, 3760,  ...,    0,    0,    0],\n",
       "          [ 221,  303,  566,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[  92,  363, 3760,  ...,    0,    0,    0],\n",
       "          [ 134,    9,  966,  ...,    0,    0,    0],\n",
       "          [4186, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 221,  235,  627,  ...,    0,    0,    0],\n",
       "          [ 975,   75,  249,  ...,    0,    0,    0],\n",
       "          [3269, 5747,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 0., 1., 0.])],\n",
       " [tensor([[ 350,  519,  976,  ...,    0,    0,    0],\n",
       "          [ 566,  311,  824,  ...,    0,    0,    0],\n",
       "          [3760,    0,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  75, 1008, 5609,  ...,    0,    0,    0],\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          [7652, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 0., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[  30, 2625, 2626,  ...,    0,    0,    0],\n",
       "          [2809,  990,   45,  ...,    0,    0,    0],\n",
       "          [1705,  645,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,   95,    9,  ...,    0,    0,    0],\n",
       "          [3760, 7776,  335,  ...,    0,    0,    0],\n",
       "          [  85,  684,   89,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "          0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 0., 0., 0., 1., 1., 0., 1.])],\n",
       " [tensor([[ 235,  386, 2031,  ...,    0,    0,    0],\n",
       "          [ 196,  443, 7795,  ...,    0,    0,    0],\n",
       "          [ 229,   48, 5019,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1618,  819, 3390,  ...,    0,    0,    0],\n",
       "          [ 238,  519,  196,  ...,    0,    0,    0],\n",
       "          [  50,   91,   92,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "          0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0.,\n",
       "          0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 0., 1., 0., 1., 0., 1.])],\n",
       " [tensor([[  98, 8681,   98,  ...,    0,    0,    0],\n",
       "          [  52,  763,  218,  ...,    0,    0,    0],\n",
       "          [ 684, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 536,  235,  301,  ...,    0,    0,    0],\n",
       "          [4535,  737, 1706,  ...,    0,    0,    0],\n",
       "          [4601, 3760,  582,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[ 131,   14,  127,  ...,    0,    0,    0],\n",
       "          [7575, 2599, 7576,  ...,    0,    0,    0],\n",
       "          [ 134,  109,  693,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5002,  109,  396,  ...,    0,    0,    0],\n",
       "          [ 579,  215, 6859,  ...,    0,    0,    0],\n",
       "          [ 363, 1421,   25,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 0., 0., 0.])],\n",
       " [tensor([[1325, 3760,  566,  ...,    0,    0,    0],\n",
       "          [  98,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 235,  415,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 144, 7048, 2005,  ...,    0,    0,    0],\n",
       "          [1499,    9,    0,  ...,    0,    0,    0],\n",
       "          [1191,    9, 2727,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 1., 1.])],\n",
       " [tensor([[  22,   27, 1853,  ...,    0,    0,    0],\n",
       "          [ 131, 2619,  118,  ...,    0,    0,    0],\n",
       "          [ 254, 1830, 2080,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  56,  632, 4232,  ...,    0,    0,    0],\n",
       "          [6998,  582,  182,  ...,    0,    0,    0],\n",
       "          [4245,  342,  182,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1.,\n",
       "          0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          1., 1., 0., 0., 0., 0., 1., 1., 0., 0.])],\n",
       " [tensor([[3477,  308,  445,  ...,    0,    0,    0],\n",
       "          [ 351, 1253, 5747,  ...,    0,    0,    0],\n",
       "          [ 536,  660,  343,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 975,    9,  427,  ...,    0,    0,    0],\n",
       "          [4923, 2929,    9,  ...,    0,    0,    0],\n",
       "          [5872, 1523,  196,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 1., 1., 1., 1., 0.])],\n",
       " [tensor([[ 221,  413, 4880,  ...,    0,    0,    0],\n",
       "          [  50,  591,  118,  ...,    0,    0,    0],\n",
       "          [ 127, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 222,   48,  100,  ...,    0,    0,    0],\n",
       "          [   9,  773,  566,  ...,    0,    0,    0],\n",
       "          [ 268, 3363, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.,\n",
       "          1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 0., 1., 1., 0.])],\n",
       " [tensor([[1758, 3296,  854,  ...,    0,    0,    0],\n",
       "          [  98,  228, 8296,  ...,    0,    0,    0],\n",
       "          [3760,  255,  109,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 308, 2282,  378,  ...,    0,    0,    0],\n",
       "          [2179,  327,  255,  ...,    0,    0,    0],\n",
       "          [ 246,   50,  179,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "          1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 0., 1., 0., 0., 0., 1., 1.])],\n",
       " [tensor([[ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [ 826, 3760, 6237,  ...,    0,    0,    0],\n",
       "          [ 442,  860,   48,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 940,  686, 3073,  ...,    0,    0,    0],\n",
       "          [2552,  229,   48,  ...,    0,    0,    0],\n",
       "          [ 827,  322,  334,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "          0., 1., 0., 0., 1., 1., 0., 0., 1., 1.])],\n",
       " [tensor([[4264, 1300, 4265,  ...,    0,    0,    0],\n",
       "          [   9,  135, 1925,  ...,    0,    0,    0],\n",
       "          [ 448, 2640, 4455,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1006,   22,  283,  ...,    0,    0,    0],\n",
       "          [ 566, 5929, 5930,  ...,    0,    0,    0],\n",
       "          [ 272, 1064,  344,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "          1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          1., 0., 0., 0., 0., 1., 0., 1., 0., 0.])],\n",
       " [tensor([[  22,  235,  386,  ...,    0,    0,    0],\n",
       "          [ 413, 8073, 8074,  ...,    0,    0,    0],\n",
       "          [ 566,  140, 1430,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 925,  536, 8276,  ...,    0,    0,    0],\n",
       "          [1047,   63, 8607,  ...,    0,    0,    0],\n",
       "          [2933, 5461, 5462,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1.,\n",
       "          1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "          0., 1., 1., 0., 1., 0., 1., 0., 0., 1.])],\n",
       " [tensor([[ 222, 4246, 5863,  ...,    0,    0,    0],\n",
       "          [  75,  136, 5670,  ...,    0,    0,    0],\n",
       "          [ 394, 4331, 2176,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1001,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 127,  303, 3760,  ...,    0,    0,    0],\n",
       "          [3021,   22,  667,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "          1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "          1., 0., 0., 0., 1., 0., 0., 1., 0., 1.])],\n",
       " [tensor([[ 179, 7509,  405,  ...,    0,    0,    0],\n",
       "          [5300, 5086,  517,  ...,    0,    0,    0],\n",
       "          [3760,  536,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2783, 1027, 2784,  ...,    0,    0,    0],\n",
       "          [2197, 4131,  705,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "          0., 0., 0., 0., 1., 0., 0., 1., 0., 0.])],\n",
       " [tensor([[1382,   95, 2005,  ...,    0,    0,    0],\n",
       "          [ 413, 3760,  311,  ...,    0,    0,    0],\n",
       "          [  49, 5308,  171,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1613, 4837,  116,  ...,    0,    0,    0],\n",
       "          [6149, 6150, 4509,  ...,    0,    0,    0],\n",
       "          [1329,  116,  236,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "          0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "          0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "          1., 0., 0., 1., 0., 1., 0., 0., 0., 0.])],\n",
       " [tensor([[ 336,  336, 7162,  ...,    0,    0,    0],\n",
       "          [ 253, 7041, 3760,  ...,    0,    0,    0],\n",
       "          [ 327,    8, 3716,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 455, 1065,    9,  ...,    0,    0,    0],\n",
       "          [ 344, 6846,   60,  ...,    0,    0,    0],\n",
       "          [ 271, 1758,  142,  ...,    0,    0,    0]]),\n",
       "  tensor([0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "          1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "          0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1.,\n",
       "          1., 1., 0., 1., 0., 1., 1., 1., 0., 1.])],\n",
       " [tensor([[  50,  550,   49,  ...,    0,    0,    0],\n",
       "          [5458,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 155,   22, 2262,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 566,  130,  225,  ...,    0,    0,    0],\n",
       "          [ 109,  916,  509,  ...,    0,    0,    0],\n",
       "          [  21,   22,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "          1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "          0., 1., 0., 0., 0., 1., 0., 0., 1., 1.])],\n",
       " [tensor([[ 838,   75, 3547,  ...,    0,    0,    0],\n",
       "          [ 235,  157,  179,  ...,    0,    0,    0],\n",
       "          [ 235, 3354,  283,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 376,  443, 3760,  ...,    0,    0,    0],\n",
       "          [ 179,  427,  109,  ...,    0,    0,    0],\n",
       "          [6545,  581, 3339,  ...,    0,    0,    0]]),\n",
       "  tensor([1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "          1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "          0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "          1., 1., 1., 0., 1., 0., 0., 0., 1., 0.])]]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpo5X-sdDBkp",
    "outputId": "ba3c049e-51de-46c6-80a9-2de282e84422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataloader)) # 250 batch pray huye hain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "7B0u0TghDBnQ",
    "outputId": "3c79a1de-48f3-42d8-a752-e575116f3a02"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0b5d7fa6c3d5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# first batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "list(dataloader)[0]  # first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "id": "-SNpO7j1DBps",
    "outputId": "82e4e504-76d4-4f2e-918d-7c284d0c35a3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f33d7339ca1c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "type(list(dataloader)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4jguB71SDBsN",
    "outputId": "e97ac2a5-73e7-40d0-934b-34ff85710348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataloader)[0])  # 0: tensor tweets, 1: corresponding labels 0s and 1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8plNtLVpDBu2",
    "outputId": "8b04513c-24b9-492d-d6ad-44226bd3c48c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1654,  236, 1109,  ...,    0,    0,    0],\n",
       "        [5747,  134, 7598,  ...,    0,    0,    0],\n",
       "        [  22,    9,    0,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 376, 8313, 8313,  ...,    0,    0,    0],\n",
       "        [ 311,  330, 5278,  ...,    0,    0,    0],\n",
       "        [  37, 1706,  420,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXlGNWZTDBxQ",
    "outputId": "add47364-cddd-43ad-8578-f8deb84c8401"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dataloader)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YiqzKOrADB0Q",
    "outputId": "7785eecb-a853-45d7-fa6f-d8982a26cb67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 1., 0., 0., 1., 1., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "us2v16eYDB2V",
    "outputId": "64a252f7-d9f7-40fe-a2ee-d769e95736ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True, False, False,  True, False,  True, False,  True, False,\n",
       "         True, False, False,  True,  True, False, False,  True, False, False,\n",
       "         True,  True,  True,  True, False, False, False, False, False, False,\n",
       "        False, False,  True, False,  True, False, False,  True, False,  True,\n",
       "        False, False, False,  True, False,  True,  True, False, False, False,\n",
       "        False, False, False, False, False,  True,  True, False,  True,  True,\n",
       "        False,  True,  True, False])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataloader)[0][1] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7jScvmVECy0",
    "outputId": "079729d0-45f4-4e6b-a89e-80913bdfe7e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(list(dataloader)[0][1] == 0)\n",
    "# yani 64 main say 30 0s hain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0jCgfs10MPw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_XqfqoF0Mj5"
   },
   "source": [
    "### Model Architecture\n",
    "#### Raw logits are model's outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXTZ_HEF4wrR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super(TweetClassifier, self).__init__()\n",
    "\n",
    "        self.embedding  =  nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc         =  nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.mean(dim=1)\n",
    "        output = self.fc(embedded)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBMD1aH76f-C"
   },
   "outputs": [],
   "source": [
    "# Example vocab size (you need to replace this with the actual size of your vocab)\n",
    "vocab_size    = len(Vocab)\n",
    "embedding_dim = 256\n",
    "output_dim    = 1\n",
    "\n",
    "model = TweetClassifier(vocab_size, embedding_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNA8BFx95JN_",
    "outputId": "6f7cd6af-6016-41b8-d41f-99f31dc7f660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0880\n",
      "Epoch [2/5], Loss: 0.0332\n",
      "Epoch [3/5], Loss: 0.0546\n",
      "Epoch [4/5], Loss: 0.0151\n",
      "Epoch [5/5], Loss: 0.0258\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()                           # binary cross entropy with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8m9h8Qt0VAK"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poM9U0Qq0UJL"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHeRxeP55z9O",
    "outputId": "bda79b11-01a2-4024-ec97-fdef705a0cdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.from_numpy(all_pos_int_tweets_matrix[0,:]).long()\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92sUkF7D7Gdu",
    "outputId": "6fa4d938-7e53-4055-c72e-7f46153e4a05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSDHAZCY7L2L",
    "outputId": "b9814b23-a3a0-4397-f55f-a8a1691198ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sample.unsqueeze(0)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B23Un3BI6gXf",
    "outputId": "cedc3b4d-677b-464a-d2a1-41f548f7728d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetClassifier(\n",
       "  (embedding): Embedding(9088, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVztSQyc7o6q",
    "outputId": "d7f94a74-980d-4ab7-a0d3-9845409d065b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2326528"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9088*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XQIPqHo6tQE",
    "outputId": "e143d1b3-5886-4adb-d8f5-ef0b1a2bc42e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9993)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(sample)\n",
    "    predictions = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyBkXtXA5z_m",
    "outputId": "c7381065-463f-49d5-960f-3d65fa30bad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9993]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = torch.sigmoid(model(sample))\n",
    "sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5EX5qMh50C7",
    "outputId": "f78aa4ca-8843-44b4-ea6c-4d3efe64998c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.2864]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ri2h4SWBInW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DNS1HkacBIqD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifdElBeS04TE"
   },
   "source": [
    "# Variation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9PMr0fVBIvM"
   },
   "outputs": [],
   "source": [
    "# Combine positive and negative samples\n",
    "all_tweets_matrix = np.vstack((all_pos_int_tweets_matrix, all_neg_int_tweets_matrix))\n",
    "all_labels = np.concatenate((pos_true_labels, neg_true_labels))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tweets_tensor = torch.tensor(all_tweets_matrix, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(all_labels, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(tweets_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmRnPint0--X"
   },
   "source": [
    "### Model Architecture\n",
    "#### Sigmoid is model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c01HnpwiBIxW"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define the neural network architecture\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SentimentAnalysisModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        embedded = embedded.mean(dim=1)  # Average embeddings over the sequence length\n",
    "        output = self.fc(embedded)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBr632iWBIzs"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = 9088\n",
    "embed_dim = 256\n",
    "\n",
    "# Instantiate the model\n",
    "model = SentimentAnalysisModel(vocab_size, embed_dim)\n",
    "\n",
    "# Step 3: Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgQ9Tu8QBI3H",
    "outputId": "7e796511-5990-44a5-cfe1-48ec840b0777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6813698740005493\n",
      "Epoch 2/10, Loss: 0.6301184883117675\n",
      "Epoch 3/10, Loss: 0.557199560880661\n",
      "Epoch 4/10, Loss: 0.46323020124435427\n",
      "Epoch 5/10, Loss: 0.36554393291473386\n",
      "Epoch 6/10, Loss: 0.28155439710617064\n",
      "Epoch 7/10, Loss: 0.21524840998649597\n",
      "Epoch 8/10, Loss: 0.16630184495449066\n",
      "Epoch 9/10, Loss: 0.1301447246670723\n",
      "Epoch 10/10, Loss: 0.10356896281242371\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udVXmYdr1NTi"
   },
   "source": [
    "# Another Model Variation\n",
    "\n",
    "### with softmax output and neg-log-likelihood loss fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8QHuwrP8ENX"
   },
   "outputs": [],
   "source": [
    "# Combine positive and negative samples\n",
    "all_tweets_matrix = np.vstack((all_pos_int_tweets_matrix, all_neg_int_tweets_matrix))\n",
    "all_labels = np.concatenate((pos_true_labels, neg_true_labels))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tweets_tensor = torch.tensor(all_tweets_matrix, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(all_labels, dtype=torch.long)  # Change to long for CrossEntropyLoss\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(tweets_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bNi3hEO8EQl"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define the neural network architecture\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_dim):\n",
    "\n",
    "    super(SentimentAnalysisModel, self).__init__()\n",
    "    self.embedding   =  nn.Embedding(vocab_size, embed_dim)\n",
    "    self.fc          =  nn.Linear(embed_dim, 2)                 # Output dimension is 2 for softmax\n",
    "    self.log_softmax =  nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    embedded      =  self.embedding(x)\n",
    "    embedded      =  embedded.mean(dim=1)                      # Average embeddings over the sequence length\n",
    "    logits        =  self.fc(embedded)\n",
    "    probabilities =  self.log_softmax(logits)                      # Apply softmax to get probabilities\n",
    "    return probabilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcTFkjrX481K"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EevRSfks8VL9"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = 9088\n",
    "embed_dim  = 256\n",
    "\n",
    "# Instantiate the model\n",
    "model = SentimentAnalysisModel(vocab_size, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-S8eLAh8afz"
   },
   "outputs": [],
   "source": [
    "# Step 3: Define loss function and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8_SPytw9gaB",
    "outputId": "16cec68d-db9a-4b46-8f3b-bf74f7499b84",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.6684565997123718\n",
      "Epoch 2/30, Loss: 0.5714530947208405\n",
      "Epoch 3/30, Loss: 0.44834967255592345\n",
      "Epoch 4/30, Loss: 0.32567218828201294\n",
      "Epoch 5/30, Loss: 0.23065419149398803\n",
      "Epoch 6/30, Loss: 0.1652928866147995\n",
      "Epoch 7/30, Loss: 0.12165165191888809\n",
      "Epoch 8/30, Loss: 0.09211435216665267\n",
      "Epoch 9/30, Loss: 0.07155854806303978\n",
      "Epoch 10/30, Loss: 0.057603250116109846\n",
      "Epoch 11/30, Loss: 0.04688794532418251\n",
      "Epoch 12/30, Loss: 0.039139284729957584\n",
      "Epoch 13/30, Loss: 0.03312096880376339\n",
      "Epoch 14/30, Loss: 0.02849630557745695\n",
      "Epoch 15/30, Loss: 0.02510268522799015\n",
      "Epoch 16/30, Loss: 0.02176929384469986\n",
      "Epoch 17/30, Loss: 0.01927870847284794\n",
      "Epoch 18/30, Loss: 0.01721077525615692\n",
      "Epoch 19/30, Loss: 0.015545440148562193\n",
      "Epoch 20/30, Loss: 0.013869173765182496\n",
      "Epoch 21/30, Loss: 0.012771548934280872\n",
      "Epoch 22/30, Loss: 0.01172525018081069\n",
      "Epoch 23/30, Loss: 0.010839160164818168\n",
      "Epoch 24/30, Loss: 0.009842290868982672\n",
      "Epoch 25/30, Loss: 0.009278351612389088\n",
      "Epoch 26/30, Loss: 0.008546622235327959\n",
      "Epoch 27/30, Loss: 0.008069949382916093\n",
      "Epoch 28/30, Loss: 0.007664043038152158\n",
      "Epoch 29/30, Loss: 0.0068289435189217325\n",
      "Epoch 30/30, Loss: 0.006586300414055586\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        probabilities = model(inputs)  # Get probabilities\n",
    "        loss = criterion(probabilities, labels)  # CrossEntropyLoss expects class indices\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFMGvDZTAi85"
   },
   "source": [
    "# Another model Variation\n",
    "\n",
    "### raw logits output, crossentropy loss\n",
    "\n",
    "nn.CrossEntropyLoss combines nn.LogSoftmax() and nn.NLLLoss() (negative log likelihood loss) in a single class.\n",
    "\n",
    "It expects the raw logits (unnormalized scores) as input, not probabilities.\n",
    "\n",
    "The softmax function within nn.CrossEntropyLoss will handle the conversion to probabilities internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wWyqL74v-Kiy"
   },
   "outputs": [],
   "source": [
    "# Combine positive and negative samples\n",
    "all_tweets_matrix = np.vstack((all_pos_int_tweets_matrix, all_neg_int_tweets_matrix))\n",
    "all_labels = np.concatenate((pos_true_labels, neg_true_labels))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "tweets_tensor = torch.tensor(all_tweets_matrix, dtype=torch.long)\n",
    "labels_tensor = torch.tensor(all_labels, dtype=torch.long)  # Change to long for CrossEntropyLoss\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "dataset = TensorDataset(tweets_tensor, labels_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSahGI3j-OQR"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define the neural network architecture\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SentimentAnalysisModel, self).__init__()\n",
    "\n",
    "        self.embedding  =  nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc         =  nn.Linear(embed_dim, 2)  # Output dimension is 2 for softmax\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=1)   # Softmax over the classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded  =  self.embedding(x)\n",
    "        embedded  =  embedded.mean(dim=1)  # Average embeddings over the sequence length\n",
    "        logits    =  self.fc(embedded)\n",
    "        return logits  # Return logits for CrossEntropyLoss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0bxaxJUAJjd"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = len(Vocab)\n",
    "embed_dim = 256\n",
    "\n",
    "# Instantiate the model\n",
    "model = SentimentAnalysisModel(vocab_size, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERABFlF8AMSy"
   },
   "outputs": [],
   "source": [
    "# Step 3: Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_cw5DHrAOpT",
    "outputId": "83e7de16-8854-4de1-a262-e5c011f963c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6698989157676697\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 2/10, Loss: 0.5840957436561585\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 3/10, Loss: 0.4701932153701782\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 4/10, Loss: 0.348238805770874\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 5/10, Loss: 0.249582932472229\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 6/10, Loss: 0.17822025448083878\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 7/10, Loss: 0.12991637319326402\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 8/10, Loss: 0.09810113298892975\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 9/10, Loss: 0.07552705666422845\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n",
      "Epoch 10/10, Loss: 0.060588793426752094\n",
      "logits:  torch.Size([64, 2]) label:  torch.Size([64])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss   = criterion(logits, labels)  # CrossEntropyLoss expects class indices\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader)}\")\n",
    "    print('logits: ', logits.shape, 'label: ', labels.shape)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEcJ5yMIicud"
   },
   "source": [
    "## from chat gpt\n",
    "\n",
    "In the context of training a neural network with PyTorch, `optimizer.zero_grad()` plays a crucial role in the optimization process. Let's break down its purpose and how it fits into the training loop.\n",
    "\n",
    "### Purpose of `optimizer.zero_grad()`\n",
    "\n",
    "**1. Clearing Previous Gradients:**\n",
    "   - During the backpropagation step (`loss.backward()`), PyTorch computes the gradients of the loss with respect to the model parameters and accumulates them in the `.grad` attributes of each parameter. If `optimizer.zero_grad()` is not called, these gradients will accumulate (i.e., they will be summed) across multiple batches. This is usually not desired because each backpropagation step should be independent and only based on the current batch of data.\n",
    "\n",
    "**2. Ensuring Correct Gradient Updates:**\n",
    "   - By zeroing the gradients at the start of each iteration, you ensure that each parameter update is based only on the gradients calculated from the current batch. This helps in ensuring that the model learns correctly and efficiently.\n",
    "\n",
    "\n",
    "### Detailed Step-by-Step Explanation\n",
    "\n",
    "1. **Step 1: Clear Previous Gradients**\n",
    "   - `optimizer.zero_grad()`: This ensures that gradients from the previous batch are not accumulated. This clears the `.grad` attribute of each parameter before computing new gradients.\n",
    "\n",
    "2. **Step 2: Forward Pass**\n",
    "   - `logits = model(inputs)`: The model processes the input data and produces predictions (logits).\n",
    "\n",
    "3. **Step 3: Compute Loss**\n",
    "   - `loss = criterion(logits, labels)`: The loss function compares the model's predictions with the true labels to compute the loss.\n",
    "\n",
    "4. **Step 4: Backward Pass**\n",
    "   - `loss.backward()`: This computes the gradient of the loss with respect to each parameter of the model. These gradients are stored in the `.grad` attributes of the model's parameters.\n",
    "\n",
    "5. **Step 5: Update Model Parameters**\n",
    "   - `optimizer.step()`: This updates the model's parameters using the gradients computed in the backward pass. The optimizer performs a step of gradient descent (or another optimization algorithm).\n",
    "\n",
    "6. **Step 6: Accumulate Loss for Reporting**\n",
    "   - `running_loss += loss.item()`: This accumulates the loss for the current batch to compute the average loss over the epoch.\n",
    "\n",
    "By zeroing the gradients at the beginning of each batch, you ensure that each parameter update is based solely on the gradients calculated from the current batch, leading to correct and stable training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDGOOIMi7dw4"
   },
   "source": [
    "## Inference from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPtrJ5w2EX6W",
    "outputId": "7bfdd469-0074-4128-f112-e050dfb0a622"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = torch.from_numpy(all_pos_int_tweets_matrix[0,:]).long()\n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxqW36twEX6a",
    "outputId": "2406fffa-bd0d-41b0-8b68-51b7a47e8df4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x5K2BtzkEX6b",
    "outputId": "19b8066f-a715-4087-cc99-eb9e48ffb491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 60])"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sample.unsqueeze(0)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jE74MX-sEX6b",
    "outputId": "cab81c51-9122-42c1-9efa-0833d2751fd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentAnalysisModel(\n",
       "  (embedding): Embedding(9088, 256)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp0AnjNjEX6c"
   },
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     outputs = model(sample)\n",
    "#     predictions = torch.sigmoid(outputs).squeeze()\n",
    "\n",
    "# predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z9h_bjVpEX6d",
    "outputId": "b6631802-f5fa-4d26-a01d-03b8c1fee546"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2480,  2.7726]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = model(sample)\n",
    "sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h5t9t_WrAPW5",
    "outputId": "ab16415f-210b-4543-8208-e3cb58651578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2480,  2.7726], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6v5jXz8XAPaZ",
    "outputId": "6cc60696-7d09-48f6-8ce9-8a5e67e60608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWca-4_-Gg4k",
    "outputId": "5eb831ec-8749-4926-e4fd-1a535e2e1dc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2480,  2.7726]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = sentiment[0].unsqueeze(0)\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Wwb1oaJGqh8",
    "outputId": "82e54520-44c5-4211-c5cd-c0c1fcb91172"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CygzSPMYGsqy",
    "outputId": "6ca191e9-9cd5-49b2-b7e5-94574441179c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2480,  2.7726], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgim0JF1GwLK",
    "outputId": "76598c78-f915-4fa6-fcf6-e57603586589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0066, 0.9934], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(sentiment[0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ0zXRyqG4EA",
    "outputId": "d74a3bf8-38c9-4e17-b710-a3356baf2b05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.0271, -0.0066], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log_softmax(sentiment[0], dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YB5uqj36Tu4"
   },
   "source": [
    "### Checking the model layer by layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJs3LJUX8jHC"
   },
   "source": [
    "## Acessing the layers of the model i.e. model's attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSukHlxd-oXm"
   },
   "outputs": [],
   "source": [
    "# # Step 2: Define the neural network architecture\n",
    "# class SentimentAnalysisModel(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_dim):\n",
    "#         super(SentimentAnalysisModel, self).__init__()\n",
    "\n",
    "#         self.embedding  =  nn.Embedding(vocab_size, embed_dim)\n",
    "#         self.fc         =  nn.Linear(embed_dim, 2)  # Output dimension is 2 for softmax\n",
    "\n",
    "#         # self.softmax = nn.Softmax(dim=1)   # Softmax over the classes\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded  =  self.embedding(x)\n",
    "#         embedded  =  embedded.mean(dim=1)  # Average embeddings over the sequence length\n",
    "#         logits    =  self.fc(embedded)\n",
    "#         return logits  # Return logits for CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YrvWWtbfbfQL",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "82ae1acd-b7e1-444d-85dc-460267491c6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0469,  0.1570, -0.8016,  ..., -0.7602, -0.8726,  0.8905],\n",
       "         [-0.8407,  0.8203, -1.4808,  ...,  1.2311, -0.4834, -1.1950],\n",
       "         [-0.6799,  1.1161, -0.7586,  ..., -1.9379,  0.4538,  0.9793],\n",
       "         ...,\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508]],\n",
       "\n",
       "        [[ 1.1541, -1.1380,  0.0074,  ...,  1.1503,  0.3124, -0.6342],\n",
       "         [-0.1839, -0.0201,  0.5426,  ..., -0.9350,  0.4004,  0.0916],\n",
       "         [-2.2354, -0.8770, -0.0563,  ..., -0.6899, -0.1936,  0.0255],\n",
       "         ...,\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508]],\n",
       "\n",
       "        [[ 2.2128,  0.6216, -1.3216,  ...,  1.2033,  0.1313, -0.8164],\n",
       "         [-0.4332, -1.8818, -0.5156,  ..., -0.3870,  0.0827,  0.2875],\n",
       "         [-0.0297,  0.7255,  0.6528,  ..., -0.9303,  0.7270,  0.6273],\n",
       "         ...,\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508]],\n",
       "\n",
       "        [[ 0.8083, -0.6676,  0.0121,  ..., -0.9322, -1.3071,  0.0485],\n",
       "         [-0.1984,  1.0650,  0.7025,  ..., -1.3162,  1.9025,  2.9686],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         ...,\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508]],\n",
       "\n",
       "        [[ 1.3726,  0.2716,  1.0203,  ...,  0.4246,  1.3127,  0.1797],\n",
       "         [ 0.9064, -0.3755, -1.8818,  ...,  1.4159,  0.4227,  1.1747],\n",
       "         [-0.0801,  0.9027,  0.4772,  ..., -1.2550, -1.6489,  0.1878],\n",
       "         ...,\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508],\n",
       "         [ 1.3383, -0.8536,  1.0025,  ..., -0.2773,  0.1708,  0.1508]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out = model.embedding(torch.tensor(all_pos_int_tweets_matrix[0:5, :]).long())\n",
    "emb_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gqXQGoF9AMI",
    "outputId": "e4e4b167-13da-4778-fd2c-85908578e654"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 256])"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6NkAFL1m9D8e",
    "outputId": "a1189c31-c341-4f33-f946-f7657617466f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2094, -0.7216,  0.8588,  ..., -0.2970,  0.2088,  0.1938],\n",
       "        [ 0.9746, -0.6268,  0.7783,  ..., -0.1478,  0.2146,  0.1289],\n",
       "        [ 1.1735, -0.7113,  0.8628,  ..., -0.2236,  0.2682,  0.1801],\n",
       "        [ 1.3039, -0.8186,  0.9810,  ..., -0.3055,  0.1751,  0.1961],\n",
       "        [ 1.0031, -0.6838,  0.7074,  ..., -0.3293,  0.1914,  0.2926]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out_mean = emb_out.mean(dim=1)\n",
    "emb_out_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIEr0qaf9J7K",
    "outputId": "c279441d-f7cc-4bf5-c35f-63ac1d68a15c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out_mean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEtEHb6k9M-U",
    "outputId": "3665924f-61b6-4cd4-fc44-5640d12062cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2480,  2.7726],\n",
       "        [-1.6415,  2.1199],\n",
       "        [-1.8441,  2.3707],\n",
       "        [-1.4450,  2.0122],\n",
       "        [-1.5970,  2.0830]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_out = model.fc(emb_out_mean)\n",
    "fc_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Ees7os398rE",
    "outputId": "0a333c41-347a-44a7-b2ef-7e9d906484fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2480,  2.7726],\n",
       "        [-1.6415,  2.1199],\n",
       "        [-1.8441,  2.3707],\n",
       "        [-1.4450,  2.0122],\n",
       "        [-1.5970,  2.0830]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# direct output\n",
    "model(torch.tensor(all_pos_int_tweets_matrix[0:5, :]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDHTtMCM9Yvi",
    "outputId": "6dbcc083-3ea1-4c8a-c195-9fdb1a9f3c3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor(0.0200, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create labels\n",
    "labs = np.ones(5)  # Example labels, normally this would come from your data\n",
    "labs = torch.from_numpy(labs).long()\n",
    "print(labs.shape)  # torch.Size([5])\n",
    "\n",
    "# Calculate the loss\n",
    "loss_value = criterion(fc_out, labs)\n",
    "print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmZ-qxht-cRP"
   },
   "source": [
    "# Doing same but by creating new individual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLMVykwRVxgb"
   },
   "outputs": [],
   "source": [
    "# # Step 2: Define the neural network architecture\n",
    "# class SentimentAnalysisModel(nn.Module):\n",
    "#     def __init__(self, vocab_size, embed_dim):\n",
    "#         super(SentimentAnalysisModel, self).__init__()\n",
    "\n",
    "#         self.embedding  =  nn.Embedding(vocab_size, embed_dim)\n",
    "#         self.fc         =  nn.Linear(embed_dim, 2)  # Output dimension is 2 for softmax\n",
    "\n",
    "#         # self.softmax = nn.Softmax(dim=1)   # Softmax over the classes\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         embedded  =  self.embedding(x)\n",
    "#         embedded  =  embedded.mean(dim=1)  # Average embeddings over the sequence length\n",
    "#         logits    =  self.fc(embedded)\n",
    "#         return logits  # Return logits for CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcVKi78GVxjz"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(Vocab)\n",
    "embed_dim  = 256\n",
    "\n",
    "embedding_l = nn.Embedding(vocab_size, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "MLNSsHgnVxqA",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "27199254-688f-461e-8a0f-1fa45d083672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6163, -0.2989,  1.0442,  ...,  1.2361,  1.7564, -1.3446],\n",
       "         [ 0.6693,  0.8019, -1.3153,  ...,  1.1763, -0.5617, -2.2972],\n",
       "         [ 0.6873, -0.9628,  0.9584,  ..., -0.7802,  1.6621,  1.0394],\n",
       "         ...,\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866]],\n",
       "\n",
       "        [[-1.0554, -0.1916,  1.1963,  ...,  1.5496,  0.7966,  2.0364],\n",
       "         [-1.6666, -0.3436, -1.0833,  ..., -1.2104, -0.6063,  0.3768],\n",
       "         [-0.0413, -0.5167,  1.6903,  ..., -0.4442,  0.2959,  1.0117],\n",
       "         ...,\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866]],\n",
       "\n",
       "        [[-0.7558,  0.4669, -0.1737,  ..., -2.4953, -0.1961,  2.0060],\n",
       "         [-0.8040,  0.1721,  1.7595,  ..., -0.8047, -0.6686, -1.2900],\n",
       "         [ 0.6537,  1.2187, -0.8649,  ...,  0.8097,  0.3517,  0.5932],\n",
       "         ...,\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866]],\n",
       "\n",
       "        [[ 0.8033,  0.0293,  1.2571,  ...,  1.4939,  0.5992,  0.0098],\n",
       "         [-1.6114,  1.1978,  0.6540,  ..., -0.2484, -0.2627, -0.4127],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         ...,\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866]],\n",
       "\n",
       "        [[-0.1526, -0.0134, -0.5816,  ..., -0.3812,  1.3837, -0.7094],\n",
       "         [ 0.4783, -1.0530,  0.9658,  ...,  0.3830, -1.1843,  1.1130],\n",
       "         [ 0.3053,  0.8583,  1.0548,  ..., -0.0775, -1.4425,  2.0134],\n",
       "         ...,\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866],\n",
       "         [-0.7801, -0.8463, -0.5342,  ...,  0.9044, -0.0411,  1.6866]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out = embedding_l(torch.tensor(all_pos_int_tweets_matrix[0:5, :]).long())\n",
    "emb_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fH_0F_X_Vxsd",
    "outputId": "05bf0d0e-1d55-4bab-8300-0c205a66729a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 60, 256])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ixxkCLgZVxu4",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "94fc0935-e8cb-4834-d332-708b2d3aea16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7306, -0.6844, -0.4117,  ...,  0.8305,  0.0019,  1.3776],\n",
       "        [-0.7020, -0.6673, -0.4447,  ...,  0.6698,  0.0739,  1.3668],\n",
       "        [-0.6642, -0.6486, -0.4283,  ...,  0.7389, -0.0488,  1.3870],\n",
       "        [-0.7676, -0.7977, -0.4845,  ...,  0.8950, -0.0342,  1.6236],\n",
       "        [-0.4928, -0.5768, -0.3473,  ...,  0.6053, -0.0243,  1.2973]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out_mean = emb_out.mean(dim=1)\n",
    "emb_out_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSMb-f_gVxxR",
    "outputId": "56099625-ec5c-4002-982f-c32a112d94d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_out_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lOSEVtmVxzL"
   },
   "outputs": [],
   "source": [
    "fc = nn.Linear(embed_dim, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJWiZ4p3W9ED",
    "outputId": "cc4a2b78-5acc-4a86-fbd7-b9fbcd4cc1e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0128, 0.3910],\n",
       "        [0.0232, 0.3510],\n",
       "        [0.0544, 0.3874],\n",
       "        [0.0644, 0.4575],\n",
       "        [0.0208, 0.2836]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_out = fc(emb_out_mean)\n",
    "fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKsJswX8aAC_"
   },
   "outputs": [],
   "source": [
    "soft_l = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTGZ1IBebYfD",
    "outputId": "e14b33b5-dfb3-421c-83dc-8c823a81f941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4066, 0.5934],\n",
       "        [0.4188, 0.5812],\n",
       "        [0.4175, 0.5825],\n",
       "        [0.4030, 0.5970],\n",
       "        [0.4347, 0.5653]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_l(fc_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUKOc0JgfrQa",
    "outputId": "9649f185-0a74-4061-d17a-1b1130298f5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SDgHF-1bYmI",
    "outputId": "2552a04b-4ade-46a9-d64e-c17a368bde48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "tensor(0.5382, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# # Dummy example for the output of the fully connected layer\n",
    "# fc_out = torch.randn(5, 2)  # Example output, normally this would come from your model\n",
    "# print(fc_out.shape)  # torch.Size([5, 2])\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create labels\n",
    "labs = np.ones(5)  # Example labels, normally this would come from your data\n",
    "labs = torch.from_numpy(labs).long()\n",
    "print(labs.shape)  # torch.Size([5])\n",
    "\n",
    "# Calculate the loss\n",
    "loss_value = criterion(fc_out, labs)\n",
    "print(loss_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXkAX5L7-7a8"
   },
   "source": [
    "# Using the last variation with train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "osny5xLBWu_X"
   },
   "outputs": [],
   "source": [
    "# validation data\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "val_x_torch = torch.tensor(val_X, dtype=torch.long)\n",
    "val_y_torch = torch.tensor(val_Y, dtype=torch.long)  # .long for CrossEntropyLoss\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "val_dataset  =  TensorDataset(val_x_torch, val_y_torch)\n",
    "val_gen      =  DataLoader(val_dataset,    batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mE1KclxWbYrO"
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_x_torch = torch.tensor(train_X, dtype=torch.long)\n",
    "train_y_torch = torch.tensor(train_Y, dtype=torch.long)  # .long for CrossEntropyLoss\n",
    "\n",
    "# Create a TensorDataset and DataLoader\n",
    "train_dataset  =  TensorDataset(train_x_torch, train_y_torch)\n",
    "train_gen      =  DataLoader(train_dataset,    batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o-Nn6nssUayO",
    "outputId": "9302a584-b0f7-430e-bd46-060ee67bb71a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hXe4mWFUayR",
    "outputId": "db36c935-a3ca-46b7-872d-22bce22eeb65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7beab2a93790>"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrYlngUxUayS",
    "outputId": "e07d3f8e-d48b-4cfd-99f2-c25379cda989"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([8339, 3760,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset)[7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pjeEYe2KUayT",
    "outputId": "d3282c60-0595-4082-af7c-29cbf48b13fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   7, 2100,    9,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset)[1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guhUsztnUayT",
    "outputId": "11a6e0e7-c0eb-4f06-cd60-a668097bac79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(dataset)[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTYmKki6UayT",
    "outputId": "4d4ad21e-82eb-4676-ce4c-806926332112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7beab2a92f50>"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "cOE0CR6fUayU",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "23b08419-d0bf-484e-ad51-76994e31c90d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [1001,    9,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22, 7876, 7877,  ...,    0,    0,    0],\n",
       "          [ 705,  308,   52,  ...,    0,    0,    0],\n",
       "          [2895, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0])],\n",
       " [tensor([[  24,  327, 1964,  ...,    0,    0,    0],\n",
       "          [  95, 1871,    0,  ...,    0,    0,    0],\n",
       "          [ 144,  376,  294,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3760,  416,   53,  ...,    0,    0,    0],\n",
       "          [ 344,  272,  336,  ...,    0,    0,    0],\n",
       "          [  56,  375,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "          0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])],\n",
       " [tensor([[7548, 3760,    0,  ...,    0,    0,    0],\n",
       "          [3154,  254, 2895,  ...,    0,    0,    0],\n",
       "          [ 136, 3282, 7747,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 232, 2796,  109,  ...,    0,    0,    0],\n",
       "          [1713,  517, 2437,  ...,    0,    0,    0],\n",
       "          [ 376, 1791,  142,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "          0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1])],\n",
       " [tensor([[  95,    0,    0,  ...,    0,    0,    0],\n",
       "          [  98,  709, 3396,  ...,    0,    0,    0],\n",
       "          [  22,   95,  109,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8690,  864,  178,  ...,    0,    0,    0],\n",
       "          [2546,  196,  459,  ...,    0,    0,    0],\n",
       "          [ 819, 1064,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "          0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "          0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1])],\n",
       " [tensor([[1329,  876, 6687,  ...,    0,    0,    0],\n",
       "          [5913,  343, 8271,  ...,    0,    0,    0],\n",
       "          [5906, 5747,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 992,  703, 1266,  ...,    0,    0,    0],\n",
       "          [6957, 6958, 4377,  ...,    0,    0,    0],\n",
       "          [ 538,    9,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "          1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "          0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])],\n",
       " [tensor([[4747,  153,   24,  ...,    0,    0,    0],\n",
       "          [1204,   37,  906,  ...,    0,    0,    0],\n",
       "          [  10, 2410, 6044,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 283,    9,  321,  ...,    0,    0,    0],\n",
       "          [2813, 7241, 7242,  ...,    0,    0,    0],\n",
       "          [7096,  104, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "          0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0])],\n",
       " [tensor([[  22, 1230,  372,  ...,    0,    0,    0],\n",
       "          [5913, 1476, 1713,  ...,    0,    0,    0],\n",
       "          [3970,  237, 3970,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 317,    8,  318,  ...,    0,    0,    0],\n",
       "          [  37, 1706,  420,  ...,    0,    0,    0],\n",
       "          [1389, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "          0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0])],\n",
       " [tensor([[  48, 1106,   92,  ...,    0,    0,    0],\n",
       "          [ 361, 5119,  645,  ...,    0,    0,    0],\n",
       "          [ 278, 8664,  667,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 155, 5591, 3760,  ...,    0,    0,    0],\n",
       "          [8467, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1044, 4706, 1380,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1])],\n",
       " [tensor([[   9,    0,    0,  ...,    0,    0,    0],\n",
       "          [5560, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 416, 4457,  363,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 803, 2653,  344,  ...,    0,    0,    0],\n",
       "          [4783,  416,  893,  ...,    0,    0,    0],\n",
       "          [ 906, 8480,  450,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])],\n",
       " [tensor([[1965, 8743, 1936,  ...,    0,    0,    0],\n",
       "          [4022, 1626, 3760,  ...,    0,    0,    0],\n",
       "          [ 221,  247, 7272,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4186,    9,    0,  ...,    0,    0,    0],\n",
       "          [  21,   22,    9,  ...,    0,    0,    0],\n",
       "          [1396,  235,  276,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "          1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1])],\n",
       " [tensor([[2425, 3760,  537,  ...,    0,    0,    0],\n",
       "          [1013,   63, 6000,  ...,    0,    0,    0],\n",
       "          [1523, 3493, 1013,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 415,   54,   49,  ...,    0,    0,    0],\n",
       "          [  98, 1869, 1066,  ...,    0,    0,    0],\n",
       "          [ 266,    9,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1])],\n",
       " [tensor([[ 443,  458, 3760,  ...,    0,    0,    0],\n",
       "          [1133,  642,   75,  ...,    0,    0,    0],\n",
       "          [ 990,   63,  224,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 212,  212, 7315,  ...,    0,    0,    0],\n",
       "          [5002,  109,  396,  ...,    0,    0,    0],\n",
       "          [ 272,  455,  235,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "          0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "          0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])],\n",
       " [tensor([[ 156,  374,  118,  ...,    0,    0,    0],\n",
       "          [ 235,   76,  385,  ...,    0,    0,    0],\n",
       "          [1006, 3760,   22,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1389,  319,  566,  ...,    0,    0,    0],\n",
       "          [4527,  135,  311,  ...,    0,    0,    0],\n",
       "          [ 426,  970,  309,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1])],\n",
       " [tensor([[   3,    4,   90,  ...,    0,    0,    0],\n",
       "          [ 838, 5826,  591,  ...,    0,    0,    0],\n",
       "          [1523,   50, 8526,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 826,   22, 5004,  ...,    0,    0,    0],\n",
       "          [ 361, 2292, 4390,  ...,    0,    0,    0],\n",
       "          [1411,   62, 3754,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "          0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "          1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1])],\n",
       " [tensor([[7503, 3668, 1224,  ...,    0,    0,    0],\n",
       "          [6780, 2808,  376,  ...,    0,    0,    0],\n",
       "          [ 363,   48, 7334,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1356, 1528, 3760,  ...,    0,    0,    0],\n",
       "          [1213,   63, 4942,  ...,    0,    0,    0],\n",
       "          [ 235,  352,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "          0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "          1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1])],\n",
       " [tensor([[ 185, 1916,  225,  ...,    0,    0,    0],\n",
       "          [ 640,  442, 1778,  ...,    0,    0,    0],\n",
       "          [ 131,  581,   48,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 116, 5591,   44,  ...,    0,    0,    0],\n",
       "          [2356, 2984, 2984,  ...,    0,    0,    0],\n",
       "          [2613,  536,  582,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1])],\n",
       " [tensor([[7107,  269, 2899,  ...,    0,    0,    0],\n",
       "          [  50, 1094,  925,  ...,    0,    0,    0],\n",
       "          [8122, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 363,  222,  946,  ...,    0,    0,    0],\n",
       "          [4201, 4201, 3901,  ...,    0,    0,    0],\n",
       "          [ 249, 9044,   14,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0])],\n",
       " [tensor([[ 246,  231, 1387,  ...,    0,    0,    0],\n",
       "          [3283,  731,  228,  ...,    0,    0,    0],\n",
       "          [4960, 4961, 4962,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 552,   75,  552,  ...,    0,    0,    0],\n",
       "          [  22,  536,   24,  ...,    0,    0,    0],\n",
       "          [ 376,  906,  450,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "          1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "          1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0])],\n",
       " [tensor([[ 344, 1832, 1833,  ...,    0,    0,    0],\n",
       "          [ 392,    9,    0,  ...,    0,    0,    0],\n",
       "          [4733, 4734, 4735,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 843,    9,    0,  ...,    0,    0,    0],\n",
       "          [2265, 1737,  385,  ...,    0,    0,    0],\n",
       "          [  10,  155,  179,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "          1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "          1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0])],\n",
       " [tensor([[ 272, 3452,  185,  ...,    0,    0,    0],\n",
       "          [1157,  722,  781,  ...,    0,    0,    0],\n",
       "          [6473,  443, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 452, 3760, 1446,  ...,    0,    0,    0],\n",
       "          [ 413, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 392,    9,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "          1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "          1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1])],\n",
       " [tensor([[3295,   14, 2650,  ...,    0,    0,    0],\n",
       "          [  45, 6276, 1380,  ...,    0,    0,    0],\n",
       "          [ 591,   71,  136,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [  22,    9,    0,  ...,    0,    0,    0],\n",
       "          [   0,    0,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "          0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "          1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1])],\n",
       " [tensor([[4855,  116,  327,  ...,    0,    0,    0],\n",
       "          [8999,  690, 5900,  ...,    0,    0,    0],\n",
       "          [3270,  536,  667,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22, 1243,  795,  ...,    0,    0,    0],\n",
       "          [ 536,  710,  596,  ...,    0,    0,    0],\n",
       "          [ 766,  458,  116,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "          0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "          1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0])],\n",
       " [tensor([[ 312, 8348, 8349,  ...,    0,    0,    0],\n",
       "          [  10,   95,  443,  ...,    0,    0,    0],\n",
       "          [3234, 3235, 3236,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 990, 1023,  164,  ...,    0,    0,    0],\n",
       "          [  56,  375, 1304,  ...,    0,    0,    0],\n",
       "          [ 416,  916,  935,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "          1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "          1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1])],\n",
       " [tensor([[ 757,    9,  212,  ...,    0,    0,    0],\n",
       "          [ 983,  428,  225,  ...,    0,    0,    0],\n",
       "          [2375, 1379,  130,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          [  85, 1843, 1844,  ...,    0,    0,    0],\n",
       "          [ 272, 2197,  763,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "          0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])],\n",
       " [tensor([[2494,  236,  693,  ...,    0,    0,    0],\n",
       "          [1191,   57,  214,  ...,    0,    0,    0],\n",
       "          [ 256,   85,  118,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 196,  443, 5747,  ...,    0,    0,    0],\n",
       "          [3859,  344, 3860,  ...,    0,    0,    0],\n",
       "          [ 705, 1178,  731,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])],\n",
       " [tensor([[ 396, 1549, 5298,  ...,    0,    0,    0],\n",
       "          [  73,  669,   48,  ...,    0,    0,    0],\n",
       "          [1804, 1980,  769,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  65,  258,  259,  ...,    0,    0,    0],\n",
       "          [6245,  144,  145,  ...,    0,    0,    0],\n",
       "          [1396, 2607,   63,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "          0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "          1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0])],\n",
       " [tensor([[3283,  138, 3760,  ...,    0,    0,    0],\n",
       "          [6464,  308,  109,  ...,    0,    0,    0],\n",
       "          [3215, 6890, 6891,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 376,   73, 1569,  ...,    0,    0,    0],\n",
       "          [ 222,   21,  731,  ...,    0,    0,    0],\n",
       "          [3442, 1156, 7295,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0])],\n",
       " [tensor([[4665,  196,  443,  ...,    0,    0,    0],\n",
       "          [  23,  752, 1182,  ...,    0,    0,    0],\n",
       "          [6826,  141,  130,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 222,  430,    9,  ...,    0,    0,    0],\n",
       "          [3348, 1523,  244,  ...,    0,    0,    0],\n",
       "          [ 635,  697,  130,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "          0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "          0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])],\n",
       " [tensor([[4551,   30,  344,  ...,    0,    0,    0],\n",
       "          [2180, 6787, 3760,  ...,    0,    0,    0],\n",
       "          [ 187, 6490, 6491,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 100,   44, 3066,  ...,    0,    0,    0],\n",
       "          [ 221,  272, 5019,  ...,    0,    0,    0],\n",
       "          [ 445,  109, 1079,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "          1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0])],\n",
       " [tensor([[ 536,  222,   65,  ...,    0,    0,    0],\n",
       "          [ 196,  197,    9,  ...,    0,    0,    0],\n",
       "          [5315,   15,  224,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3760,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 710, 1016,  498,  ...,    0,    0,    0],\n",
       "          [3795, 2303,  230,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "          0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "          1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1])],\n",
       " [tensor([[3792,  342,  182,  ...,    0,    0,    0],\n",
       "          [ 582,  179,  116,  ...,    0,    0,    0],\n",
       "          [3760, 1218,  229,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  91,   22,  214,  ...,    0,    0,    0],\n",
       "          [ 826,  221, 8109,  ...,    0,    0,    0],\n",
       "          [6802, 6157, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0])],\n",
       " [tensor([[  63, 1748,   89,  ...,    0,    0,    0],\n",
       "          [8757,  643,   92,  ...,    0,    0,    0],\n",
       "          [ 416, 2601, 6378,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 222,  223,   25,  ...,    0,    0,    0],\n",
       "          [4520, 4783,  973,  ...,    0,    0,    0],\n",
       "          [1732,  753, 4539,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "          0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "          0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1])],\n",
       " [tensor([[ 715, 1380,  312,  ...,    0,    0,    0],\n",
       "          [ 929,   95, 2917,  ...,    0,    0,    0],\n",
       "          [1560, 1807,  127,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  60,  725, 1594,  ...,    0,    0,    0],\n",
       "          [6191,  709,   24,  ...,    0,    0,    0],\n",
       "          [4725, 6105,  737,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "          1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0])],\n",
       " [tensor([[ 159,   91, 4204,  ...,    0,    0,    0],\n",
       "          [1379,   22,  219,  ...,    0,    0,    0],\n",
       "          [1706,   48,  553,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  57,    9,    0,  ...,    0,    0,    0],\n",
       "          [  22, 2314, 2315,  ...,    0,    0,    0],\n",
       "          [1742, 1742,  591,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "          0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1])],\n",
       " [tensor([[ 235,  415,   22,  ...,    0,    0,    0],\n",
       "          [ 272,  322,  179,  ...,    0,    0,    0],\n",
       "          [ 222,  153,  777,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7048,  837,  667,  ...,    0,    0,    0],\n",
       "          [3423, 1142,  453,  ...,    0,    0,    0],\n",
       "          [  22,   75,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "          1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "          1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1])],\n",
       " [tensor([[ 673,  415, 3760,  ...,    0,    0,    0],\n",
       "          [2581, 2582,  552,  ...,    0,    0,    0],\n",
       "          [  22,  365, 3746,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 427, 1472, 4074,  ...,    0,    0,    0],\n",
       "          [3924, 1417, 7145,  ...,    0,    0,    0],\n",
       "          [ 109,   95,  204,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "          0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1])],\n",
       " [tensor([[ 134,  396, 6815,  ...,    0,    0,    0],\n",
       "          [  22,  365, 2618,  ...,    0,    0,    0],\n",
       "          [ 498, 8726, 1982,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  14,  196,  443,  ...,    0,    0,    0],\n",
       "          [  37,  839,  392,  ...,    0,    0,    0],\n",
       "          [ 317,   44,  318,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1])],\n",
       " [tensor([[1834,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 236,  706, 2197,  ...,    0,    0,    0],\n",
       "          [  75,  725,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 893,  182, 6393,  ...,    0,    0,    0],\n",
       "          [2144,    9,    0,  ...,    0,    0,    0],\n",
       "          [4225, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "          1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0])],\n",
       " [tensor([[  98,  246,   50,  ...,    0,    0,    0],\n",
       "          [ 133,    9,  109,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 179,  372,    9,  ...,    0,    0,    0],\n",
       "          [7324, 3728, 6130,  ...,    0,    0,    0],\n",
       "          [1560,  178,  643,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "          0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0])],\n",
       " [tensor([[ 336,  626,  643,  ...,    0,    0,    0],\n",
       "          [7561, 2005,  350,  ...,    0,    0,    0],\n",
       "          [ 235,  171,  309,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 376,   73, 7578,  ...,    0,    0,    0],\n",
       "          [ 566, 2400,    9,  ...,    0,    0,    0],\n",
       "          [ 131, 4670, 4671,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "          0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1])],\n",
       " [tensor([[ 498,  615,  616,  ...,    0,    0,    0],\n",
       "          [ 450,  451, 1532,  ...,    0,    0,    0],\n",
       "          [ 519,  109,  906,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 693,  582,  744,  ...,    0,    0,    0],\n",
       "          [  99, 4885,  566,  ...,    0,    0,    0],\n",
       "          [2750, 5747,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "          0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "          1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0])],\n",
       " [tensor([[5672,    9,    0,  ...,    0,    0,    0],\n",
       "          [1160,   54,  344,  ...,    0,    0,    0],\n",
       "          [  54,  109,  210,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 225,    9,    0,  ...,    0,    0,    0],\n",
       "          [2671, 2672, 2673,  ...,    0,    0,    0],\n",
       "          [ 413, 1522, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "          0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "          1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0])],\n",
       " [tensor([[  55,    9,    0,  ...,    0,    0,    0],\n",
       "          [5942, 3760, 1737,  ...,    0,    0,    0],\n",
       "          [ 566, 1044,  830,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  56,  375, 1629,  ...,    0,    0,    0],\n",
       "          [ 586,  118,  143,  ...,    0,    0,    0],\n",
       "          [ 566,  140, 1430,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "          0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1])],\n",
       " [tensor([[1691, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 636, 5747,  142,  ...,    0,    0,    0],\n",
       "          [  98, 1453, 2418,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  66,  976, 1000,  ...,    0,    0,    0],\n",
       "          [  52, 3486, 3487,  ...,    0,    0,    0],\n",
       "          [3587,    9, 3935,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1])],\n",
       " [tensor([[6810, 7957, 7737,  ...,    0,    0,    0],\n",
       "          [ 857,  667, 2085,  ...,    0,    0,    0],\n",
       "          [ 970,   44,  443,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8790, 2815,  983,  ...,    0,    0,    0],\n",
       "          [  98,  599,   37,  ...,    0,    0,    0],\n",
       "          [1043,  118, 1690,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "          1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "          1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1])],\n",
       " [tensor([[ 141,  416, 1594,  ...,    0,    0,    0],\n",
       "          [  52, 3392, 4760,  ...,    0,    0,    0],\n",
       "          [2808,   73, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3129, 5276,  419,  ...,    0,    0,    0],\n",
       "          [4994, 6948,   92,  ...,    0,    0,    0],\n",
       "          [1258,   89,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "          0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "          0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])],\n",
       " [tensor([[  22,   50,   75,  ...,    0,    0,    0],\n",
       "          [6850,  136, 1691,  ...,    0,    0,    0],\n",
       "          [ 100, 3437,   54,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1594,  109, 1013,  ...,    0,    0,    0],\n",
       "          [ 133,   92, 3760,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "          1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "          0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0])],\n",
       " [tensor([[ 376,   65,  256,  ...,    0,    0,    0],\n",
       "          [ 131,  246,   48,  ...,    0,    0,    0],\n",
       "          [ 272,  767,  442,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 413, 1625,  667,  ...,    0,    0,    0],\n",
       "          [5788, 4594, 5789,  ...,    0,    0,    0],\n",
       "          [ 238,   73, 7844,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0])],\n",
       " [tensor([[4618, 4619,  927,  ...,    0,    0,    0],\n",
       "          [5852, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  60, 5991,   91,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,  882, 3512,  ...,    0,    0,    0],\n",
       "          [3094,   92,  620,  ...,    0,    0,    0],\n",
       "          [5585,  582,  912,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "          0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1])],\n",
       " [tensor([[  22, 7842,  627,  ...,    0,    0,    0],\n",
       "          [7755,   50, 7755,  ...,    0,    0,    0],\n",
       "          [  22,    9,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 735,  443,    9,  ...,    0,    0,    0],\n",
       "          [5875, 3760, 5876,  ...,    0,    0,    0],\n",
       "          [ 133,    9,  882,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "          0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1])],\n",
       " [tensor([[6377, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1006,  448, 2410,  ...,    0,    0,    0],\n",
       "          [7481,   70, 1387,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 512,  222, 1379,  ...,    0,    0,    0],\n",
       "          [  14, 1559, 7072,  ...,    0,    0,    0],\n",
       "          [ 348,  443, 6830,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0])],\n",
       " [tensor([[ 272,  118,  790,  ...,    0,    0,    0],\n",
       "          [ 876, 2641, 3760,  ...,    0,    0,    0],\n",
       "          [ 311, 4577, 9008,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 582, 3760,    0,  ...,    0,    0,    0],\n",
       "          [2000,  698,  566,  ...,    0,    0,    0],\n",
       "          [ 663,  664,  665,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "          1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1])],\n",
       " [tensor([[1424, 7767, 5879,  ...,    0,    0,    0],\n",
       "          [ 927,  376, 3419,  ...,    0,    0,    0],\n",
       "          [ 566,  882,  890,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1769,  582,  582,  ...,    0,    0,    0],\n",
       "          [ 148,  140, 7162,  ...,    0,    0,    0],\n",
       "          [ 157,  751,  376,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "          0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "          0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])],\n",
       " [tensor([[1230,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 312,  237, 5389,  ...,    0,    0,    0],\n",
       "          [ 376,   91,  620,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 134, 7497, 7498,  ...,    0,    0,    0],\n",
       "          [1094,  632, 6611,  ...,    0,    0,    0],\n",
       "          [  50, 1632, 7721,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "          1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0])],\n",
       " [tensor([[7673, 1791, 1572,  ...,    0,    0,    0],\n",
       "          [3305,  327, 1747,  ...,    0,    0,    0],\n",
       "          [ 763, 1044,  854,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1006, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1349, 1253, 3760,  ...,    0,    0,    0],\n",
       "          [ 221, 7809,  363,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "          0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])],\n",
       " [tensor([[6893,  821,   95,  ...,    0,    0,    0],\n",
       "          [  22,  625,   54,  ...,    0,    0,    0],\n",
       "          [ 860,  487, 1909,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [3479,   45,   44,  ...,    0,    0,    0],\n",
       "          [ 131, 1074,  838,  ...,    0,    0,    0],\n",
       "          [8288, 8289, 8290,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "          1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "          1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0])],\n",
       " [tensor([[4131,   60,  319,  ...,    0,    0,    0],\n",
       "          [6972, 5881, 6973,  ...,    0,    0,    0],\n",
       "          [ 196, 1321,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 229,  906,  365,  ...,    0,    0,    0],\n",
       "          [ 246,  378, 2490,  ...,    0,    0,    0],\n",
       "          [ 165, 1212, 2630,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "          0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "          1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0])],\n",
       " [tensor([[6228,  109, 7979,  ...,    0,    0,    0],\n",
       "          [2878, 1887,  148,  ...,    0,    0,    0],\n",
       "          [ 222,  627,  350,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 838, 3399,  428,  ...,    0,    0,    0],\n",
       "          [ 596, 6894, 5747,  ...,    0,    0,    0],\n",
       "          [1525, 6946,   98,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "          0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0])],\n",
       " [tensor([[ 238,  235, 4890,  ...,    0,    0,    0],\n",
       "          [ 133, 1208,   37,  ...,    0,    0,    0],\n",
       "          [ 311,   73, 8721,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 648,   48, 5747,  ...,    0,    0,    0],\n",
       "          [1737,  138,   53,  ...,    0,    0,    0],\n",
       "          [ 155, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0])],\n",
       " [tensor([[  22,   50,   73,  ...,    0,    0,    0],\n",
       "          [ 155, 1706, 1594,  ...,    0,    0,    0],\n",
       "          [1259,  658,   92,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8020,  238, 8021,  ...,    0,    0,    0],\n",
       "          [ 512, 6845, 3760,  ...,    0,    0,    0],\n",
       "          [1909, 2035,  589,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "          0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "          1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1])],\n",
       " [tensor([[ 581,   85, 3813,  ...,    0,    0,    0],\n",
       "          [1204,   65,  659,  ...,    0,    0,    0],\n",
       "          [ 709,  270,  230,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 579,   73, 6205,  ...,    0,    0,    0],\n",
       "          [2000,   75,    0,  ...,    0,    0,    0],\n",
       "          [ 366,   48, 1122,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "          1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "          0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1])],\n",
       " [tensor([[1253,    8, 3760,  ...,    0,    0,    0],\n",
       "          [5747,    0,    0,  ...,    0,    0,    0],\n",
       "          [2723, 8994,   68,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5336, 5336, 5336,  ...,    0,    0,    0],\n",
       "          [ 735,  597,  182,  ...,    0,    0,    0],\n",
       "          [   9,  536,  537,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1])],\n",
       " [tensor([[6438,  229,   85,  ...,    0,    0,    0],\n",
       "          [ 131,   22,  625,  ...,    0,    0,    0],\n",
       "          [ 498, 1371,   75,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 827,  268,  715,  ...,    0,    0,    0],\n",
       "          [ 131, 8327,  566,  ...,    0,    0,    0],\n",
       "          [ 868, 3673,  118,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "          1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1])],\n",
       " [tensor([[ 854,  627,  363,  ...,    0,    0,    0],\n",
       "          [1121,   65,  550,  ...,    0,    0,    0],\n",
       "          [ 232, 2796,  109,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  56,  375, 5722,  ...,    0,    0,    0],\n",
       "          [ 269,  148,   75,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "          1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0])],\n",
       " [tensor([[4934, 4935, 2968,  ...,    0,    0,    0],\n",
       "          [ 221,  303,   98,  ...,    0,    0,    0],\n",
       "          [  22,    9,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  626, 4704,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [ 254,  812,  595,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "          1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0])],\n",
       " [tensor([[9010, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  56,   57,  118,  ...,    0,    0,    0],\n",
       "          [  48,  118,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          [ 136,  591,  976,  ...,    0,    0,    0],\n",
       "          [1182, 5656, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "          1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0])],\n",
       " [tensor([[1548, 1549, 1550,  ...,    0,    0,    0],\n",
       "          [8197, 1424,  182,  ...,    0,    0,    0],\n",
       "          [ 272,  305, 6237,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,  118, 1396,  ...,    0,    0,    0],\n",
       "          [ 827,  827,   50,  ...,    0,    0,    0],\n",
       "          [ 419,  219,  986,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "          1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "          0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0])],\n",
       " [tensor([[ 140,   73, 4644,  ...,    0,    0,    0],\n",
       "          [1472, 3297,    9,  ...,    0,    0,    0],\n",
       "          [ 763,   73, 1106,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  55, 1044, 1045,  ...,    0,    0,    0],\n",
       "          [8378, 8379, 3760,  ...,    0,    0,    0],\n",
       "          [   0,    0,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "          0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1])],\n",
       " [tensor([[1159, 3760,  133,  ...,    0,    0,    0],\n",
       "          [4351, 3760,    0,  ...,    0,    0,    0],\n",
       "          [5460, 1380,  868,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 136,  428, 2146,  ...,    0,    0,    0],\n",
       "          [5776, 3348,  363,  ...,    0,    0,    0],\n",
       "          [ 579,  215, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "          1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0])],\n",
       " [tensor([[8974, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 272, 6593,  536,  ...,    0,    0,    0],\n",
       "          [ 582,  625, 2791,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 268,  127,    9,  ...,    0,    0,    0],\n",
       "          [ 222,  153,  777,  ...,    0,    0,    0],\n",
       "          [ 136,  414, 3528,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "          0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "          1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0])],\n",
       " [tensor([[ 238, 1522,   48,  ...,    0,    0,    0],\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [ 680,   25,  342,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22,   95, 2557,  ...,    0,    0,    0],\n",
       "          [5834, 5835,  179,  ...,    0,    0,    0],\n",
       "          [1341, 5361, 5362,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1])],\n",
       " [tensor([[4609, 8235, 8236,  ...,    0,    0,    0],\n",
       "          [7618,  787, 3760,  ...,    0,    0,    0],\n",
       "          [6521,  693, 6522,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,  208,   95,  ...,    0,    0,    0],\n",
       "          [1559,  627,  164,  ...,    0,    0,    0],\n",
       "          [ 674,   85,   54,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "          1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "          0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1])],\n",
       " [tensor([[5254, 3028, 3098,  ...,    0,    0,    0],\n",
       "          [ 229,   85, 3760,  ...,    0,    0,    0],\n",
       "          [ 155,   60, 2005,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8339, 3760,    0,  ...,    0,    0,    0],\n",
       "          [1005,   45,   63,  ...,    0,    0,    0],\n",
       "          [ 658,  325,  171,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "          1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1])],\n",
       " [tensor([[ 579,  374, 3760,  ...,    0,    0,    0],\n",
       "          [3187, 3188,  238,  ...,    0,    0,    0],\n",
       "          [7221,  319, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1056,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 819, 4122,  100,  ...,    0,    0,    0],\n",
       "          [ 179, 1158, 2614,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "          0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1])],\n",
       " [tensor([[ 336, 1013, 1035,  ...,    0,    0,    0],\n",
       "          [ 134, 3164,  134,  ...,    0,    0,    0],\n",
       "          [ 693, 4476,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1050, 1051, 1052,  ...,    0,    0,    0],\n",
       "          [  22, 3994,    9,  ...,    0,    0,    0],\n",
       "          [ 228,  196, 3872,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])],\n",
       " [tensor([[ 257, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 784,  452,  785,  ...,    0,    0,    0],\n",
       "          [ 446,   62, 7003,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 243,  244,  245,  ...,    0,    0,    0],\n",
       "          [6656, 6657, 6658,  ...,    0,    0,    0],\n",
       "          [1044, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "          0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "          1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0])],\n",
       " [tensor([[ 563,  564,  565,  ...,    0,    0,    0],\n",
       "          [4586,  670,  130,  ...,    0,    0,    0],\n",
       "          [  22,  791, 1494,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 133, 2556,   75,  ...,    0,    0,    0],\n",
       "          [ 105,  595, 6639,  ...,    0,    0,    0],\n",
       "          [1013,   44,   92,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0])],\n",
       " [tensor([[6369, 6370, 3760,  ...,    0,    0,    0],\n",
       "          [4245,  342,  182,  ...,    0,    0,    0],\n",
       "          [ 376, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  95,    0,    0,  ...,    0,    0,    0],\n",
       "          [3760, 1329, 8725,  ...,    0,    0,    0],\n",
       "          [  85,  706, 6165,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0])],\n",
       " [tensor([[8127, 1243, 3096,  ...,    0,    0,    0],\n",
       "          [ 579,   73, 3760,  ...,    0,    0,    0],\n",
       "          [ 254, 1044,  254,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 376, 6168,   95,  ...,    0,    0,    0],\n",
       "          [3054,  235, 1246,  ...,    0,    0,    0],\n",
       "          [8321, 8322, 8323,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "          1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "          1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0])],\n",
       " [tensor([[  50, 3432,    9,  ...,    0,    0,    0],\n",
       "          [6238, 1534, 1737,  ...,    0,    0,    0],\n",
       "          [5854, 5855, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 566,   97,  838,  ...,    0,    0,    0],\n",
       "          [2047, 7983, 1943,  ...,    0,    0,    0],\n",
       "          [ 131,   22,  625,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "          1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "          1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])],\n",
       " [tensor([[  23,   24,   25,  ...,    0,    0,    0],\n",
       "          [5784,  375, 3760,  ...,    0,    0,    0],\n",
       "          [3379,  182, 3380,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2641, 3760,    0,  ...,    0,    0,    0],\n",
       "          [7084,  222,  705,  ...,    0,    0,    0],\n",
       "          [ 536,   27,  731,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "          0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "          1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1])],\n",
       " [tensor([[2809,  990,   45,  ...,    0,    0,    0],\n",
       "          [5477, 5667,   89,  ...,    0,    0,    0],\n",
       "          [  55, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7989, 7990, 5903,  ...,    0,    0,    0],\n",
       "          [1943,  761,    9,  ...,    0,    0,    0],\n",
       "          [1340,  646,    9,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "          1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1])],\n",
       " [tensor([[5113,    9,  376,  ...,    0,    0,    0],\n",
       "          [ 579,  348,   94,  ...,    0,    0,    0],\n",
       "          [ 550, 7938, 1531,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1017,  566,  311,  ...,    0,    0,    0],\n",
       "          [ 626,  638, 4495,  ...,    0,    0,    0],\n",
       "          [ 224,  609,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "          1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "          0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1])],\n",
       " [tensor([[6987, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 131, 2344, 2345,  ...,    0,    0,    0],\n",
       "          [5788, 4594, 1423,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 222,   48,  100,  ...,    0,    0,    0],\n",
       "          [  45,  127, 3760,  ...,    0,    0,    0],\n",
       "          [ 352,  130, 3397,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "          1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0])],\n",
       " [tensor([[1792,  363,  229,  ...,    0,    0,    0],\n",
       "          [ 838, 1507, 1706,  ...,    0,    0,    0],\n",
       "          [5144,   96,   75,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [5175,   75,    0,  ...,    0,    0,    0],\n",
       "          [  45,   46,    9,  ...,    0,    0,    0],\n",
       "          [  22,  242,  626,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "          0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "          1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1])],\n",
       " [tensor([[ 701,  116,  247,  ...,    0,    0,    0],\n",
       "          [ 970,  573, 2792,  ...,    0,    0,    0],\n",
       "          [ 413,   97, 5747,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6541,  447,  179,  ...,    0,    0,    0],\n",
       "          [ 221,   75,    0,  ...,    0,    0,    0],\n",
       "          [3620,  538, 8791,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "          0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "          1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0])],\n",
       " [tensor([[8919, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 366,    9, 2419,  ...,    0,    0,    0],\n",
       "          [1044,  536,  294,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 238,   73, 1528,  ...,    0,    0,    0],\n",
       "          [  37,  598, 5464,  ...,    0,    0,    0],\n",
       "          [ 501, 2485,  267,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "          1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0])],\n",
       " [tensor([[  98, 1460,   98,  ...,    0,    0,    0],\n",
       "          [  96, 3009, 3010,  ...,    0,    0,    0],\n",
       "          [ 249,  344,  344,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 131,    9,  626,  ...,    0,    0,    0],\n",
       "          [  14,  917,  312,  ...,    0,    0,    0],\n",
       "          [2109,   52,   44,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "          1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "          0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1])],\n",
       " [tensor([[ 690, 2485, 2795,  ...,    0,    0,    0],\n",
       "          [8064, 3442,  566,  ...,    0,    0,    0],\n",
       "          [ 658,  591,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  54,  100,   45,  ...,    0,    0,    0],\n",
       "          [8733,  246,  933,  ...,    0,    0,    0],\n",
       "          [ 109, 4583,  134,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "          1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "          1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0])],\n",
       " [tensor([[1380,  363,   98,  ...,    0,    0,    0],\n",
       "          [2563,  376, 2564,  ...,    0,    0,    0],\n",
       "          [6007, 5002, 1334,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 427,  231,  109,  ...,    0,    0,    0],\n",
       "          [3760,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 551,  342, 4932,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "          0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1])],\n",
       " [tensor([[ 316, 2838,    9,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [ 164,  790, 6272,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 933,  935,  231,  ...,    0,    0,    0],\n",
       "          [1027,  310, 1170,  ...,    0,    0,    0],\n",
       "          [1156, 1170, 5830,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0])],\n",
       " [tensor([[  22, 2549,  413,  ...,    0,    0,    0],\n",
       "          [ 235,  415,  247,  ...,    0,    0,    0],\n",
       "          [6983, 3201, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2569,   48, 2570,  ...,    0,    0,    0],\n",
       "          [   9,   22,    0,  ...,    0,    0,    0],\n",
       "          [ 953,  670, 2616,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "          0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "          0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1])],\n",
       " [tensor([[ 311,  308,  711,  ...,    0,    0,    0],\n",
       "          [ 482, 5290,   75,  ...,    0,    0,    0],\n",
       "          [2177,  601,  139,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1570, 3760,    0,  ...,    0,    0,    0],\n",
       "          [  22,   27,  196,  ...,    0,    0,    0],\n",
       "          [ 447,  519, 1472,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0])],\n",
       " [tensor([[ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [  22,   95, 3669,  ...,    0,    0,    0],\n",
       "          [ 134, 1436, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 136, 1398, 1399,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [3313, 3760,    0,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "          1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0])],\n",
       " [tensor([[2129, 7899, 3760,  ...,    0,    0,    0],\n",
       "          [3527,  363,  148,  ...,    0,    0,    0],\n",
       "          [1421,  927,  363,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1099, 5703,    9,  ...,    0,    0,    0],\n",
       "          [ 360,    9,  563,  ...,    0,    0,    0],\n",
       "          [ 229, 2616,  196,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "          1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "          1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0])],\n",
       " [tensor([[  50,  918,  919,  ...,    0,    0,    0],\n",
       "          [ 140,  342,   98,  ...,    0,    0,    0],\n",
       "          [9009, 1499,   14,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 159, 1253,  482,  ...,    0,    0,    0],\n",
       "          [1380,   98,  419,  ...,    0,    0,    0],\n",
       "          [ 777, 8051,  777,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "          1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "          1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0])],\n",
       " [tensor([[ 271,  118,    0,  ...,    0,    0,    0],\n",
       "          [8180,  579,  109,  ...,    0,    0,    0],\n",
       "          [ 591,   95, 1574,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 541, 8078, 2796,  ...,    0,    0,    0],\n",
       "          [ 517, 8042,  336,  ...,    0,    0,    0],\n",
       "          [ 413, 8030,  667,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "          1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0])],\n",
       " [tensor([[  10,  246,  127,  ...,    0,    0,    0],\n",
       "          [7898, 3261,  155,  ...,    0,    0,    0],\n",
       "          [1257, 5727, 5728,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  22, 5713, 3472,  ...,    0,    0,    0],\n",
       "          [ 155,  601,  667,  ...,    0,    0,    0],\n",
       "          [8409,  566,  363,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "          1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0])],\n",
       " [tensor([[  98, 6504, 2222,  ...,    0,    0,    0],\n",
       "          [ 308,   52, 1469,  ...,    0,    0,    0],\n",
       "          [6066, 1613, 1329,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 316, 1066, 3007,  ...,    0,    0,    0],\n",
       "          [1084,  109, 7949,  ...,    0,    0,    0],\n",
       "          [1559,  970, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "          1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "          0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0])],\n",
       " [tensor([[3760,  906,   63,  ...,    0,    0,    0],\n",
       "          [8134,   85,   92,  ...,    0,    0,    0],\n",
       "          [ 582,  259,  118,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 221,  235,  253,  ...,    0,    0,    0],\n",
       "          [ 566, 1044, 3760,  ...,    0,    0,    0],\n",
       "          [4069, 1895,  821,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "          0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1])],\n",
       " [tensor([[5881,   59, 6462,  ...,    0,    0,    0],\n",
       "          [ 308,  795,  476,  ...,    0,    0,    0],\n",
       "          [  44,   44, 1534,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  14, 3760,    0,  ...,    0,    0,    0],\n",
       "          [5135, 3877,  935,  ...,    0,    0,    0],\n",
       "          [  10,  128,  370,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "          1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "          0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1])],\n",
       " [tensor([[ 134,  165, 5881,  ...,    0,    0,    0],\n",
       "          [3752, 2141, 3753,  ...,    0,    0,    0],\n",
       "          [ 308,  374, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 272,   14,  246,  ...,    0,    0,    0],\n",
       "          [ 308, 3760,    0,  ...,    0,    0,    0],\n",
       "          [3121,  235, 2895,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "          1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1])],\n",
       " [tensor([[ 221,  303,  304,  ...,    0,    0,    0],\n",
       "          [3604,  632,  283,  ...,    0,    0,    0],\n",
       "          [1044, 2136, 3037,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 249,    9,    0,  ...,    0,    0,    0],\n",
       "          [1550,  238,  406,  ...,    0,    0,    0],\n",
       "          [ 196,  792,  305,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "          1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1])],\n",
       " [tensor([[ 311, 8058, 8059,  ...,    0,    0,    0],\n",
       "          [ 838, 1507, 6831,  ...,    0,    0,    0],\n",
       "          [6281, 6782, 8595,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2109,  725,    9,  ...,    0,    0,    0],\n",
       "          [ 914,  914,  914,  ...,    0,    0,    0],\n",
       "          [1308,   44,  116,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "          0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "          1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1])],\n",
       " [tensor([[7419,  840, 3760,  ...,    0,    0,    0],\n",
       "          [ 136, 3784,  305,  ...,    0,    0,    0],\n",
       "          [ 116,   56,   44,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4080,    9,    0,  ...,    0,    0,    0],\n",
       "          [ 222,  709, 1027,  ...,    0,    0,    0],\n",
       "          [5857, 2143, 5747,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "          1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "          1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0])],\n",
       " [tensor([[7654, 7655, 3760,  ...,    0,    0,    0],\n",
       "          [ 413, 8611,  667,  ...,    0,    0,    0],\n",
       "          [ 171, 3079, 6082,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 591, 1472,  187,  ...,    0,    0,    0],\n",
       "          [2127,  566,  610,  ...,    0,    0,    0],\n",
       "          [ 860,  229,   48,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "          1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "          1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0])],\n",
       " [tensor([[7684, 2206, 3760,  ...,    0,    0,    0],\n",
       "          [ 229, 4153, 1334,  ...,    0,    0,    0],\n",
       "          [4179,  235,  130,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 270,  866, 1812,  ...,    0,    0,    0],\n",
       "          [1939,  118,    0,  ...,    0,    0,    0],\n",
       "          [ 316,  138,  346,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "          1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "          1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])],\n",
       " [tensor([[  22, 1214,  457,  ...,    0,    0,    0],\n",
       "          [3201, 3202,    9,  ...,    0,    0,    0],\n",
       "          [ 239,  246, 2795,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [6379, 6380, 6381,  ...,    0,    0,    0],\n",
       "          [2940,  882, 2941,  ...,    0,    0,    0],\n",
       "          [ 231, 2783, 3230,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "          1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "          0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])],\n",
       " [tensor([[1525,  254, 1360,  ...,    0,    0,    0],\n",
       "          [ 737,  427,  271,  ...,    0,    0,    0],\n",
       "          [1255, 8000, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2127,  235,  393,  ...,    0,    0,    0],\n",
       "          [ 566,  140,  246,  ...,    0,    0,    0],\n",
       "          [ 221,  235,  627,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "          0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "          1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0])],\n",
       " [tensor([[ 254,    9,  143,  ...,    0,    0,    0],\n",
       "          [1499,    9,    0,  ...,    0,    0,    0],\n",
       "          [6508,   14, 2943,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [  95,   22,   14,  ...,    0,    0,    0],\n",
       "          [ 268,   45,  751,  ...,    0,    0,    0],\n",
       "          [ 773,  171, 6557,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "          0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "          0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0])],\n",
       " [tensor([[ 235,  386, 1599,  ...,    0,    0,    0],\n",
       "          [  54,  109,  179,  ...,    0,    0,    0],\n",
       "          [5747,   54,  130,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 762, 5088,  536,  ...,    0,    0,    0],\n",
       "          [ 720,  310,  185,  ...,    0,    0,    0],\n",
       "          [  85,  392,  235,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1])],\n",
       " [tensor([[ 458,  229, 4245,  ...,    0,    0,    0],\n",
       "          [ 620,   21,    9,  ...,    0,    0,    0],\n",
       "          [ 419,  703,    9,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8265, 8265, 8265,  ...,    0,    0,    0],\n",
       "          [8358,  706, 8359,  ...,    0,    0,    0],\n",
       "          [ 498, 1392, 1673,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "          0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "          1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1])],\n",
       " [tensor([[ 351,  838,  204,  ...,    0,    0,    0],\n",
       "          [ 754,   14, 3760,  ...,    0,    0,    0],\n",
       "          [9058, 9059, 3760,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1013,  109,   15,  ...,    0,    0,    0],\n",
       "          [ 131, 8474,  262,  ...,    0,    0,    0],\n",
       "          [3760,  136,  249,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "          1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "          0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0])],\n",
       " [tensor([[  48, 4073,    9,  ...,    0,    0,    0],\n",
       "          [ 308, 6293,   14,  ...,    0,    0,    0],\n",
       "          [1675, 1676, 1677,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [2356,   92, 3760,  ...,    0,    0,    0],\n",
       "          [ 155,  144,  145,  ...,    0,    0,    0],\n",
       "          [ 635,   15,  878,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "          1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "          1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])],\n",
       " [tensor([[ 317,   44,  318,  ...,    0,    0,    0],\n",
       "          [3924, 3760, 1044,  ...,    0,    0,    0],\n",
       "          [   9,    0,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1021, 8200,  876,  ...,    0,    0,    0],\n",
       "          [   9,    0,    0,  ...,    0,    0,    0],\n",
       "          [ 372, 7513,  157,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "          0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "          1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])],\n",
       " [tensor([[5925, 3760,    0,  ...,    0,    0,    0],\n",
       "          [ 196,  697,   75,  ...,    0,    0,    0],\n",
       "          [ 235, 3354,  283,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [8843, 3240, 1310,  ...,    0,    0,    0],\n",
       "          [ 144,  376, 1931,  ...,    0,    0,    0],\n",
       "          [ 752, 1201,  254,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "          0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "          0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0])],\n",
       " [tensor([[ 413, 5747,    0,  ...,    0,    0,    0],\n",
       "          [  50,  658,  659,  ...,    0,    0,    0],\n",
       "          [ 893,   92,  182,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 317,    8,  318,  ...,    0,    0,    0],\n",
       "          [ 629,  876,  116,  ...,    0,    0,    0],\n",
       "          [1179,  561, 8902,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "          1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0])],\n",
       " [tensor([[ 136,  228, 4491,  ...,    0,    0,    0],\n",
       "          [3301,  306,    9,  ...,    0,    0,    0],\n",
       "          [1936, 3760,    0,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [4179,   75,   22,  ...,    0,    0,    0],\n",
       "          [  23,  517,  468,  ...,    0,    0,    0],\n",
       "          [1035, 3713, 1106,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0])],\n",
       " [tensor([[ 325,    9,    0,  ...,    0,    0,    0],\n",
       "          [1596,  953, 1549,  ...,    0,    0,    0],\n",
       "          [1389,    9, 4203,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 136,   95, 3760,  ...,    0,    0,    0],\n",
       "          [ 133,    9,  109,  ...,    0,    0,    0],\n",
       "          [6029,  632,  428,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "          0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "          0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])],\n",
       " [tensor([[1013,  136, 4581,  ...,    0,    0,    0],\n",
       "          [ 316, 2915, 2644,  ...,    0,    0,    0],\n",
       "          [ 660, 2057, 6266,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 312,  566,   73,  ...,    0,    0,    0],\n",
       "          [ 327,    8,  263,  ...,    0,    0,    0],\n",
       "          [1968, 1969, 1970,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "          0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1])],\n",
       " [tensor([[2836, 2837,    9,  ...,    0,    0,    0],\n",
       "          [7352, 7352, 7352,  ...,    0,    0,    0],\n",
       "          [ 229,  838,  268,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7213, 3950, 5882,  ...,    0,    0,    0],\n",
       "          [6429, 1887, 2355,  ...,    0,    0,    0],\n",
       "          [ 109,  144,  419,  ...,    0,    0,    0]]),\n",
       "  tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "          1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0])],\n",
       " [tensor([[  97,  178, 3760,  ...,    0,    0,    0],\n",
       "          [ 312,  519,  109,  ...,    0,    0,    0],\n",
       "          [  10, 2783, 2442,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [7801, 7798, 3760,  ...,    0,    0,    0],\n",
       "          [9055,   73, 9056,  ...,    0,    0,    0],\n",
       "          [7818,  144, 4851,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "          0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "          0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0])],\n",
       " [tensor([[5736, 2900, 3760,  ...,    0,    0,    0],\n",
       "          [  60,  763,  156,  ...,    0,    0,    0],\n",
       "          [2742, 2743,   75,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [1970,  148, 3760,  ...,    0,    0,    0],\n",
       "          [ 272,   22,  136,  ...,    0,    0,    0],\n",
       "          [ 735,   85, 3760,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "          0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "          0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])],\n",
       " [tensor([[3760, 8123, 1610,  ...,    0,    0,    0],\n",
       "          [ 601, 2234,  413,  ...,    0,    0,    0],\n",
       "          [ 319,  164,  790,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 445, 7201, 3760,  ...,    0,    0,    0],\n",
       "          [ 566,  363, 1329,  ...,    0,    0,    0],\n",
       "          [ 579,  268,  731,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "          1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0])],\n",
       " [tensor([[ 235,  566, 1170,  ...,    0,    0,    0],\n",
       "          [ 134,   91, 2842,  ...,    0,    0,    0],\n",
       "          [  85, 5652, 1618,  ...,    0,    0,    0],\n",
       "          ...,\n",
       "          [ 643,  975,   22,  ...,    0,    0,    0],\n",
       "          [2163, 2164, 2165,  ...,    0,    0,    0],\n",
       "          [  73,  458,  459,  ...,    0,    0,    0]]),\n",
       "  tensor([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "          0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "          1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0])]]"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjtCJUCxUayU",
    "outputId": "ade94d62-f9e7-4dbc-a4b0-de187d073a48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_gen)) # 125 batch pray huye hain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "muquK0O5UayV",
    "outputId": "9dd5d8ba-e57a-4a18-d454-1aad915e4a86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 325, 4509,    9,  ...,    0,    0,    0],\n",
       "         [ 601, 3283,  510,  ...,    0,    0,    0],\n",
       "         [ 458,  229, 4245,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 808, 5782, 5747,  ...,    0,    0,    0],\n",
       "         [1961, 1106,   92,  ...,    0,    0,    0],\n",
       "         [3225,  744, 3760,  ...,    0,    0,    0]]),\n",
       " tensor([1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0])]"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_gen)[0]  # first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jGjuDpVKUayV",
    "outputId": "b42a2b0c-187a-4cac-a182-7be90df887e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(train_gen)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBjE8bPpUayW",
    "outputId": "0290f128-4f2b-499c-8c54-71d2160db86c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_gen)[0])  # 0: tensor tweets, 1: corresponding labels 0s and 1s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xZgWJDuAUayW",
    "outputId": "cb217133-f208-43b8-b75d-8070216f9844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 349,   75,  253,  ...,    0,    0,    0],\n",
       "        [2340, 2685,   75,  ...,    0,    0,    0],\n",
       "        [1528,  579,  179,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 427, 1027, 3948,  ...,    0,    0,    0],\n",
       "        [6938,  308,  394,  ...,    0,    0,    0],\n",
       "        [ 131,  242, 1017,  ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_gen)[0][0]  # har new call par kuch oor hi aaye ga\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bGw9d0iUayX",
    "outputId": "0c859133-ab39-4ebe-f735-02291cee430d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_gen)[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDR9U1ysUayX",
    "outputId": "f2bd32ad-3edf-4879-eb2d-5b583f9dba16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_gen)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eav4WFFCUayY",
    "outputId": "4d9d058a-5a89-43c1-b835-e5c3a8a3b209"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True, False, False, False, False, False, False,\n",
       "         True,  True, False,  True, False,  True, False, False,  True,  True,\n",
       "        False,  True, False, False,  True, False,  True, False,  True, False,\n",
       "         True,  True, False,  True,  True, False, False,  True, False, False,\n",
       "         True,  True,  True, False,  True, False, False,  True,  True,  True,\n",
       "         True,  True, False, False,  True, False,  True, False, False, False,\n",
       "         True, False,  True,  True])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_gen)[0][1] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5hVJvd6dUayY",
    "outputId": "befc5fdd-ffc0-4ba5-89c1-b5952f0d1ef5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(32)"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(list(train_gen)[0][1] == 0)\n",
    "# yani 64 main say 38 0s hain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asnCYSkEUSG2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0uqn_EiWDXG"
   },
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfhxwjBJ-L6j"
   },
   "outputs": [],
   "source": [
    "# Step 2: Define the neural network architecture\n",
    "class SentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super(SentimentAnalysisModel, self).__init__()\n",
    "\n",
    "        self.embedding  =  nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc         =  nn.Linear(embed_dim, 2)  # Output dimension is 2 for softmax\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=1)   # Softmax over the classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded  =  self.embedding(x)\n",
    "        embedded  =  embedded.mean(dim=1)  # Average embeddings over the sequence length\n",
    "        logits    =  self.fc(embedded)\n",
    "        return logits  # Return logits for CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gs3vFk4hWM9s"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "vocab_size = len(Vocab)\n",
    "embed_dim  = 256\n",
    "\n",
    "# Instantiate the model\n",
    "model = SentimentAnalysisModel(vocab_size, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7zne-aAWM9v"
   },
   "outputs": [],
   "source": [
    "# Step 3: Define loss function and optimizer\n",
    "criterion  =  nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class classification\n",
    "optimizer  =  optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyC9mMhBXt26"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(outputs, labels):\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    correct      = (predicted == labels).sum().item()\n",
    "    total        = labels.size(0)\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "pERlpt0tb4Pi",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2f846e69-e224-4a60-8857-bb244e44e5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0LslxOXcGBM"
   },
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# # Create a SummaryWriter instance\n",
    "# writer = SummaryWriter(log_dir='runs/experiment_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IVqRqH2cGx7",
    "outputId": "1d954c09-3834-4942-9e81-f9f439e5d63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Training Loss: 0.6453, Training Accuracy: 0.7135\n",
      "Validation Loss: 0.5302, Validation Accuracy: 0.9590\n",
      "\n",
      "Epoch 2/10\n",
      "Training Loss: 0.5250, Training Accuracy: 0.9062\n",
      "Validation Loss: 0.3606, Validation Accuracy: 0.9675\n",
      "\n",
      "Epoch 3/10\n",
      "Training Loss: 0.3865, Training Accuracy: 0.9699\n",
      "Validation Loss: 0.2120, Validation Accuracy: 0.9880\n",
      "\n",
      "Epoch 4/10\n",
      "Training Loss: 0.2683, Training Accuracy: 0.9888\n",
      "Validation Loss: 0.1255, Validation Accuracy: 0.9900\n",
      "\n",
      "Epoch 5/10\n",
      "Training Loss: 0.1859, Training Accuracy: 0.9935\n",
      "Validation Loss: 0.0813, Validation Accuracy: 0.9900\n",
      "\n",
      "Epoch 6/10\n",
      "Training Loss: 0.1332, Training Accuracy: 0.9940\n",
      "Validation Loss: 0.0521, Validation Accuracy: 0.9940\n",
      "\n",
      "Epoch 7/10\n",
      "Training Loss: 0.0970, Training Accuracy: 0.9960\n",
      "Validation Loss: 0.0403, Validation Accuracy: 0.9935\n",
      "\n",
      "Epoch 8/10\n",
      "Training Loss: 0.0735, Training Accuracy: 0.9964\n",
      "Validation Loss: 0.0277, Validation Accuracy: 0.9955\n",
      "\n",
      "Epoch 9/10\n",
      "Training Loss: 0.0576, Training Accuracy: 0.9966\n",
      "Validation Loss: 0.0223, Validation Accuracy: 0.9955\n",
      "\n",
      "Epoch 10/10\n",
      "Training Loss: 0.0463, Training Accuracy: 0.9972\n",
      "Validation Loss: 0.0187, Validation Accuracy: 0.9955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss  = 0.0\n",
    "    correct_train = 0\n",
    "    total_train   = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_gen):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss   = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, predicted   = torch.max(logits, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train   += labels.size(0)\n",
    "\n",
    "    # Average training loss and accuracy\n",
    "    avg_train_loss = running_loss / len(train_gen)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # # Log training metrics\n",
    "    # writer.add_scalar('Training Loss', avg_train_loss, epoch)\n",
    "    # writer.add_scalar('Training Accuracy', train_accuracy, epoch)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct_val      = 0\n",
    "    total_val        = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_gen:\n",
    "            logits            = model(inputs)\n",
    "            loss              = criterion(logits, labels)\n",
    "            running_val_loss += loss.item()\n",
    "\n",
    "            # Calculate validation accuracy\n",
    "            _, predicted  = torch.max(logits, 1)\n",
    "            correct_val  += (predicted == labels).sum().item()\n",
    "            total_val    += labels.size(0)\n",
    "\n",
    "    # Average validation loss and accuracy\n",
    "    avg_val_loss = running_val_loss / len(val_gen)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    # # Log validation metrics\n",
    "    # writer.add_scalar('Validation Loss', avg_val_loss, epoch)\n",
    "    # writer.add_scalar('Validation Accuracy', val_accuracy, epoch)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_o3Ot1vjdk9T"
   },
   "source": [
    "# [A discussion with chatgpt on call backs in pytorch](https://chatgpt.com/share/1a49c819-c3a2-403d-9cf6-9fd6418d8afe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yFqrT5LAcG1Z",
    "outputId": "959f183b-a020-4f0e-da56-6dd5c1fa2d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-22 12:38:29.868550: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-22 12:38:29.868627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-22 12:38:29.872223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-22 12:38:31.667726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# !tensorboard --logdir=runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQ9I3OW-Y5jI"
   },
   "source": [
    "### from chat gpt\n",
    "The `with torch.no_grad():` context manager in PyTorch is used to temporarily disable gradient calculation, which is crucial during the evaluation phase of model training. Here‚Äôs a detailed explanation of the motivation and benefits behind using `torch.no_grad()`:\n",
    "\n",
    "### Motivation and Benefits\n",
    "\n",
    "1. **Memory Efficiency:**\n",
    "   - **Gradient Storage:** During training, PyTorch needs to store intermediate values and gradients for backpropagation. This requires additional memory. When you are only performing forward passes, such as during evaluation or inference, storing gradients is unnecessary and wasteful. By using `torch.no_grad()`, you avoid allocating memory for gradients, which can significantly reduce memory usage, especially with large models or large batch sizes.\n",
    "\n",
    "2. **Computational Efficiency:**\n",
    "   - **Unnecessary Computation:** Computing gradients involves additional operations that are not needed during evaluation. Disabling gradient computation reduces the amount of computation performed, speeding up the forward pass and making the evaluation phase faster.\n",
    "\n",
    "3. **Avoiding Gradient Accumulation:**\n",
    "   - **Gradient Accumulation Issue:** PyTorch accumulates gradients by default, which means gradients from previous batches are added to the current ones. This is intended for training but can lead to unintended behavior during evaluation if not disabled. Using `torch.no_grad()` ensures that no gradients are calculated or accumulated, which is what you want during validation or inference.\n",
    "\n",
    "4. **Consistency with Training Mode:**\n",
    "   - **Training vs. Evaluation:** When using `torch.no_grad()`, you clearly separate the phases where gradients are required (training) from those where they are not (evaluation). This helps in maintaining consistency and clarity in the code.\n",
    "\n",
    "### Example Use Cases\n",
    "\n",
    "1. **During Validation:**\n",
    "   Validation is typically performed to evaluate the performance of the model on unseen data without updating model parameters. Here's how you use `torch.no_grad()` during validation:\n",
    "\n",
    "2. **During Inference:**\n",
    "   When deploying a model for inference or making predictions, you only need the forward pass to obtain predictions. Use `torch.no_grad()` to ensure that the model runs efficiently:\n",
    "\n",
    "   ```python\n",
    "   model.eval()  # Set model to evaluation mode\n",
    "   with torch.no_grad():  # Disable gradient calculation\n",
    "       predictions = model(input_data)\n",
    "   ```\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Memory Efficiency:** Reduces memory usage by not storing gradients.\n",
    "- **Computational Efficiency:** Speeds up the forward pass by avoiding unnecessary computations.\n",
    "- **Avoids Unintended Gradient Accumulation:** Ensures no gradients are computed or stored.\n",
    "- **Consistency:** Separates training and evaluation phases clearly.\n",
    "\n",
    "Using `torch.no_grad()` is a best practice in PyTorch for evaluation and inference to ensure that your model runs efficiently and effectively during these phases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0ZQizGyXt7g",
    "outputId": "d5eb662f-9b12-420a-9c5c-d177da3d006b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['my name is ans imran and i am a very very bad guy. go to hell',\n",
       "  'my name is ans imran and i am a very very good guy',\n",
       "  'i am nether a good guy, nor a bad guy, i am neutral'],\n",
       " [0, 1, 0])"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytweet1 = ['my name is ans imran and i am a very very bad guy. go to hell']\n",
    "mytweet2 = ['my name is ans imran and i am a very very good guy']\n",
    "mytweet3 = ['i am nether a good guy, nor a bad guy, i am neutral']\n",
    "\n",
    "\n",
    "my_tweets = mytweet1+mytweet2+mytweet3\n",
    "my_labels = [0,1,0]\n",
    "\n",
    "my_tweets, my_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DF7t_9W3Xt_E"
   },
   "outputs": [],
   "source": [
    "test_X, test_Y = list_of_sentences_to_numpy_sequences(my_tweets,Vocab, my_labels)\n",
    "\n",
    "test_X = np.array(test_X)\n",
    "test_Y = np.array(test_Y)\n",
    "\n",
    "test_X = torch.from_numpy(test_X).long()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDWPi86RgeWB",
    "outputId": "9b3b5807-8e29-497b-f49b-a62049b28240"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX1ZV6n6WZWU",
    "outputId": "4d3709c3-7947-40a8-e04e-24ec9c4a0ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentAnalysisModel(\n",
       "  (embedding): Embedding(9088, 256)\n",
       "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 738,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMHpPBcafRd0",
    "outputId": "fcd62156-f65b-4719-c3c4-076a88f228b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 1]), 0.5841279029846191)"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  logits            = model(test_X)\n",
    "  loss              = criterion(logits, test_Y)\n",
    "  running_test_loss = loss.item()\n",
    "\n",
    "  _, predicted  = torch.max(logits, 1)\n",
    "    # correct_val  += (predicted == labels).sum().item()\n",
    "    # total_val    += labels.size(0)\n",
    "predicted, running_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rg3tS7mTfzBd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
