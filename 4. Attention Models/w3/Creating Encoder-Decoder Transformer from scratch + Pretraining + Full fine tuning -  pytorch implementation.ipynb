{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b129e1-b835-48a4-8379-545da9d7f73c",
   "metadata": {},
   "source": [
    "# Creating an Encoder-Decoder Transformer (T5) from scratch + Pretraining + Full fine tuning - pytorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804a3741-bea6-4eb9-b083-d78f3f78748b",
   "metadata": {},
   "source": [
    "### Links for the datasets used in this notebook: [1](https://github.com/Ariyanbgd/T5_Q-A) [2](https://huggingface.co/datasets/rajpurkar/squad_v2/tree/main)\n",
    "\n",
    "\n",
    "#### The link for the github repository of full [Natural Language Processing Specialisation](https://github.com/AnsImran/DeepLearning.AI-Natural-Language-Processing-Specialization/tree/main/4-Natural%20Language%20Processing%20with%20Attention%20Models/Week%203).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb20e1d-454a-4e54-9747-debfcc0cd21a",
   "metadata": {},
   "source": [
    "# Assignment 3: Question Answering\n",
    "\n",
    "Welcome to the third assignment of course 4. In this assignment you will explore question answering. You will implement the \"Text to Text Transfer from Transformers\" (better known as T5). Since you implemented transformers from scratch last week you will now be able to use them. \n",
    "\n",
    "<img src = \"images/qa.png\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61427e9-1126-4a62-88e1-c28a8eb06a14",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Overview](#0-1)\n",
    "- [Importing the Packages](#0-2)\n",
    "- [1 - Prepare the data for pretraining T5](#1)\n",
    "    - [1.1 - Pre-Training Objective](#1-1)\n",
    "    - [1.2 - C4 Dataset](#1-2)\n",
    "    - [1.3 - Process C4](#1-3)\n",
    "    - [1.4 - Decode to Natural Language](#1-4)\n",
    "    - [1.5 - Tokenizing and Masking](#1-5)\n",
    "        - [Exercise 1 - tokenize_and_mask](#ex-1)\n",
    "    - [1.6 - Creating the Pairs](#1-6)\n",
    "- [2 - Pretrain a T5 model using C4](#2)\n",
    "    - [2.1 - Instantiate a new transformer model](#2-1)\n",
    "    - [2.2 - C4 pretraining](#2-2)\n",
    "- [3 - Fine tune the T5 model for Question Answering](#3)\n",
    "    - [3.1 - Creating a list of paired question and answers](#3-1)\n",
    "        - [Exercise 2 - Parse the SQuaD 2.0 dataset](#ex-2)\n",
    "    - [3.2 - Fine tune the T5 model](#3-2)    \n",
    "    - [3.3 - Implement your Question Answering model](#3-3)\n",
    "        - [Exercise 3 - Implement the question answering function](#ex-3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ddb72-214d-4671-83d9-ae0ba48bcaa1",
   "metadata": {},
   "source": [
    "<a name='0-1'></a>\n",
    "## Overview\n",
    "\n",
    "This assignment will be different from the two previous ones. Due to memory constraints of this environment and for the sake of time, your model will be trained with small datasets, so you won't get models that you could use in production but you will gain the necessary knowledge about how the Generative Language models are trained and used. Also you won't spend too much time with the architecture of the models but you will instead take a model that is pre-trained on a larger dataset and fine tune it to get better results.\n",
    "\n",
    "After completing this labs you will:\n",
    "* Understand how the C4 dataset is structured.\n",
    "* Pretrain a transformer model using a Masked Language Model.\n",
    "* Understand how the \"Text to Text Transfer from Transformers\" or T5 model works. \n",
    "* Fine tune the T5 model for Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b57c50-2f4f-4600-82e8-1ae75cce9310",
   "metadata": {},
   "source": [
    "<a name='0-2'></a>\n",
    "## Importing the Packages\n",
    "\n",
    "Let's start by importing all the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2142295-a65e-4686-a47b-9d4a0e1a4172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import log_softmax\n",
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import string\n",
    "import itertools\n",
    "import transformer_utils \n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import utils\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "#import datasets\n",
    "import json\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d28f8ed-8e4c-42c2-af4d-ee21bd5b25e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e850e26c-162b-40f5-8a56-9a96cbc7f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# import traceback\n",
    "# import time\n",
    "# import json\n",
    "# from termcolor import colored\n",
    "# import string\n",
    "# import textwrap\n",
    "# import itertools\n",
    "# import numpy as np\n",
    "# import tensorflow_text as tf_text\n",
    "# import tensorflow as tf\n",
    "\n",
    "# import transformer_utils \n",
    "# import utils\n",
    "\n",
    "# # Will come in handy later\n",
    "# wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "# # Set random seed\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ef172-e068-4786-8ac6-d33089767edd",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 -  Prepare the data for pretraining T5 \n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Pre-Training Objective\n",
    "\n",
    "In the initial phase of training a T5 model for a Question Answering task, the pre-training process involves leveraging a masked language model (MLM) on a very large dataset, such as the C4 dataset. The objective is to allow the model to learn contextualized representations of words and phrases, fostering a deeper understanding of language semantics. To initiate pre-training, it is essential to employ the Transformer architecture, which forms the backbone of T5. The Transformer's self-attention mechanism enables the model to weigh different parts of the input sequence dynamically, capturing long-range dependencies effectively.\n",
    "\n",
    "Before delving into pre-training, thorough data preprocessing is crucial. The C4 dataset, a diverse and extensive collection of web pages, provides a rich source for language understanding tasks. The dataset needs to be tokenized into smaller units, such as subwords or words, to facilitate model input. Additionally, the text is often segmented into fixed-length sequences or batches, optimizing computational efficiency during training.\n",
    "\n",
    "For the masked language modeling objective, a percentage of the tokenized input is randomly masked, and the model is trained to predict the original content of these masked tokens. This process encourages the T5 model to grasp contextual relationships between words and phrases, enhancing its ability to generate coherent and contextually appropriate responses during downstream tasks like question answering.\n",
    "\n",
    "In summary, the pre-training of the T5 model involves utilizing the Transformer architecture on a sizable dataset like C4, coupled with meticulous data preprocessing to convert raw text into a format suitable for training. The incorporation of a masked language modeling objective ensures that the model learns robust contextual representations, laying a solid foundation for subsequent fine-tuning on specific tasks such as question answering.\n",
    "\n",
    "**Note:** The word \"mask\" will be used throughout this assignment in context of hiding/removing word(s)\n",
    "\n",
    "You will be implementing the Masked language model (MLM) as shown in the following image. \n",
    "\n",
    "<img src = \"images/loss.png\" width=\"600\" height = \"400\">\n",
    "\n",
    "Assume you have the following text: <span style = \"color:blue\"> **Thank you <span style = \"color:red\">for inviting </span> me to your party <span style = \"color:red\">last</span>  week** </span> \n",
    "\n",
    "\n",
    "Now as input you will mask the words in red in the text: \n",
    "\n",
    "<span style = \"color:blue\"> **Input:**</span> Thank you  **X** me to your party **Y** week.\n",
    "\n",
    "<span style = \"color:blue\">**Output:**</span> The model should predict the words(s) for **X** and **Y**. \n",
    "\n",
    "**[EOS]** will be used to mark the end of the target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf2e16-7950-4cae-8e49-afaed9a5c2ff",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - C4 Dataset\n",
    "\n",
    "The [C4 dataset](https://www.tensorflow.org/datasets/catalog/c4), also known as the Common Crawl C4 (Common Crawl Corpus C4), is a large-scale dataset of web pages collected by the [Common Crawl organization](https://commoncrawl.org/). It is commonly used for various natural language processing tasks and machine learning research. Each sample in the C4 dataset follows a consistent format, making it suitable for pretraining models like BERT. Here's a short explanation and description of the C4 dataset:\n",
    "\n",
    "- Format: Each sample in the C4 dataset is represented as a JSON object, containing several key-value pairs.\n",
    "\n",
    "- Content: The 'text' field in each sample contains the actual text content extracted from web pages. This text often includes a wide range of topics and writing styles, making it diverse and suitable for training language models.\n",
    "\n",
    "- Metadata: The dataset includes metadata such as 'content-length,' 'content-type,' 'timestamp,' and 'url,' providing additional information about each web page. 'Content-length' specifies the length of the content, 'content-type' describes the type of content (e.g., 'text/plain'), 'timestamp' indicates when the web page was crawled, and 'url' provides the source URL of the web page.\n",
    "\n",
    "- Applications: The C4 dataset is commonly used for training and fine-tuning large-scale language models, such as BERT. It serves as a valuable resource for tasks like text classification, named entity recognition, question answering, and more.\n",
    "\n",
    "- Size: The C4 dataset is containing more than 800 GiB of text data, making it suitable for training models with billions of parameters.\n",
    "\n",
    "Run the cell below to see how the C4 dataset looks like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9311df-0873-4e75-a07c-f5b64468da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example number 1: \n",
      "\n",
      "{'text': 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\\nHe will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\\nThe cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.'} \n",
      "\n",
      "example number 2: \n",
      "\n",
      "{'text': 'Discussion in \\'Mac OS X Lion (10.7)\\' started by axboi87, Jan 20, 2012.\\nI\\'ve got a 500gb internal drive and a 240gb SSD.\\nWhen trying to restore using disk utility i\\'m given the error \"Not enough space on disk ____ to restore\"\\nBut I shouldn\\'t have to do that!!!\\nAny ideas or workarounds before resorting to the above?\\nUse Carbon Copy Cloner to copy one drive to the other. I\\'ve done this several times going from larger HDD to smaller SSD and I wound up with a bootable SSD drive. One step you have to remember not to skip is to use Disk Utility to partition the SSD as GUID partition scheme HFS+ before doing the clone. If it came Apple Partition Scheme, even if you let CCC do the clone, the resulting drive won\\'t be bootable. CCC usually works in \"file mode\" and it can easily copy a larger drive (that\\'s mostly empty) onto a smaller drive. If you tell CCC to clone a drive you did NOT boot from, it can work in block copy mode where the destination drive must be the same size or larger than the drive you are cloning from (if I recall).\\nI\\'ve actually done this somehow on Disk Utility several times (booting from a different drive (or even the dvd) so not running disk utility from the drive your cloning) and had it work just fine from larger to smaller bootable clone. Definitely format the drive cloning to first, as bootable Apple etc..\\nThanks for pointing this out. My only experience using DU to go larger to smaller was when I was trying to make a Lion install stick and I was unable to restore InstallESD.dmg to a 4 GB USB stick but of course the reason that wouldn\\'t fit is there was slightly more than 4 GB of data.'} \n",
      "\n",
      "example number 3: \n",
      "\n",
      "{'text': 'Foil plaid lycra and spandex shortall with metallic slinky insets. Attached metallic elastic belt with O-ring. Headband included. Great hip hop or jazz dance costume. Made in the USA.'} \n",
      "\n",
      "example number 4: \n",
      "\n",
      "{'text': \"How many backlinks per day for new site?\\nDiscussion in 'Black Hat SEO' started by Omoplata, Dec 3, 2010.\\n1) for a newly created site, what's the max # backlinks per day I should do to be safe?\\n2) how long do I have to let my site age before I can start making more blinks?\\nI did about 6000 forum profiles every 24 hours for 10 days for one of my sites which had a brand new domain.\\nThere is three backlinks for every of these forum profile so thats 18 000 backlinks every 24 hours and nothing happened in terms of being penalized or sandboxed. This is now maybe 3 months ago and the site is ranking on first page for a lot of my targeted keywords.\\nbuild more you can in starting but do manual submission and not spammy type means manual + relevant to the post.. then after 1 month you can make a big blast..\\nWow, dude, you built 18k backlinks a day on a brand new site? How quickly did you rank up? What kind of competition/searches did those keywords have?\"} \n",
      "\n",
      "example number 5: \n",
      "\n",
      "{'text': 'The Denver Board of Education opened the 2017-18 school year with an update on projects that include new construction, upgrades, heat mitigation and quality learning environments.\\nWe are excited that Denver students will be the beneficiaries of a four year, $572 million General Obligation Bond. Since the passage of the bond, our construction team has worked to schedule the projects over the four-year term of the bond.\\nDenver voters on Tuesday approved bond and mill funding measures for students in Denver Public Schools, agreeing to invest $572 million in bond funding to build and improve schools and $56.6 million in operating dollars to support proven initiatives, such as early literacy.\\nDenver voters say yes to bond and mill levy funding support for DPS students and schools. Click to learn more about the details of the voter-approved bond measure.\\nDenver voters on Nov. 8 approved bond and mill funding measures for DPS students and schools. Learn more about what’s included in the mill levy measure.'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load example jsons\n",
    "with open('data/c4-en-10k.jsonl', 'r') as file:\n",
    "    example_jsons = [json.loads(line.strip()) for line in file]\n",
    "\n",
    "# Printing the examples to see how the data looks like\n",
    "for i in range(5):\n",
    "    print(f'example number {i+1}: \\n\\n{example_jsons[i]} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f862181-be27-4db0-839d-052d9d1f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i guess k ye jo jsonl, ('l') file hay, is main sirf 'l'ines, sir text val entryries hi vocab ki pri hui hain or metadata etc, har aik individual dict\n",
    "# main nahi pra hua\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be9c6b-ae0f-4fcc-9c75-cb9b0d3ebf66",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Process C4\n",
    "\n",
    "For the purpose of pretaining the T5 model, you will only use the `content` of each entry. In the following code, you filter only the field `text` from all the entries in the dataset. This is the data that you will use to create the `inputs` and `targets` of your language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9725ef43-68da-41e8-9add-f495b9f2601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginners BBQ Class Taking Place in Missoula!\n",
      "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
      "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
      "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n"
     ]
    }
   ],
   "source": [
    "# Grab text field from dictionary\n",
    "natural_language_texts = [example_json['text'] for example_json in example_jsons]\n",
    "\n",
    "# Print the first text example\n",
    "print(natural_language_texts[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78675370-6cc9-4f77-b546-ad238de07280",
   "metadata": {},
   "source": [
    "<a name='1-4'></a>\n",
    "### 1.4 - Decode to Natural Language\n",
    "\n",
    "The [SentencePieceTokenizer](https://www.tensorflow.org/text/api_docs/python/text/SentencepieceTokenizer), used in the code snippet, tokenizes text into subword units, enhancing handling of complex word structures, out-of-vocabulary words, and multilingual support. It simplifies preprocessing, ensures consistent tokenization, and seamlessly integrates with machine learning frameworks.\n",
    "\n",
    "In this task, a SentencePiece model is loaded from a file, which is used to tokenize text into subwords represented by integer IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccca0e61-dfa0-4242-aae8-f9bfdfbd4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special tokens\n",
    "# PAD, EOS = 0, 1\n",
    "\n",
    "with open(\"./models/sentencepiece.model\", \"rb\") as f:\n",
    "    pre_trained_tokenizer = f.read()\n",
    "    \n",
    "tokenizer = tf_text.SentencepieceTokenizer(pre_trained_tokenizer, out_type=tf.int32)\n",
    "\n",
    "\n",
    "# # Another possibility\n",
    "\n",
    "# import sentencepiece as spm\n",
    "\n",
    "# # Load the SentencePiece model\n",
    "# sp = spm.SentencePieceProcessor()\n",
    "# sp.load('./models/sentencepiece.model')\n",
    "\n",
    "# # Tokenize text using the loaded model\n",
    "# text = \"This is a sample text.\"\n",
    "# tokenized_text = sp.encode(text, out_type=int)  # Use out_type=int to get int token ids | out_type, torch.tensor kar k daikhna, otherwise integer bhi thek hi hay\n",
    "\n",
    "# print(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f2c89-8223-43eb-8bfb-eb4149202a2e",
   "metadata": {},
   "source": [
    "In this tokenizer the string `</s>` is used as `EOS` token. By default, the tokenizer does not add the `EOS` to the end of each sentence, so you need to add it manually when required. Let's verify what id correspond to this token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3224741-0162-4ac5-a947-945dfe09d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS: 1\n"
     ]
    }
   ],
   "source": [
    "eos = tokenizer.string_to_id(\"</s>\").numpy()\n",
    "\n",
    "print(\"EOS: \" + str(eos))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ddf54c4-9e8f-49f3-a883-d67e9bbd06b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word\t\t-->\tTokenization\n",
      "\n",
      "Foil\t-->\t[4452, 173]\n",
      "plaid\t-->\t[30772]\n",
      "lycra\t-->\t[3, 120, 2935]\n",
      "and\t-->\t[11]\n",
      "spandex\t-->\t[8438, 26, 994]\n",
      "shortall\t-->\t[710, 1748]\n",
      "with\t-->\t[28]\n",
      "metallic\t-->\t[18813]\n",
      "slinky\t-->\t[3, 7, 4907, 63]\n",
      "insets.\t-->\t[16, 2244, 7, 5]\n",
      "Attached\t-->\t[28416, 15, 26]\n",
      "metallic\t-->\t[18813]\n",
      "elastic\t-->\t[15855]\n",
      "belt\t-->\t[6782]\n",
      "with\t-->\t[28]\n",
      "O-ring.\t-->\t[411, 18, 1007, 5]\n",
      "Headband\t-->\t[3642, 3348]\n",
      "included.\t-->\t[1285, 5]\n",
      "Great\t-->\t[1651]\n",
      "hip\t-->\t[5436]\n",
      "hop\t-->\t[13652]\n",
      "or\t-->\t[42]\n",
      "jazz\t-->\t[9948]\n",
      "dance\t-->\t[2595]\n",
      "costume.\t-->\t[11594, 5]\n",
      "Made\t-->\t[6465]\n",
      "in\t-->\t[16]\n",
      "the\t-->\t[8]\n",
      "USA.\t-->\t[2312, 5]\n"
     ]
    }
   ],
   "source": [
    "# printing the encoding of each word to see how subwords are tokenized\n",
    "tokenized_text = [(list(tokenizer.tokenize(word).numpy()), word) for word in natural_language_texts[2].split()]\n",
    "\n",
    "print(\"Word\\t\\t-->\\tTokenization\\n\")\n",
    "for element in tokenized_text:\n",
    "    print(f\"{element[1]}\\t-->\\t{element[0]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e992543-a2da-4d12-bc03-98b23e808ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04ef70b-7677-4f47-97b1-1143a1c8a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(natural_language_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64f747ef-7230-441a-b987-3b66dbfe4cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Foil', 'plaid', 'lycra', 'and', 'spandex', 'shortall', 'with', 'metallic', 'slinky', 'insets.', 'Attached', 'metallic', 'elastic', 'belt', 'with', 'O-ring.', 'Headband', 'included.', 'Great', 'hip', 'hop', 'or', 'jazz', 'dance', 'costume.', 'Made', 'in', 'the', 'USA.']\n"
     ]
    }
   ],
   "source": [
    "print(natural_language_texts[2].split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d84797-f8e4-45db-aeb0-1a81de5e4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([30772])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('plaid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8159a29c-80d9-4390-91a6-3c6fca1571fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30772])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('plaid').numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d81caa6e-72aa-4545-99fb-46ed0ea8a1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([   3,  120, 2935])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('lycra')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b84c4b4-5ad5-42df-ab38-691bb5dd7421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,  120, 2935])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('lycra').numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2038588d-f864-4a4b-b987-cb2c485b414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'lycra'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b''>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize([120, 2935]), tokenizer.detokenize([3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8704194d-2195-4095-b8b3-e97e0010017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3437c-6427-4954-8da5-b7dad5d35113",
   "metadata": {},
   "source": [
    "And as usual, the library provides a function to turn numeric tokens into human readable text. Look how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c6774df-d14c-42c0-bdfc-77aefa67d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized: [12847   277]\n",
      "detokenized: b'Beginners'\n"
     ]
    }
   ],
   "source": [
    "# We can see that detokenize successfully undoes the tokenization\n",
    "print(f\"tokenized: {tokenizer.tokenize('Beginners')}\\ndetokenized: {tokenizer.detokenize(tokenizer.tokenize('Beginners'))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea975b-beb1-4a94-a0fa-26484eff8a8f",
   "metadata": {},
   "source": [
    "As you can see above, you were able to take a piece of string and tokenize it. \n",
    "\n",
    "Now you will create `input` and `target` pairs that will allow you to train your model. T5 uses the ids at the end of the vocab file as sentinels. For example, it will replace: \n",
    "   - `vocab_size - 1` by `<Z>`\n",
    "   - `vocab_size - 2` by `<Y>`\n",
    "   - and so forth. \n",
    "   \n",
    "It assigns every word a `chr`.\n",
    "\n",
    "The `pretty_decode` function below, which you will use in a bit, helps in handling the type when decoding. Take a look and try to understand what the function is doing.\n",
    "\n",
    "\n",
    "Notice that:\n",
    "```python\n",
    "string.ascii_letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "```\n",
    "\n",
    "**NOTE:** Targets may have more than the 52 sentinels we replace, but this is just to give you an idea of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e619817-f69d-419d-b6c2-9d55ff6f8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentinels(tokenizer, display=False):\n",
    "    sentinels = {}\n",
    "    vocab_size = tokenizer.vocab_size(name=None)\n",
    "    for i, char in enumerate(reversed(string.ascii_letters), 1):\n",
    "        decoded_text = tokenizer.detokenize([vocab_size - i]).numpy().decode(\"utf-8\")\n",
    "        \n",
    "        # Sentinels, ex: <Z> - <a>\n",
    "        sentinels[decoded_text] = f'<{char}>'    \n",
    "    \n",
    "        if display:\n",
    "            print(f'The sentinel is <{char}> and the decoded token is:', decoded_text)\n",
    "\n",
    "    return sentinels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0865620e-d103-42c1-86bf-7592ed064fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1532d2dc-4838-4850-bac9-242b2ce0a8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.ascii_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52863536-f6f2-4bb4-8ba9-08693c69427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<reversed at 0x21cbe6cee90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reversed('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "# Return a reverse iterator over the values of the given sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f57ea7d-d9b0-4a37-b4a5-5a6093c1ac8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  1 \tchar:  Z\n",
      "i:  2 \tchar:  Y\n",
      "i:  3 \tchar:  X\n",
      "i:  4 \tchar:  W\n",
      "i:  5 \tchar:  V\n",
      "i:  6 \tchar:  U\n",
      "i:  7 \tchar:  T\n",
      "i:  8 \tchar:  S\n",
      "i:  9 \tchar:  R\n",
      "i:  10 \tchar:  Q\n",
      "i:  11 \tchar:  P\n",
      "i:  12 \tchar:  O\n",
      "i:  13 \tchar:  N\n",
      "i:  14 \tchar:  M\n",
      "i:  15 \tchar:  L\n",
      "i:  16 \tchar:  K\n",
      "i:  17 \tchar:  J\n",
      "i:  18 \tchar:  I\n",
      "i:  19 \tchar:  H\n",
      "i:  20 \tchar:  G\n",
      "i:  21 \tchar:  F\n",
      "i:  22 \tchar:  E\n",
      "i:  23 \tchar:  D\n",
      "i:  24 \tchar:  C\n",
      "i:  25 \tchar:  B\n",
      "i:  26 \tchar:  A\n",
      "i:  27 \tchar:  z\n",
      "i:  28 \tchar:  y\n",
      "i:  29 \tchar:  x\n",
      "i:  30 \tchar:  w\n",
      "i:  31 \tchar:  v\n",
      "i:  32 \tchar:  u\n",
      "i:  33 \tchar:  t\n",
      "i:  34 \tchar:  s\n",
      "i:  35 \tchar:  r\n",
      "i:  36 \tchar:  q\n",
      "i:  37 \tchar:  p\n",
      "i:  38 \tchar:  o\n",
      "i:  39 \tchar:  n\n",
      "i:  40 \tchar:  m\n",
      "i:  41 \tchar:  l\n",
      "i:  42 \tchar:  k\n",
      "i:  43 \tchar:  j\n",
      "i:  44 \tchar:  i\n",
      "i:  45 \tchar:  h\n",
      "i:  46 \tchar:  g\n",
      "i:  47 \tchar:  f\n",
      "i:  48 \tchar:  e\n",
      "i:  49 \tchar:  d\n",
      "i:  50 \tchar:  c\n",
      "i:  51 \tchar:  b\n",
      "i:  52 \tchar:  a\n"
     ]
    }
   ],
   "source": [
    "for i, char in enumerate(reversed('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'), 1):\n",
    "    print('i: ',i, '\\tchar: ', char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "217c40b0-b088-4fcb-9788-6bb32c01309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SentencepieceTokenizer.vocab_size of <tensorflow_text.python.ops.sentencepiece_tokenizer.SentencepieceTokenizer object at 0x0000021CB5D8AB90>>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbd080e7-d5ea-4c69-9fd6-66c10ad2d87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=32000>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size(name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9587bb2-173c-42d1-8ef7-640fef90a768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=32000>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17937856-3725-45b2-a4ce-06558f7a85e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Internațional'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize([32000 - 1]).numpy().decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46e8e92b-aa5b-4c53-9c2f-a5908424e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c73bfc6-5beb-441d-a9f9-0bea4bbb93d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentinel is <Z> and the decoded token is: Internațional\n",
      "The sentinel is <Y> and the decoded token is: erwachsene\n",
      "The sentinel is <X> and the decoded token is: Cushion\n",
      "The sentinel is <W> and the decoded token is: imunitar\n",
      "The sentinel is <V> and the decoded token is: Intellectual\n",
      "The sentinel is <U> and the decoded token is: traditi\n",
      "The sentinel is <T> and the decoded token is: disguise\n",
      "The sentinel is <S> and the decoded token is: exerce\n",
      "The sentinel is <R> and the decoded token is: nourishe\n",
      "The sentinel is <Q> and the decoded token is: predominant\n",
      "The sentinel is <P> and the decoded token is: amitié\n",
      "The sentinel is <O> and the decoded token is: erkennt\n",
      "The sentinel is <N> and the decoded token is: dimension\n",
      "The sentinel is <M> and the decoded token is: inférieur\n",
      "The sentinel is <L> and the decoded token is: refugi\n",
      "The sentinel is <K> and the decoded token is: cheddar\n",
      "The sentinel is <J> and the decoded token is: unterlieg\n",
      "The sentinel is <I> and the decoded token is: garanteaz\n",
      "The sentinel is <H> and the decoded token is: făcute\n",
      "The sentinel is <G> and the decoded token is: réglage\n",
      "The sentinel is <F> and the decoded token is: pedepse\n",
      "The sentinel is <E> and the decoded token is: Germain\n",
      "The sentinel is <D> and the decoded token is: distinctly\n",
      "The sentinel is <C> and the decoded token is: Schraub\n",
      "The sentinel is <B> and the decoded token is: emanat\n",
      "The sentinel is <A> and the decoded token is: trimestre\n",
      "The sentinel is <z> and the decoded token is: disrespect\n",
      "The sentinel is <y> and the decoded token is: Erasmus\n",
      "The sentinel is <x> and the decoded token is: Australia\n",
      "The sentinel is <w> and the decoded token is: permeabil\n",
      "The sentinel is <v> and the decoded token is: deseori\n",
      "The sentinel is <u> and the decoded token is: manipulated\n",
      "The sentinel is <t> and the decoded token is: suggér\n",
      "The sentinel is <s> and the decoded token is: corespund\n",
      "The sentinel is <r> and the decoded token is: nitro\n",
      "The sentinel is <q> and the decoded token is: oyons\n",
      "The sentinel is <p> and the decoded token is: Account\n",
      "The sentinel is <o> and the decoded token is: échéan\n",
      "The sentinel is <n> and the decoded token is: laundering\n",
      "The sentinel is <m> and the decoded token is: genealogy\n",
      "The sentinel is <l> and the decoded token is: QuickBooks\n",
      "The sentinel is <k> and the decoded token is: constituted\n",
      "The sentinel is <j> and the decoded token is: Fertigung\n",
      "The sentinel is <i> and the decoded token is: goutte\n",
      "The sentinel is <h> and the decoded token is: regulă\n",
      "The sentinel is <g> and the decoded token is: overwhelmingly\n",
      "The sentinel is <f> and the decoded token is: émerg\n",
      "The sentinel is <e> and the decoded token is: broyeur\n",
      "The sentinel is <d> and the decoded token is: povești\n",
      "The sentinel is <c> and the decoded token is: emulator\n",
      "The sentinel is <b> and the decoded token is: halloween\n",
      "The sentinel is <a> and the decoded token is: combustibil\n"
     ]
    }
   ],
   "source": [
    "sentinels = get_sentinels(tokenizer, display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7ff09-b5d8-425d-bb4a-ddb29298a663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4795e004-52a7-4a85-88ce-de85dea1f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_decode(encoded_str_list, sentinels, tokenizer):\n",
    "    # If already a string, just do the replacements.\n",
    "    if tf.is_tensor(encoded_str_list) and encoded_str_list.dtype == tf.string:\n",
    "        for token, char in sentinels.items():\n",
    "            encoded_str_list = tf.strings.regex_replace(encoded_str_list, token, char)\n",
    "        return encoded_str_list\n",
    "  \n",
    "    # We need to decode and then prettyfy it.\n",
    "    return pretty_decode(tokenizer.detokenize(encoded_str_list), sentinels, tokenizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b22a6c-fab6-4799-8c13-47815a337c5c",
   "metadata": {},
   "source": [
    "Now, let's use the `pretty_decode` function in the following sentence. Note that all the words listed as sentinels, will be replaced by the function with the corresponding sentinel. It could be a drawback of this method, but don't worry about it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1b58fe4-a5de-4799-ace1-ff2cfe56e955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'I want to dress up as an <V> this <b>.'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(tf.constant(\"I want to dress up as an Intellectual this halloween.\"), sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dfbadd6-b02e-44b1-af51-538dce043663",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c6e5a2-75c4-4d9d-8963-16e470d6c79d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Internațional': '<Z>',\n",
       " 'erwachsene': '<Y>',\n",
       " 'Cushion': '<X>',\n",
       " 'imunitar': '<W>',\n",
       " 'Intellectual': '<V>',\n",
       " 'traditi': '<U>',\n",
       " 'disguise': '<T>',\n",
       " 'exerce': '<S>',\n",
       " 'nourishe': '<R>',\n",
       " 'predominant': '<Q>',\n",
       " 'amitié': '<P>',\n",
       " 'erkennt': '<O>',\n",
       " 'dimension': '<N>',\n",
       " 'inférieur': '<M>',\n",
       " 'refugi': '<L>',\n",
       " 'cheddar': '<K>',\n",
       " 'unterlieg': '<J>',\n",
       " 'garanteaz': '<I>',\n",
       " 'făcute': '<H>',\n",
       " 'réglage': '<G>',\n",
       " 'pedepse': '<F>',\n",
       " 'Germain': '<E>',\n",
       " 'distinctly': '<D>',\n",
       " 'Schraub': '<C>',\n",
       " 'emanat': '<B>',\n",
       " 'trimestre': '<A>',\n",
       " 'disrespect': '<z>',\n",
       " 'Erasmus': '<y>',\n",
       " 'Australia': '<x>',\n",
       " 'permeabil': '<w>',\n",
       " 'deseori': '<v>',\n",
       " 'manipulated': '<u>',\n",
       " 'suggér': '<t>',\n",
       " 'corespund': '<s>',\n",
       " 'nitro': '<r>',\n",
       " 'oyons': '<q>',\n",
       " 'Account': '<p>',\n",
       " 'échéan': '<o>',\n",
       " 'laundering': '<n>',\n",
       " 'genealogy': '<m>',\n",
       " 'QuickBooks': '<l>',\n",
       " 'constituted': '<k>',\n",
       " 'Fertigung': '<j>',\n",
       " 'goutte': '<i>',\n",
       " 'regulă': '<h>',\n",
       " 'overwhelmingly': '<g>',\n",
       " 'émerg': '<f>',\n",
       " 'broyeur': '<e>',\n",
       " 'povești': '<d>',\n",
       " 'emulator': '<c>',\n",
       " 'halloween': '<b>',\n",
       " 'combustibil': '<a>'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentinels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33c73216-ce43-4986-9a24-696f1f1c75ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'I want to dress up as an Intellectual this halloween.'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(\"I want to dress up as an Intellectual this halloween.\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9c92500-ffd2-4596-82f0-9e3ad22953e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'I want to dress up as an Intellectual this halloween.'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.regex_replace(a, 'Internațional', '<Z>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36f4220e-6abd-4f10-b2e3-50fbe306b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8fff8-f87d-4023-a352-feb0b47a719a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11998bc2-eaf8-4844-88bf-4ed87a5efb53",
   "metadata": {},
   "source": [
    "The functions above make your `inputs` and `targets` more readable. For example, you might see something like this once you implement the masking function below. \n",
    "\n",
    "- <span style=\"color:red\"> Input sentence: </span> Younes and Lukasz were working together in the lab yesterday after lunch. \n",
    "- <span style=\"color:red\">Input: </span> Younes and Lukasz  **Z** together in the **Y** yesterday after lunch.\n",
    "- <span style=\"color:red\">Target: </span> **Z** were working **Y** lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af63a2-7e78-4b2e-a61b-c9ed15b3261c",
   "metadata": {},
   "source": [
    "<a name='1-5'></a>\n",
    "### 1.5 - Tokenizing and Masking\n",
    "\n",
    "In this task, you will implement the `tokenize_and_mask` function, which tokenizes and masks input words based on a given probability. The probability is controlled by the `noise` parameter, typically set to mask around `15%` of the words in the input text. The function will generate two lists of tokenized sequences following the algorithm outlined below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b778aa2-1f92-45d9-9867-76051448f501",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - tokenize_and_mask\n",
    "\n",
    "- Start with two empty lists: `inps` and `targs`\n",
    "- Tokenize the input text using the given tokenizer.\n",
    "- For each `token` in the tokenized sequence:\n",
    "  - Generate a random number(simulating a weighted coin toss)\n",
    "  - If the random value is greater than the given threshold(noise):\n",
    "    - Add the current token to the `inps` list\n",
    "  - Else:\n",
    "    - If a new sentinel must be included(read note **):\n",
    "      - Compute the next sentinel ID using a progression.\n",
    "      - Add a sentinel into the `inps` and `targs` to mark the position of the masked element.\n",
    "    - Add the current token to the `targs` list.\n",
    "\n",
    "** There's a special case to consider. If two consecutive tokens get masked during the process, you don't need to add a new sentinel to the sequences. To account for this, use the `prev_no_mask` flag, which starts as `True` but is turned to `False` each time you mask a new element. The code that adds sentinels will only be executed if, before masking the token, the flag was in the `True` state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d420fcd3-2cf9-4ca8-8b65-f7f0ce4ea09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: tokenize_and_mask\n",
    "def tokenize_and_mask(text, \n",
    "                      noise =0.15, \n",
    "                      randomizer=np.random.uniform, \n",
    "                      tokenizer=None):\n",
    "    \"\"\"Tokenizes and masks a given input.\n",
    "\n",
    "    Args:\n",
    "        text (str or bytes): Text input.\n",
    "        noise (float, optional): Probability of masking a token. Defaults to 0.15.\n",
    "        randomizer (function, optional): Function that generates random values. Defaults to np.random.uniform.\n",
    "        tokenizer (function, optional): Tokenizer function. Defaults to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        inps, targs: Lists of integers associated to inputs and targets.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Current sentinel number (starts at 0)\n",
    "    cur_sentinel_num = 0\n",
    "    \n",
    "    # Inputs and targets\n",
    "    inps, targs = [], []\n",
    "\n",
    "    # Vocab_size\n",
    "    vocab_size = int(tokenizer.vocab_size())\n",
    "    \n",
    "    # EOS token id \n",
    "    # Must be at the end of each target!\n",
    "    eos = tokenizer.string_to_id(\"</s>\").numpy()\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # prev_no_mask is True if the previous token was NOT masked, False otherwise\n",
    "    # set prev_no_mask to True\n",
    "    prev_no_mask = True\n",
    "    \n",
    "    # Loop over the tokenized text\n",
    "    for token in tokenizer.tokenize(text).numpy():\n",
    "        \n",
    "        # Generate a random value between 0 and 1\n",
    "        rnd_val = randomizer() \n",
    "        \n",
    "        # Check if the noise is greater than a random value (weighted coin flip)\n",
    "        if rnd_val < noise:\n",
    "            \n",
    "            # Check if previous token was NOT masked\n",
    "            if prev_no_mask:\n",
    "                \n",
    "                # Current sentinel increases by 1\n",
    "                cur_sentinel_num += 1\n",
    "                \n",
    "                # Compute end_id by subtracting current sentinel value out of the total vocabulary size\n",
    "                end_id = vocab_size - cur_sentinel_num\n",
    "                \n",
    "                # Append end_id at the end of the targets\n",
    "                targs.append(end_id)\n",
    "                \n",
    "                # Append end_id at the end of the inputs\n",
    "                inps.append(end_id)\n",
    "                \n",
    "            # Append token at the end of the targets\n",
    "            targs.append(token)\n",
    "            \n",
    "            # set prev_no_mask accordingly\n",
    "            prev_no_mask = False\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # Append token at the end of the inputs\n",
    "            inps.append(token)\n",
    "            \n",
    "            # Set prev_no_mask accordingly\n",
    "            prev_no_mask = True\n",
    "    \n",
    "    \n",
    "    # Add EOS token to the end of the targets\n",
    "    targs.append(eos)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inps, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62dcda4-452b-4b9b-a2f3-ca0ea35ec22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5403d65-a31e-4c9b-8479-4deddce8b9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('1')\n",
    "    if False:\n",
    "        print('2')\n",
    "else:\n",
    "    print('3')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f4dd39c-f457-4516-bf2d-116368ef2139",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e2d50b19-9f5e-41c9-8f9a-9e0264b86b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized inputs - shape=53:\n",
      "\n",
      "[31999, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 31998, 531, 25, 241, 12, 129, 394, 44, 492, 31997, 58, 148, 56, 43, 8, 1004, 6, 474, 31996, 39, 4793, 230, 5, 2721, 6, 1600, 1630, 31995, 1150, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31994, 782, 3624, 14627, 15, 12612, 277, 5]\n",
      "\n",
      "targets - shape=19:\n",
      "\n",
      "[31999, 12847, 277, 31998, 9, 55, 31997, 3326, 15068, 31996, 48, 30, 31995, 727, 1715, 31994, 45, 301, 1]\n"
     ]
    }
   ],
   "source": [
    "# Some logic to mock a np.random value generator\n",
    "# Needs to be in the same cell for it to always generate same output\n",
    "def testing_rnd():\n",
    "    def dummy_generator():\n",
    "        vals = np.linspace(0, 1, 10)\n",
    "        cyclic_vals = itertools.cycle(vals)\n",
    "        for _ in range(100):\n",
    "            yield next(cyclic_vals)\n",
    "\n",
    "    dumr = itertools.cycle(dummy_generator())\n",
    "\n",
    "    def dummy_randomizer():\n",
    "        return next(dumr)\n",
    "    \n",
    "    return dummy_randomizer\n",
    "\n",
    "input_str = 'Beginners BBQ Class Taking Place in Missoula!\\nDo you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers.'\n",
    "\n",
    "inps, targs = tokenize_and_mask(input_str, randomizer=testing_rnd(), tokenizer=tokenizer)\n",
    "print(f\"tokenized inputs - shape={len(inps)}:\\n\\n{inps}\\n\\ntargets - shape={len(targs)}:\\n\\n{targs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ed43e-c9fb-483e-b051-a68bd0010082",
   "metadata": {},
   "source": [
    "You will now use the inputs and the targets from the `tokenize_and_mask` function you implemented above. Take a look at the decoded version of your masked sentence using your `inps` and `targs` from the sentence above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f1557a0-92cd-470d-845e-b903cb04750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "\n",
      " b'<Z> BBQ Class Taking Place in Missoul <Y> Do you want to get better at making <X>? You will have the opportunity, put <W> your calendar now. Thursday, September 22 <V> World Class BBQ Champion, Tony Balay <U>onestar Smoke Rangers.'\n",
      "\n",
      "Targets: \n",
      "\n",
      " b'<Z> Beginners <Y>a! <X> delicious BBQ <W> this on <V>nd join <U> from L'\n"
     ]
    }
   ],
   "source": [
    "print('Inputs: \\n\\n', pretty_decode(inps, sentinels, tokenizer).numpy())\n",
    "print('\\nTargets: \\n\\n', pretty_decode(targs, sentinels, tokenizer).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0698cd9-a55a-4e6a-8b37-36fa71db2340",
   "metadata": {},
   "source": [
    "<a name='1-6'></a>\n",
    "### 1.6 - Creating the Pairs\n",
    "\n",
    "You will now create pairs using your dataset. You will iterate over your data and create (inp, targ) pairs using the functions that we have given you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ca6e5e7-e585-4a45-b9f2-43dacf81b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply tokenize_and_mask\n",
    "inputs_targets_pairs = [tokenize_and_mask(text.encode('utf-8', errors='ignore').decode('utf-8'), tokenizer=tokenizer) \n",
    "                        for text in natural_language_texts]\n",
    "################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd9a245d-cf36-4069-ab99-49f2dc0f24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a6109f7-d032-4641-8d72-9ed1de41020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ 破�..\\nNáo Loạn - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_texts[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da35c019-84fd-407b-be02-e3ba0ddc9c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(natural_language_texts[10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac80e338-2c7f-4def-b967-8c45661ce807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ \\xe7\\xa0\\xb4\\xef\\xbf\\xbd..\\nN\\xc3\\xa1o Lo\\xe1\\xba\\xa1n - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_texts[10].encode('utf-8', errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d14f836d-82f7-4ba3-97da-d6430b97e4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pencarian FILM Untuk \"Peace Breaker 2017\"\\nyuk mampir ke channel say..\\nEdges East provides the l..\\nA corrupt cop makes one w..\\nPeace Breaker 2017 ~ 破�..\\nNáo Loạn - Peace Break..\\nPlease subscribe and hit ..\\nuploaded in HD at http://..\\nI cannot believe I manage..'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_language_texts[10].encode('utf-8', errors='ignore').decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26aea9b3-9f19-47af-83db-3eca8f2dc968",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1eb0476f-9a25-4192-a683-b59bbb177d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "\n",
      "inputs:\n",
      "Beginners BBQ Class Taking Place in Missoula <Z> Do you want to get\n",
      "<Y> at making delicious BBQ? You <X> the opportunity, put this on <W>\n",
      "calendar now. Thursday, September <V>nd join <U> Class BBQ Champion,\n",
      "Tony Balay <T> Lonestar Smoke Rangers. He will<S> teaching<R>a\n",
      "beginner <Q> class for everyone who wants to get better with their\n",
      "culinary skills. He will teach you everything you need to know to\n",
      "compete<P> a KCBS BBQ competition, including techniques, recipes <O>,\n",
      "meat selection and trimming, plus<N> and fire information. The cost to\n",
      "be in <M> class is $35 per person, and for spectators it is free.\n",
      "Included in the cost will be <L> a t-shirt or apron and you will be\n",
      "tasting samples of each <K> that is prepared.\n",
      "\n",
      "targets:\n",
      "<Z>! <Y> better <X> will have <W> your <V> 22 <U> World <T> from<S>\n",
      "be<R>  <Q> level<P> in <O>, timelines<N> smoker <M> the <L> either <K>\n",
      "meat\n",
      "\n",
      "\n",
      "\n",
      "[2]\n",
      "\n",
      "inputs:\n",
      "Discussion in 'Mac OS X Lion (10.7)' started by axboi87, Jan 20, 2012.\n",
      "<Z>'ve got a 500g <Y> internal drive and <X>a 240gb <W>. When trying\n",
      "<V> restore using disk utility <U>i <T>m given the error<S>Not<R>\n",
      "space on disk ____ to restore\" But <Q> shouldn't<P> to do that!!! Any\n",
      "ideas or workarounds before resorting to the above? Use Carbon <O>\n",
      "Cloner to copy one drive to the other. I've done<N> several <M> going\n",
      "from larger HDD to <L> I wound up <K> a bootable SSD drive. One step\n",
      "<J> to remember not to skip is to use Disk Utility to partition the\n",
      "SSD as GUID <I> HFS<H> before doing the clo<G>e. If it came Apple\n",
      "Partition Scheme, <F> if<E> let CCC<D> the <C>ne <B> the resulting <A>\n",
      "won't be bootable. CCC usually works in \"file mode\" and it can easily\n",
      "copy a larger <z> (that's mostly empty) onto a smaller drive. <y> you\n",
      "tell CCC to clone <x> drive you did NOT boot from, it can<w> in block\n",
      "copy<v> the destination drive<u> be <t> same size or larger than the\n",
      "drive <s> are clo<r>ing from (<q> I recall). I've actually done this\n",
      "somehow on Disk<p> times (booting from a different drive <o>or even\n",
      "the dvd) so not running <n> utility from the drive <m> clon <l> and\n",
      "had it work just<k> from larger to <j>able clone. Definitely format<i>\n",
      "drive clo<h>ing to first, as boot<g> Apple etc.. Thanks for pointing\n",
      "this out. My only experience using DU to go larger to smaller was when\n",
      "I was trying to <f> a<e> install stick and I was unable <d> restore\n",
      "InstallES <c>.dmg to  <b> 4 GB USB stick but of course the reason that\n",
      "<a>'t Théâtre is there was slightly more than 4 GB ofKeep.\n",
      "\n",
      "targets:\n",
      "<Z> I <Y>b <X>  <W> SSD <V> to <U>  <T>'<S> \"<R> enough <Q> I<P> have\n",
      "<O> Copy<N> this <M> times <L> smaller SSD and <K> with <J> you have\n",
      "<I> partition scheme<H>+<G>n <F> even<E> you<D> do<C>clo <B>, <A>\n",
      "drive <z> drive <y> If<x>a<w> work<v> mode where<u> must <t> the <s>\n",
      "you<r>n<q>if<p> Utility several <o> ( <n> disk <m> your <l>ing)<k>\n",
      "fine <j> smaller boot<i> the<h>n<g>able <f> make<e> Lion <d> to <c>D\n",
      "<b>a <a> wouldn Théâtre fitKeep data\n",
      "\n",
      "\n",
      "\n",
      "[3]\n",
      "\n",
      "inputs:\n",
      "Foil <Z>  <Y> and <X>dex shortall with metallic slinky insets.\n",
      "Attached metallic elastic <W> with O-ring. Headband <V> Great hip hop\n",
      "or jazz dance costume. Made in the USA.\n",
      "\n",
      "targets:\n",
      "<Z> plaid <Y>lycra <X> span <W> belt <V> included.\n",
      "\n",
      "\n",
      "\n",
      "[4]\n",
      "\n",
      "inputs:\n",
      "How many backlink <Z> per day <Y> new site? Discussion in 'Black Hat\n",
      "SEO <X> started <W> Om <V>plat <U>, Dec 3, 2010. 1) for <T>a<S>\n",
      "created site, what'<R> the max # backlinks per day I should do to be\n",
      "safe? 2) how long do I <Q> to let<P> site age <O> I can start making\n",
      "more blink<N>? I <M> 6000 forum profiles every 24 hours for 10 days\n",
      "for one of <L> sites which had a brand new domain. There <K> three\n",
      "<J>link <I> for every of these forum profile so thats 18 000 backlinks\n",
      "every 24 hours and nothing happened<H> terms of being penal<G> or\n",
      "sandboxed. This is now maybe 3 months <F> and the site<E> ranking on\n",
      "first page for a lot of my targeted keywords. build more you can in\n",
      "starting but do<D> submission<C> spammy type <B> manual + relevant <A>\n",
      "post. <z> then after 1 <y> you can<x> a big blast.. Wow, dude, you\n",
      "built<w>k back<v>s a day on <u> brand new site? How quickly did you\n",
      "rank up? <t> kind <s>/searches did those keywords<r>?\n",
      "\n",
      "targets:\n",
      "<Z>s <Y> for <X>' <W> by <V>o <U>a <T> <S> newly<R>s <Q> have<P> my\n",
      "<O> before<N>s <M> did about <L> my <K> is <J> back <I>s<H> in<G>ized\n",
      "<F> ago<E> is<D> manual<C> and not <B> means <A> to the <z>. <y>\n",
      "month<x> make<w> 18<v>link<u>a <t> What <s> of competition<r> have\n",
      "\n",
      "\n",
      "\n",
      "[5]\n",
      "\n",
      "inputs:\n",
      "The Denver Board <Z> Education opened the 2017-18 school year with an\n",
      "update on projects that include new construction, <Y> mitigation and\n",
      "quality <X> environments. We are <W> that Denver students will be the\n",
      "<V> of a <U> year, $572 million <T> Obligation Bond<S> Since<R>\n",
      "passage of <Q> bond, our construction team has worked<P> schedule the\n",
      "projects over the four-year term of the bond. Denver voters on Tuesday\n",
      "<O> and mill funding measures for students in Denver Public Schools,\n",
      "agreeing to invest $572 million<N> bond funding to build and improve\n",
      "schools <M> $56.6 <L> in operating <K> to support proven initiatives\n",
      "<J> such as early literacy. Denver voters <I> yes<H> bond and mill\n",
      "levy funding support for DPS students and schools. Click to learn more\n",
      "about the details of the voter-approved bond measure<G> Denver <F> on\n",
      "Nov. 8 approved bond and mill funding measures for DPS students\n",
      "and<E>. Learn more<D> what’s<C> in the mill  <B>y measure.\n",
      "\n",
      "targets:\n",
      "<Z> of <Y> upgrades, heat <X> learning <W> excited <V> beneficiaries\n",
      "<U> four <T> General<S>.<R> the <Q> the<P> to <O> approved bond<N> in\n",
      "<M> and <L> million <K> dollars <J>, <I> say<H> to<G>. <F> voters<E>\n",
      "schools<D> about<C> included <B>lev\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_input_target_pairs(inputs_targets_pairs, sentinels, wrapper=textwrap.TextWrapper(width=70), tokenizer=tokenizer):\n",
    "    for i, inp_tgt_pair in enumerate(inputs_targets_pairs, 1):\n",
    "        inps, tgts = inp_tgt_pair\n",
    "        inps = str(pretty_decode(inps, sentinels, tokenizer).numpy(), encoding='utf-8')\n",
    "        tgts = str(pretty_decode(tgts, sentinels, tokenizer).numpy(), encoding='utf-8')\n",
    "        print(f'[{i}]\\n\\n'\n",
    "              f'inputs:\\n{wrapper.fill(text=inps)}\\n\\n'\n",
    "              f'targets:\\n{wrapper.fill(text=tgts)}\\n\\n\\n')\n",
    "\n",
    "# Print the first 5 samples\n",
    "display_input_target_pairs(inputs_targets_pairs[0:5], sentinels, wrapper, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8e8a4d-c378-495c-8d0b-5cdac0ceb25c",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Pretrain a T5 model using C4\n",
    "\n",
    "Now you are going to use the Transformer's architecture that you coded in the previous assignment to summarize text, but this time to answer questions. Instead of training the question answering model from scratch, you will first \"pre-train\" the model using the C4 data set you just processed. This will help the model to learn the general structure of language from a large dataset. This is much easier to do, as you don't need to label any data, but just use the masking, which is done automatically. You will then use the data from the SQuAD set to teach the model to answer questions given a context. To start let's review the Transformer's architecture. \n",
    "\n",
    "<img src = \"images/fulltransformer.png\" width=\"300\" height=\"600\">\n",
    "\n",
    "\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - Instantiate a new transformer model\n",
    "\n",
    "We have packaged the code implemented in the previous week into the `Transformer.py` file. You can import it here, and setup with the same configuration used there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c22f2e9-d6f0-4177-9d3d-03a5380bd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model parameters\n",
    "num_layers                 = 2\n",
    "embedding_dim              = 128\n",
    "fully_connected_dim        = 128\n",
    "num_heads                  = 2\n",
    "positional_encoding_length = 256\n",
    "\n",
    "encoder_vocab_size = int(tokenizer.vocab_size())\n",
    "decoder_vocab_size = encoder_vocab_size\n",
    "\n",
    "# Initialize the model\n",
    "transformer = transformer_utils.Transformer(\n",
    "    num_layers, \n",
    "    embedding_dim, \n",
    "    num_heads, \n",
    "    fully_connected_dim,\n",
    "    encoder_vocab_size, \n",
    "    decoder_vocab_size, \n",
    "    positional_encoding_length, \n",
    "    positional_encoding_length,\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa70c868-e281-4381-9c59-90ff1712cf4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(32000, 128, padding_idx=0)\n",
       "    (enc_layers): ModuleList(\n",
       "      (0-1): 2 x EncoderLayer(\n",
       "        (attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (layernorm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (layernorm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(32000, 128, padding_idx=0)\n",
       "    (dec_layers): ModuleList(\n",
       "      (0-1): 2 x DecoderLayer(\n",
       "        (mha1): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (mha2): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (layernorm1): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layernorm2): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (layernorm3): BatchNorm1d(128, eps=1e-06, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_ffn): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (final_layer): Linear(in_features=128, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97660dd-cadf-4749-b360-079cd2534a22",
   "metadata": {},
   "source": [
    "\n",
    "Now, you will define the optimizer and the loss function. For this task the model will try to predict the masked words, so, as in the previous lab, the loss function will be the `torch.NLLLoss(...)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f0c11-12f9-43ab-b9a2-88d022a53a2a",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - C4 pretraining\n",
    "\n",
    "For training a Tensorflow model you need to arrange the data into datasets. Now, you will get the `inputs` and the `targets` for the transformer model from the `inputs_targets_pairs`. Before creating the dataset, you need to be sure that all `inputs` have the same length by truncating the longer sequences and padding the shorter ones with `0`. The same must be done for the targets. The function `tf.keras.preprocessing.sequence.pad_sequences` will help you here, as in the previous week assignment.\n",
    "\n",
    "You will use a `BATCH_SIZE = 64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99ea902c-a778-4b9f-959b-bbcb7c0d5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data so this can run in this environment\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "inputs  = tf.keras.preprocessing.sequence.pad_sequences([x[0] for x in inputs_targets_pairs], maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences([x[1] for x in inputs_targets_pairs], maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs  = tf.cast(inputs,  dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE  = 64\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72cfb9c4-1c45-48d2-992d-c04f765b4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "749b595c-a732-4aab-93e1-3f37a8cbc972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12847, 277, 15068, 4501, 3, 12297, 3399, 16, 5964, 7115, 9, 31999, 531, 25, 241, 12, 129, 31998, 44, 492, 3326, 15068, 58, 148, 31997, 8, 1004, 6, 474, 48, 30, 31996, 4793, 230, 5, 2721, 6, 1600, 31995, 727, 1715, 31994, 4501, 15068, 16127, 6, 9137, 2659, 5595, 31993, 301, 782, 3624, 14627, 15, 12612, 277, 5, 216, 56, 31992, 2119, 31991, 9, 19529, 31990, 853, 21, 921, 113, 2746, 12, 129, 394, 28, 70, 17712, 1098, 5, 216, 56, 3884, 25, 762, 25, 174, 12, 214, 12, 5978, 31989, 3, 9, 3, 23405, 4547, 15068, 2259, 6, 379, 2097, 6, 5459, 31988, 6, 3604, 1801, 11, 27856, 6, 303, 31987, 11, 1472, 251, 5, 37, 583, 12, 36, 16, 31986, 853, 19, 25264, 399, 568, 6, 11, 21, 21380, 7, 34, 19, 339, 5, 15746, 26, 16, 8, 583, 56, 36, 31985, 3, 9, 3, 17, 18, 9486, 42, 3, 9, 1409, 29, 11, 25, 56, 36, 12246, 5977, 13, 284, 31984, 24, 19, 2657, 5]\n",
      "\n",
      "[31999, 55, 31998, 394, 31997, 56, 43, 31996, 39, 31995, 1630, 31994, 1150, 31993, 45, 31992, 36, 31991, 3, 31990, 593, 31989, 16, 31988, 6, 13618, 7, 31987, 24190, 31986, 8, 31985, 893, 31984, 3604, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputs_targets_pairs[0][0]), print(), print(inputs_targets_pairs[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c1afb7c4-ccf6-4301-b455-dc04a8823ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039ae3c-0241-4981-a46f-e9e6851e5c77",
   "metadata": {},
   "source": [
    "Now, you can run the training loop for 10 epochs. Running it with a big dataset such as C4 on a good computer with enough memory and a good GPU could take more than 24 hours. Here, you will run few epochs using a small portion of the C4 dataset for illustration. It will only take a few minutes, but the model won't be very powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8baa0752-c3e3-42db-85f9-a8d1117c382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (batch, (inp, tar)) in enumerate(dataset):\n",
    "    if batch >=2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2793b59-daf4-4b69-88b3-1a667992d689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84585f9d-808f-44db-b2a1-d4cc012c741a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 150]), torch.Size([64, 50]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = torch.tensor(inp.numpy()).to(torch.int32).to(device)\n",
    "tar = torch.tensor(tar.numpy()).to(torch.int32).to(device)\n",
    "inp.shape, tar.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d24af5ba-b916-49d6-8951-7416f2a04348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1210,    12,     8,  ...,     0,     0,     0],\n",
       "        [ 4467,     7,  1849,  ...,   123,     6,   123],\n",
       "        [31999,    12,   240,  ...,   256,    51,   202],\n",
       "        ...,\n",
       "        [20876,    19,     3,  ...,  2121,    11,  1769],\n",
       "        [   37, 31999,  3849,  ...,   109,    18, 12931],\n",
       "        [  421,  5193,  3325,  ...,     0,     0,     0]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "866f7a0e-1737-4432-85e5-d02fcaf3f283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:  torch.Size([64, 50, 32000])\n"
     ]
    }
   ],
   "source": [
    "transformer.to(device)\n",
    "preds, _ = transformer(inp, tar)\n",
    "print('preds: ', preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0aff93dc-61ed-41ab-849c-62c0a3c40d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  torch.Size([3200, 32000])\n",
      "targets:  torch.Size([3200])\n",
      "10.490058898925781\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
    "\n",
    "# Ensure outputs is of type Float\n",
    "outputs = preds.float().clone()\n",
    "outputs = outputs.reshape(-1, preds.shape[2])\n",
    "print('outputs: ', outputs.shape)\n",
    "\n",
    "# Ensure targets is of type Long\n",
    "targets = tar.long().clone()\n",
    "targets = targets.reshape(-1)\n",
    "print('targets: ', targets.shape)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Calculate loss\n",
    "loss = criterion(outputs, targets)\n",
    "loss.backward()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e2c76f7-d6d4-4149-bc9d-6f9149e12ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31999,  4314, 31998,  ...,     0,     0,     0],\n",
       "        [31999,    28, 31998,  ..., 31978,    75,     1],\n",
       "        [31999,   571, 31998,  ...,    16, 31977,   225],\n",
       "        ...,\n",
       "        [31999,    11, 31998,  ..., 31976,    12, 31975],\n",
       "        [31999,   638, 31998,  ..., 31978,    12, 31977],\n",
       "        [31999,   876,    21,  ...,     0,     0,     0]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc1726d3-2737-4825-8ac1-ac0c72b18bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31999,  4314, 31998,  ...,     0,     0,     0],\n",
       "        [31999,    28, 31998,  ...,    23, 31978,    75],\n",
       "        [31999,   571, 31998,  ..., 31978,    16, 31977],\n",
       "        ...,\n",
       "        [31999,    11, 31998,  ...,  2849, 31976,    12],\n",
       "        [31999,   638, 31998,  ...,     7, 31978,    12],\n",
       "        [31999,   876,    21,  ...,     0,     0,     0]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[:, :-1] # tar_inp | to decoder i guess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a5386d0d-c688-44d3-baf1-e492725085aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4314, 31998, 10149,  ...,     0,     0,     0],\n",
       "        [   28, 31998,   543,  ..., 31978,    75,     1],\n",
       "        [  571, 31998,    19,  ...,    16, 31977,   225],\n",
       "        ...,\n",
       "        [   11, 31998,    18,  ..., 31976,    12, 31975],\n",
       "        [  638, 31998, 12185,  ..., 31978,    12, 31977],\n",
       "        [  876,    21,     8,  ...,     0,     0,     0]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[:, 1:] # tar_real | to loss fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "454fadc9-032b-48a4-9769-9ceb751c92ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Interna\\xc8\\x9bional'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize([31999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88f97a78-7208-4d6e-8083-0ef0b287f51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1210,    12,     8, 10043, 17368, 18360, 31999,    61,    16, 31998,\n",
       "        10669,     6,    37,  1485, 31997, 18301,   257,   138,  2345,    47,\n",
       "         5330,  1192,    16,   507,  4560,    38,     3,     9,  1679,    18,\n",
       "        11415,  2078,     5,     3, 13283,     3,     9,  2646,   865,    16,\n",
       "          957,  3076,     6,     3,     9,  1472, 10932,    24, 31996,     5,\n",
       "           71,   215,   865,     6,     8,  2078, 31995, 26935,     6,    48,\n",
       "           97,    91,    13,  4459,  7944,     6, 31994,    47,  2425,    30,\n",
       "            8,   337,  2140,     5,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22bdbe69-92b2-45ea-9e68-b8b0da6d6034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Home to the oldest congregation (17 Interna\\xc8\\x9bional) in erwachseneetta, The First Cushiongregational Church was originally built in 1807 as a wood-frame church. Almost a century later in 1905, a fire destroyed that imunitar. A year later, the church Intellectual rebuilt, this time out of yellow brick, traditi was dedicated on the same spot.'>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = inp[0,:].to('cpu').clone()\n",
    "inp_de = inp_de.numpy()\n",
    "\n",
    "inp_de = tokenizer.detokenize(inp_de)\n",
    "\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "168b43fc-e776-4e86-922c-f117afcaa1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999,  4314, 31998, 10149, 31997,  1193, 31996,  1809, 31995,    47,\n",
       "        31994,    11,     1,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f01cae1-b39a-4d3f-be17-50c3a6ac0e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Interna\\xc8\\x9bional96 erwachsene Mari Cushion Con imunitar structure Intellectual was traditi and'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_de = tar[0,:].to('cpu').clone()\n",
    "tar_de = tar_de.numpy()\n",
    "\n",
    "tar_de = tokenizer.detokenize(tar_de)\n",
    "\n",
    "tar_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9dfa755-07b6-4101-9a1c-c0a2ccf815f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Home to the oldest congregation (17 <Z>) in <Y>etta, The First <X>gregational Church was originally built in 1807 as a wood-frame church. Almost a century later in 1905, a fire destroyed that <W>. A year later, the church <V> rebuilt, this time out of yellow brick, <U> was dedicated on the same spot.'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "584952c5-e63e-434b-9119-2804fcb046d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'<Z>96 <Y> Mari <X> Con <W> structure <V> was <U> and'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(tar_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7b759456-9a97-45c5-a5e3-c4ef2fb036cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "87dc54d4-6ff4-4b2c-b40c-4b3954a7a402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 20]\n",
      "\n",
      "20:  3.932839035987854\n",
      "\n",
      "\n",
      "40:  3.9562532782554625\n",
      "\n",
      "\n",
      "60:  3.9803857167561847\n",
      "\n",
      "\n",
      "80:  3.9956479012966155\n",
      "\n",
      "\n",
      "100:  4.009383769035339\n",
      "\n",
      "\n",
      "120:  4.021211091677348\n",
      "\n",
      "\n",
      "140:  4.030296976225717\n",
      "\n",
      "Time taken for one epoch: 37.79567193984985 sec\n",
      "Epoch [2 / 20]\n",
      "\n",
      "20:  3.892728352546692\n",
      "\n",
      "\n",
      "40:  3.894625049829483\n",
      "\n",
      "\n",
      "60:  3.8986412366231282\n",
      "\n",
      "\n",
      "80:  3.9094325363636018\n",
      "\n",
      "\n",
      "100:  3.917003610134125\n",
      "\n",
      "\n",
      "120:  3.922011075417201\n",
      "\n",
      "\n",
      "140:  3.927750905922481\n",
      "\n",
      "Time taken for one epoch: 37.6154363155365 sec\n",
      "Epoch [3 / 20]\n",
      "\n",
      "20:  3.8019819378852846\n",
      "\n",
      "\n",
      "40:  3.813938891887665\n",
      "\n",
      "\n",
      "60:  3.8208597898483276\n",
      "\n",
      "\n",
      "80:  3.831940159201622\n",
      "\n",
      "\n",
      "100:  3.840540907382965\n",
      "\n",
      "\n",
      "120:  3.848538513978322\n",
      "\n",
      "\n",
      "140:  3.8563846026148116\n",
      "\n",
      "Time taken for one epoch: 37.58730173110962 sec\n",
      "Epoch [4 / 20]\n",
      "\n",
      "20:  3.7319002032279966\n",
      "\n",
      "\n",
      "40:  3.7375342905521394\n",
      "\n",
      "\n",
      "60:  3.7472851276397705\n",
      "\n",
      "\n",
      "80:  3.753888776898384\n",
      "\n",
      "\n",
      "100:  3.7614490818977355\n",
      "\n",
      "\n",
      "120:  3.768587766091029\n",
      "\n",
      "\n",
      "140:  3.7746338163103377\n",
      "\n",
      "Time taken for one epoch: 37.53516244888306 sec\n",
      "Epoch [5 / 20]\n",
      "\n",
      "20:  3.6571163535118103\n",
      "\n",
      "\n",
      "40:  3.6607883155345915\n",
      "\n",
      "\n",
      "60:  3.6691497723261515\n",
      "\n",
      "\n",
      "80:  3.679546132683754\n",
      "\n",
      "\n",
      "100:  3.6859974336624144\n",
      "\n",
      "\n",
      "120:  3.694372699658076\n",
      "\n",
      "\n",
      "140:  3.6994499530111042\n",
      "\n",
      "Time taken for one epoch: 37.60599327087402 sec\n",
      "Epoch [6 / 20]\n",
      "\n",
      "20:  3.565690648555756\n",
      "\n",
      "\n",
      "40:  3.578146308660507\n",
      "\n",
      "\n",
      "60:  3.590783735116323\n",
      "\n",
      "\n",
      "80:  3.6026589035987855\n",
      "\n",
      "\n",
      "100:  3.6122133207321165\n",
      "\n",
      "\n",
      "120:  3.6238835672537486\n",
      "\n",
      "\n",
      "140:  3.6323163969176155\n",
      "\n",
      "Time taken for one epoch: 37.96967625617981 sec\n",
      "Epoch [7 / 20]\n",
      "\n",
      "20:  3.5097533226013184\n",
      "\n",
      "\n",
      "40:  3.5233590841293334\n",
      "\n",
      "\n",
      "60:  3.531471840540568\n",
      "\n",
      "\n",
      "80:  3.54137844145298\n",
      "\n",
      "\n",
      "100:  3.5505669355392455\n",
      "\n",
      "\n",
      "120:  3.5605015913645426\n",
      "\n",
      "\n",
      "140:  3.570893040725163\n",
      "\n",
      "Time taken for one epoch: 37.7266411781311 sec\n",
      "Epoch [8 / 20]\n",
      "\n",
      "20:  3.426839601993561\n",
      "\n",
      "\n",
      "40:  3.4410682201385496\n",
      "\n",
      "\n",
      "60:  3.4613831202189127\n",
      "\n",
      "\n",
      "80:  3.477434879541397\n",
      "\n",
      "\n",
      "100:  3.48806099653244\n",
      "\n",
      "\n",
      "120:  3.495395761728287\n",
      "\n",
      "\n",
      "140:  3.5062400102615356\n",
      "\n",
      "Time taken for one epoch: 37.665430784225464 sec\n",
      "Epoch [9 / 20]\n",
      "\n",
      "20:  3.377499854564667\n",
      "\n",
      "\n",
      "40:  3.3899943470954894\n",
      "\n",
      "\n",
      "60:  3.404519518216451\n",
      "\n",
      "\n",
      "80:  3.4146139085292817\n",
      "\n",
      "\n",
      "100:  3.425444221496582\n",
      "\n",
      "\n",
      "120:  3.4367427925268808\n",
      "\n",
      "\n",
      "140:  3.4454566291400366\n",
      "\n",
      "Time taken for one epoch: 37.575639724731445 sec\n",
      "Epoch [10 / 20]\n",
      "\n",
      "20:  3.305922544002533\n",
      "\n",
      "\n",
      "40:  3.3204027354717254\n",
      "\n",
      "\n",
      "60:  3.3361515124638874\n",
      "\n",
      "\n",
      "80:  3.349272033572197\n",
      "\n",
      "\n",
      "100:  3.362734754085541\n",
      "\n",
      "\n",
      "120:  3.377049833536148\n",
      "\n",
      "\n",
      "140:  3.3869335157530647\n",
      "\n",
      "Time taken for one epoch: 37.624927282333374 sec\n",
      "Epoch [11 / 20]\n",
      "\n",
      "20:  3.2676269173622132\n",
      "\n",
      "\n",
      "40:  3.2704336285591125\n",
      "\n",
      "\n",
      "60:  3.27698571284612\n",
      "\n",
      "\n",
      "80:  3.29048333466053\n",
      "\n",
      "\n",
      "100:  3.3038050365447997\n",
      "\n",
      "\n",
      "120:  3.3140845318635304\n",
      "\n",
      "\n",
      "140:  3.3284819739205496\n",
      "\n",
      "Time taken for one epoch: 37.62219762802124 sec\n",
      "Epoch [12 / 20]\n",
      "\n",
      "20:  3.181013059616089\n",
      "\n",
      "\n",
      "40:  3.204194951057434\n",
      "\n",
      "\n",
      "60:  3.2216603636741636\n",
      "\n",
      "\n",
      "80:  3.237585869431496\n",
      "\n",
      "\n",
      "100:  3.2503781795501707\n",
      "\n",
      "\n",
      "120:  3.262382886807124\n",
      "\n",
      "\n",
      "140:  3.2711866412843977\n",
      "\n",
      "Time taken for one epoch: 37.71876287460327 sec\n",
      "Epoch [13 / 20]\n",
      "\n",
      "20:  3.153003764152527\n",
      "\n",
      "\n",
      "40:  3.1494395673274993\n",
      "\n",
      "\n",
      "60:  3.16377610762914\n",
      "\n",
      "\n",
      "80:  3.181564688682556\n",
      "\n",
      "\n",
      "100:  3.196370737552643\n",
      "\n",
      "\n",
      "120:  3.208749262491862\n",
      "\n",
      "\n",
      "140:  3.2200152397155763\n",
      "\n",
      "Time taken for one epoch: 37.877829790115356 sec\n",
      "Epoch [14 / 20]\n",
      "\n",
      "20:  3.0911230206489564\n",
      "\n",
      "\n",
      "40:  3.100430887937546\n",
      "\n",
      "\n",
      "60:  3.1192649722099306\n",
      "\n",
      "\n",
      "80:  3.1292261987924577\n",
      "\n",
      "\n",
      "100:  3.1429913330078123\n",
      "\n",
      "\n",
      "120:  3.156024640798569\n",
      "\n",
      "\n",
      "140:  3.1689064911433626\n",
      "\n",
      "Time taken for one epoch: 37.67287993431091 sec\n",
      "Epoch [15 / 20]\n",
      "\n",
      "20:  3.0491593718528747\n",
      "\n",
      "\n",
      "40:  3.057163155078888\n",
      "\n",
      "\n",
      "60:  3.074385702610016\n",
      "\n",
      "\n",
      "80:  3.087287625670433\n",
      "\n",
      "\n",
      "100:  3.0976837944984434\n",
      "\n",
      "\n",
      "120:  3.1104207078615826\n",
      "\n",
      "\n",
      "140:  3.1219100628580367\n",
      "\n",
      "Time taken for one epoch: 37.96788191795349 sec\n",
      "Epoch [16 / 20]\n",
      "\n",
      "20:  2.9793404936790466\n",
      "\n",
      "\n",
      "40:  3.002635896205902\n",
      "\n",
      "\n",
      "60:  3.024795631567637\n",
      "\n",
      "\n",
      "80:  3.038945260643959\n",
      "\n",
      "\n",
      "100:  3.052652032375336\n",
      "\n",
      "\n",
      "120:  3.0666668275992075\n",
      "\n",
      "\n",
      "140:  3.0749402471951077\n",
      "\n",
      "Time taken for one epoch: 38.31355595588684 sec\n",
      "Epoch [17 / 20]\n",
      "\n",
      "20:  2.93512761592865\n",
      "\n",
      "\n",
      "40:  2.9653990387916567\n",
      "\n",
      "\n",
      "60:  2.979647195339203\n",
      "\n",
      "\n",
      "80:  2.998079526424408\n",
      "\n",
      "\n",
      "100:  3.0120428609848022\n",
      "\n",
      "\n",
      "120:  3.0222254514694216\n",
      "\n",
      "\n",
      "140:  3.0363975763320923\n",
      "\n",
      "Time taken for one epoch: 38.40945553779602 sec\n",
      "Epoch [18 / 20]\n",
      "\n",
      "20:  2.8970617175102236\n",
      "\n",
      "\n",
      "40:  2.922115421295166\n",
      "\n",
      "\n",
      "60:  2.9342126925786336\n",
      "\n",
      "\n",
      "80:  2.956002688407898\n",
      "\n",
      "\n",
      "100:  2.9693014287948607\n",
      "\n",
      "\n",
      "120:  2.9843234499295552\n",
      "\n",
      "\n",
      "140:  2.993270911489214\n",
      "\n",
      "Time taken for one epoch: 38.74295949935913 sec\n",
      "Epoch [19 / 20]\n",
      "\n",
      "20:  2.8808035254478455\n",
      "\n",
      "\n",
      "40:  2.8906124114990233\n",
      "\n",
      "\n",
      "60:  2.8998176058133445\n",
      "\n",
      "\n",
      "80:  2.9144435971975327\n",
      "\n",
      "\n",
      "100:  2.9264659810066225\n",
      "\n",
      "\n",
      "120:  2.93914631207784\n",
      "\n",
      "\n",
      "140:  2.94855877501624\n",
      "\n",
      "Time taken for one epoch: 38.895732164382935 sec\n",
      "Epoch [20 / 20]\n",
      "\n",
      "20:  2.8076154708862306\n",
      "\n",
      "\n",
      "40:  2.8245706260204315\n",
      "\n",
      "\n",
      "60:  2.841797113418579\n",
      "\n",
      "\n",
      "80:  2.860663491487503\n",
      "\n",
      "\n",
      "100:  2.872648465633392\n",
      "\n",
      "\n",
      "120:  2.886443950732549\n",
      "\n",
      "\n",
      "140:  2.8974404147693087\n",
      "\n",
      "Time taken for one epoch: 39.20720195770264 sec\n"
     ]
    }
   ],
   "source": [
    "transformer.to(device)\n",
    "\n",
    "# test_example  = 0\n",
    "# true_summary  = summary_test[test_example]\n",
    "# true_document = document_test[test_example]\n",
    "\n",
    "\n",
    "# Training Hyperparameters\n",
    "num_epochs    = 20 #20\n",
    "learning_rate = 0.001\n",
    "batch_size    = 64\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "pad_idx    = 0\n",
    "criterion  = nn.NLLLoss(ignore_index=pad_idx)\n",
    "optimizer  = optim.Adam(transformer.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch+1} / {num_epochs}]')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    running_loss = 0\n",
    "    transformer.train()\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "\n",
    "        inp1 = torch.tensor(inp.numpy()).long().clone().to(device)\n",
    "        tar1 = torch.tensor(tar.numpy()).long().clone().to(device)\n",
    "\n",
    "        # print('inp_data1: ', inp_data1.shape)\n",
    "        # print('target1: ',   target1.shape)\n",
    "\n",
    "        preds, _ = transformer(inp1, tar1[:, :-1])\n",
    "\n",
    "        # Ensure outputs is of type Float\n",
    "        outputs = preds.float().clone()\n",
    "        outputs = outputs.reshape(-1, preds.shape[2])\n",
    "        # print('outputs: ', outputs.shape)\n",
    "        \n",
    "        # Ensure targets is of type Long\n",
    "        targets = tar1[:, 1:].long().clone()\n",
    "        targets = targets.reshape(-1)\n",
    "        # print('targets: ', targets.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss = running_loss+loss.item()\n",
    "        avg_running_loss = running_loss/(batch+1)\n",
    "\n",
    "        if (batch+1)%20 == 0:\n",
    "            print()\n",
    "            print(f'{batch+1}: ', avg_running_loss)\n",
    "            print()\n",
    "        \n",
    "        if (batch+1) >= len(dataset):\n",
    "            break\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "    # print('Example summarization on the test set:')\n",
    "    # print('  True summarization:')\n",
    "    # print(f'    {true_summary}')\n",
    "    # print('  Predicted summarization:')\n",
    "    \n",
    "    # transformer.eval()\n",
    "    # print(f'    {summarize(transformer, true_document)}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bf86e427-a690-4d02-9dac-78de40f95e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer, \"pretrained transformer (encoder-decoder) 10000 seqs 30 epoch.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e2c02-e3d7-4267-bed1-5530cbd88469",
   "metadata": {},
   "source": [
    "## Checking if given a context and an initial token, whether the model is indeed predicting the expected next token or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "203ee538-ac3e-466d-b812-4b9a788e002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = torch.load('pretrained transformer (encoder-decoder) 10000 seqs 30 epoch.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7ed8837c-fda5-4d95-b5a7-832cd3f3348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999,    12,   240,   124,    13,    39, 21118,    28,     8,   199,\n",
       "           13,     3,     9, 25740,    23,   152,    58,   290, 31998,   150,\n",
       "          224,  1829,    38,  3609,    39,   861,    21,     8, 31997,    97,\n",
       "           16, 31996,  6026,     5,    94,   656,    25,   473,     6,    38,\n",
       "            3, 31995,     8,   829,  8800,    13,     8,   296,    19,   652,\n",
       "          504,  3737,    30,    25,     5,   611,     6, 31994,   798,    13,\n",
       "        26078,  4049,  1273,    15,     7,     6,   116,    39, 21118,  2347,\n",
       "            3,  1092,     5,   304,  1792,    48,   589,     6,    25,   398,\n",
       "          373,  1049,    16,   574,    28,     3,     9, 18325,    23,   152,\n",
       "            5,   290,    33, 31993,  1155,   190,    84,     3,     9, 18325,\n",
       "           23,   152,    54,  1539,    25,    16,   838,   124,    13,    39,\n",
       "         9806,     5, 31992,   323, 31991,   669,    72,     5,    37,   166,\n",
       "           11, 19839,   589,    19, 31990,   256,    51, 31989,  1707,     7,\n",
       "            5, 31988,    33,    16,  1646,   574,    13,     3,     9, 31987,\n",
       "          152,     6, 31986,    54,  1153, 31985,     8,   256,    51,   202],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c345873-e363-4e1f-832c-04b1bcfc52c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31999,   571, 31998,    19, 31997,   166, 31996,    39, 31995,    99,\n",
       "        31994,    48, 31993,   186, 31992, 25731, 31991,    12, 31990,     8,\n",
       "        31989,   202, 31988,   366,    25, 31987, 18325,    23, 31986,   258,\n",
       "           25, 31985,  2023, 31984,     7,    24, 31983,     6, 31982,   430,\n",
       "        31981, 15266, 31980,   186, 31979,     7, 31978,    16, 31977,   225],\n",
       "       device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[2,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0823cbcc-3498-4c78-9cb7-94604218576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Interna\\xc8\\x9bional to take care of your newborn with the help of a Pediatrician? There erwachsene no such feeling as holding your child for the Cushion time in imunitar arms. It makes you feel, as  Intellectual the whole happiness of the world is getting showered on you. However, traditi moment of bliss vanishes, when your newborn gets ill. To avoid this thing, you must always stay in contact with a pediatrician. There are disguise ways through which a pediatrician can guide you in taking care of your infant.exerce downnourishe learn more. The first and foremost thing is predominant immamiti\\xc3\\xa9izations. erkennt are in regular contact of adimensionan, inf\\xc3\\xa9rieur can easily refugi the immun'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = np.copy(inp[2,:].to('cpu').numpy())\n",
    "\n",
    "\n",
    "inp_de = tokenizer.detokenize(inp_de)\n",
    "\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6901f0c-e94d-4659-a26a-2d1770e4818c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'<Z> to take care of your newborn with the help of a Pediatrician? There <Y> no such feeling as holding your child for the <X> time in <W> arms. It makes you feel, as  <V> the whole happiness of the world is getting showered on you. However, <U> moment of bliss vanishes, when your newborn gets ill. To avoid this thing, you must always stay in contact with a pediatrician. There are <T> ways through which a pediatrician can guide you in taking care of your infant.<S> down<R> learn more. The first and foremost thing is <Q> imm<P>izations. <O> are in regular contact of a<N>an, <M> can easily <L> the immun'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4208753-5a15-4675-9026-d450de620e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Interna\\xc8\\x9bional How erwachsene is Cushion first imunitar your Intellectualif traditi this disguise manyexerce Scrollnourishe to predominant theamiti\\xc3\\xa9un erkennt When youdimension pediatrici inf\\xc3\\xa9rieur then you refugi schedule cheddars that unterlieg, garanteaz anotherf\\xc4\\x83cute confusingr\\xc3\\xa9glage many pedepsesGermain indistinctly should'>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_de = np.copy(tar[2,:].to('cpu').numpy())\n",
    "tar_de = tokenizer.detokenize(tar_de)\n",
    "tar_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0eed0457-3e00-44e5-b82d-e9b0fb578a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'<Z> How <Y> is <X> first <W> your <V>if <U> this <T> many<S> Scroll<R> to <Q> the<P>un <O> When you<N> pediatrici <M> then you <L> schedule <K>s that <J>, <I> another<H> confusing<G> many <F>s<E> in<D> should'>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(tar_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91b848fb-9bc6-4068-b7ae-c764df536bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[3037, 29, 9, 2, 6318]]>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(['Interna\\xc8\\x9bional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc4521-2557-4031-918a-6328ddcb9468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27cb0e-303a-4ac2-9c60-b68099cc0c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb6594f-7537-4685-8b2f-521e6904dfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50573233-37d4-491b-ac1f-7eb95e50c6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 150), (1, 1))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[2,:].to('cpu').numpy()\n",
    "inp[2,:].to('cpu').numpy().reshape(1, inp[2,:].shape[0]).shape, np.array([[31999]]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d8891140-c637-4bce-9589-ac9c0ec53928",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp1 = torch.tensor(np.copy(inp[2:4,:].to('cpu').numpy())).long().clone().to(device)\n",
    "tar1 = torch.tensor(np.copy(np.array([[31997],[31999]]))).long().clone().to(device)\n",
    "\n",
    "\n",
    "# print('inp_data1: ', inp_data1.shape)\n",
    "# print('target1: ',   target1.shape)\n",
    "\n",
    "preds, _ = transformer(inp1, tar1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fac720c2-d6ee-4605-8f0c-b1d12c2d00cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32000])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "938f668a-9f5b-44d8-a6e7-2d1458fc0b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]),\n",
       " tensor([[5],\n",
       "         [3]], device='cuda:0'))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(preds[:,-1,:], dim=-1).shape, torch.argmax(preds, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "39f2313b-13f3-46af-b535-623caef9b9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'. '>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = torch.argmax(preds[:,-1,:], dim=-1).to(torch.int32).to('cpu').clone()\n",
    "inp_de = inp_de.numpy()\n",
    "\n",
    "inp_de = tokenizer.detokenize(inp_de)\n",
    "\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ad99ec77-ac0d-4166-9497-9ba3733b13f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'. '>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "563ac857-850c-4dca-8cb5-d1fe995fad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41bf68-7553-40d5-8754-25a1163f0c1e",
   "metadata": {},
   "source": [
    "### Own Text. Note these cells were run after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7032dc7e-a09d-41a5-872e-472cae7b9617",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = 'my name is ans imran'\n",
    "a2 = 'i live in paris'\n",
    "\n",
    "b1 = 'my name'\n",
    "b2 = 'i live'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "606b58b5-7a1b-43a9-9418-5daefe7f403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tokenizer.tokenize([a1]).to_tensor().numpy()\n",
    "a2 = tokenizer.tokenize([a2]).to_tensor().numpy()\n",
    "\n",
    "b1 = tokenizer.tokenize([b1]).to_tensor().numpy()\n",
    "b2 = tokenizer.tokenize([b2]).to_tensor().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a8d2b847-d7f9-4533-8533-0c9c25a78093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  82,  564,   19,   46,    7,  256, 2002]]),\n",
       " array([[  3,  23, 619,  16, 260, 159]]),\n",
       " array([[ 82, 564]]),\n",
       " array([[  3,  23, 619]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1, a2, b1, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5cc321c7-7830-4f43-8d4c-66d2c87f9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([  82,  564,   19,   46,    7,  256, 2002])\n",
    "a2 = np.array([  27,  619,   16,  260,  159,    0,    0])\n",
    "\n",
    "b1 = np.array([82, 564])\n",
    "b2 = np.array([27, 619])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "93906369-82ee-43f5-89d5-22f4ff08bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([a1,a2]).to(device)\n",
    "b = torch.tensor([b1,b2]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc443afc-0f77-4cc0-830b-fd19a0aeaed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = transformer(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "85dac9ba-1b32-455a-ae4f-484cb3c0ada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 32000])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dac90072-6a05-4314-82b8-72043f069736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'born.'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_de = torch.argmax(preds[:,-1,:], dim=-1).to(torch.int32).to('cpu').clone()\n",
    "inp_de = inp_de.numpy()\n",
    "\n",
    "inp_de = tokenizer.detokenize(inp_de)\n",
    "\n",
    "inp_de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a7ed2dd-ffdc-4c28-884b-22c3078e95a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'born.'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it'll work\n",
    "pretty_decode(inp_de, sentinels, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58f44a-5eb6-48b7-ae68-1cd8a1bf2d76",
   "metadata": {},
   "source": [
    "# **Load a pretrained model**\n",
    "\n",
    "To show how powerful this model actually is, we trained it for several epochs with the full dataset in Colab and saved the weights for you. You can load them using the cell below. For the rest of the notebook, you will see the power of the transfer learning in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bafed080-0a11-46c3-864e-367d25fd5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = torch.load('pretrained transformer (encoder-decoder) 10000 seqs 30 epoch.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1b88c-02d4-4021-908f-23ae26a32715",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. Fine tune the T5 model for Question Answering\n",
    "\n",
    "Now,  you are going to fine tune the pretrained model for Question Answering using the [SQUad 2.0 dataset](https://rajpurkar.github.io/SQuAD-explorer/).\n",
    "\n",
    "SQuAD, short for Stanford Question Answering Dataset, is a dataset designed for training and evaluating question answering systems. It consists of real questions posed by humans on a set of Wikipedia articles, where the answer to each question is a specific span of text within the corresponding article.\n",
    "\n",
    "SQuAD 1.1, the previous version of the SQuAD dataset, contains 100,000+ question-answer pairs on about 500 articles.\n",
    "SQuAD 2.0, contains 50.000 additional questions that are not meant to be answered. This extra set of questions can help to train models to detect unanswerable questions.\n",
    "\n",
    "Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2152c67e-fdb8-4f33-aede-c3995427cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 442\n"
     ]
    }
   ],
   "source": [
    "with open('data/train-v2.0.json', 'r') as f:\n",
    "    example_jsons = json.load(f)\n",
    "\n",
    "example_jsons = example_jsons['data']\n",
    "\n",
    "print('Number of articles: ' + str(len(example_jsons)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab014b6a-af34-4fec-81a4-19b78f691968",
   "metadata": {},
   "source": [
    "The structure of each article is as follows:\n",
    "- `title`: The article title\n",
    "- `paragraphs`: A list of paragraphs and questions related to them\n",
    "    - `context`: The actual paragraph text\n",
    "    - `qas`: A set of question related to the paragraph\n",
    "        - `question`: A question\n",
    "        - `id`: The question unique identifier\n",
    "        - `is_imposible`: Boolean, specifies if the question can be answered or not\n",
    "        - `answers`: A set of possible answers for the question\n",
    "            - `text`: The answer\n",
    "            - `answer_start`: The index of the character that starts the sentence containing the explicit answer to the question\n",
    "            \n",
    "Take a look at an article by running the next cell. Notice that the `context` is usually the last element for every paragraph:           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c95fc41-3574-4787-8795-358d7177bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Beyoncé\n",
      "{'qas': [{'question': 'When did Beyonce start becoming popular?', 'id': '56be85543aeaaa14008c9063', 'answers': [{'text': 'in the late 1990s', 'answer_start': 269}], 'is_impossible': False}, {'question': 'What areas did Beyonce compete in when she was growing up?', 'id': '56be85543aeaaa14008c9065', 'answers': [{'text': 'singing and dancing', 'answer_start': 207}], 'is_impossible': False}, {'question': \"When did Beyonce leave Destiny's Child and become a solo singer?\", 'id': '56be85543aeaaa14008c9066', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'In what city and state did Beyonce  grow up? ', 'id': '56bf6b0f3aeaaa14008c9601', 'answers': [{'text': 'Houston, Texas', 'answer_start': 166}], 'is_impossible': False}, {'question': 'In which decade did Beyonce become famous?', 'id': '56bf6b0f3aeaaa14008c9602', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': 'In what R&B group was she the lead singer?', 'id': '56bf6b0f3aeaaa14008c9603', 'answers': [{'text': \"Destiny's Child\", 'answer_start': 320}], 'is_impossible': False}, {'question': 'What album made her a worldwide known artist?', 'id': '56bf6b0f3aeaaa14008c9604', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': \"Who managed the Destiny's Child group?\", 'id': '56bf6b0f3aeaaa14008c9605', 'answers': [{'text': 'Mathew Knowles', 'answer_start': 360}], 'is_impossible': False}, {'question': 'When did Beyoncé rise to fame?', 'id': '56d43c5f2ccc5a1400d830a9', 'answers': [{'text': 'late 1990s', 'answer_start': 276}], 'is_impossible': False}, {'question': \"What role did Beyoncé have in Destiny's Child?\", 'id': '56d43c5f2ccc5a1400d830aa', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': 'What was the first album Beyoncé released as a solo artist?', 'id': '56d43c5f2ccc5a1400d830ab', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}, {'question': 'When did Beyoncé release Dangerously in Love?', 'id': '56d43c5f2ccc5a1400d830ac', 'answers': [{'text': '2003', 'answer_start': 526}], 'is_impossible': False}, {'question': 'How many Grammy awards did Beyoncé win for her first solo album?', 'id': '56d43c5f2ccc5a1400d830ad', 'answers': [{'text': 'five', 'answer_start': 590}], 'is_impossible': False}, {'question': \"What was Beyoncé's role in Destiny's Child?\", 'id': '56d43ce42ccc5a1400d830b4', 'answers': [{'text': 'lead singer', 'answer_start': 290}], 'is_impossible': False}, {'question': \"What was the name of Beyoncé's first solo album?\", 'id': '56d43ce42ccc5a1400d830b5', 'answers': [{'text': 'Dangerously in Love', 'answer_start': 505}], 'is_impossible': False}], 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".'}\n"
     ]
    }
   ],
   "source": [
    "example_article = example_jsons[0]\n",
    "example_article\n",
    "\n",
    "print(\"Title: \" + example_article[\"title\"])\n",
    "print(example_article[\"paragraphs\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f99d8-b526-4ded-921f-79eaec0d8e44",
   "metadata": {},
   "source": [
    "The previous article might be difficult to navigate so here is a nicely formatted example paragraph:\n",
    "```python\n",
    "{\n",
    "  \"context\": \"Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles 'Crazy in Love' and 'Baby Boy'\",\n",
    "  \"qas\": [\n",
    "    {\n",
    "      \"question\": \"When did Beyonce start becoming popular?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9063\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"in the late 1990s\",\n",
    "          \"answer_start\": 269\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    {\n",
    "      \"question\": \"What areas did Beyonce compete in when she was growing up?\",\n",
    "      \"id\": \"56be85543aeaaa14008c9065\",\n",
    "      \"answers\": [\n",
    "        {\n",
    "          \"text\": \"singing and dancing\",\n",
    "          \"answer_start\": 207\n",
    "        }\n",
    "      ],\n",
    "      \"is_impossible\": false\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9dd952-60a8-4f12-9328-ed10e2a7aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: parse_squad\n",
    "def parse_squad(dataset):\n",
    "    \"\"\"Extract all the answers/questions pairs from the SQuAD dataset\n",
    "\n",
    "    Args:\n",
    "        dataset (dict): The imported JSON dataset\n",
    "\n",
    "    Returns:\n",
    "        inputs, targets: Two lists containing the inputs and the targets for the QA model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Loop over all the articles\n",
    "    for article in dataset:\n",
    "        \n",
    "        # Loop over each paragraph of each article\n",
    "        for paragraph in article['paragraphs']:\n",
    "            \n",
    "            # Extract context from the paragraph\n",
    "            context = paragraph['context']\n",
    "            \n",
    "            #Loop over each question of the given paragraph\n",
    "            for qa in paragraph['qas']:\n",
    "                \n",
    "                # If this question is not impossible and there is at least one answer\n",
    "                if len(qa['answers']) > 0 and not(qa['is_impossible']):\n",
    "                    \n",
    "                    # Create the question/context sequence\n",
    "                    question_context = 'question: ' + qa['question'] + ' context: ' + context\n",
    "                    \n",
    "                    # Create the answer sequence. Use the text field of the first answer\n",
    "                    answer = 'answer: ' + qa['answers'][0]['text']\n",
    "                    \n",
    "                    # Add the question_context to the inputs list\n",
    "                    inputs.append(question_context)\n",
    "                    \n",
    "                    # Add the answer to the targets list\n",
    "                    targets.append(answer)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ddde263-4b51-4feb-a028-3ab2d98a32b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question/answer pairs: 86821\n",
      "\n",
      "First Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: in the late 1990s\u001b[0m\n",
      "\n",
      "Last Q/A pair:\n",
      "\n",
      "inputs: \u001b[34mquestion: What is KMC an initialism of? context: Kathmandu Metropolitan City (KMC), in order to promote international relations has established an International Relations Secretariat (IRC). KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States. This activity has been further enhanced by establishing formal relationships with 8 other cities: Motsumoto City of Japan, Rochester of the USA, Yangon (formerly Rangoon) of Myanmar, Xi'an of the People's Republic of China, Minsk of Belarus, and Pyongyang of the Democratic Republic of Korea. KMC's constant endeavor is to enhance its interaction with SAARC countries, other International agencies and many other major cities of the world to achieve better urban management and developmental programs for Kathmandu.\u001b[0m\n",
      "\n",
      "targets: \u001b[32manswer: Kathmandu Metropolitan City\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inputs, targets =  parse_squad(example_jsons)          \n",
    "print(\"Number of question/answer pairs: \" + str(len(inputs)))\n",
    "\n",
    "print('\\nFirst Q/A pair:\\n\\ninputs: ' + colored(inputs[0], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[0], 'green'))\n",
    "print('\\nLast Q/A pair:\\n\\ninputs: ' + colored(inputs[-1], 'blue'))\n",
    "print('\\ntargets: ' + colored(targets[-1], 'green'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce986da8-7027-46f0-91ae-62feb9b82e4c",
   "metadata": {},
   "source": [
    "#### **Expected Output:**\n",
    "```\n",
    "Number of question/answer pairs: 86821\n",
    "\n",
    "First Q/A pair:\n",
    "\n",
    "inputs: question: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
    "\n",
    "targets: answer: in the late 1990s\n",
    "\n",
    "Last Q/A pair:\n",
    "\n",
    "inputs: question: What is KMC an initialism of? context: Kathmandu Metropolitan City (KMC), in order to promote international relations has established an International Relations Secretariat (IRC). KMC's first international relationship was established in 1975 with the city of Eugene, Oregon, United States. This activity has been further enhanced by establishing formal relationships with 8 other cities: Motsumoto City of Japan, Rochester of the USA, Yangon (formerly Rangoon) of Myanmar, Xi'an of the People's Republic of China, Minsk of Belarus, and Pyongyang of the Democratic Republic of Korea. KMC's constant endeavor is to enhance its interaction with SAARC countries, other International agencies and many other major cities of the world to achieve better urban management and developmental programs for Kathmandu.\n",
    "\n",
    "targets: answer: Kathmandu Metropolitan City\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6cd04-4910-45a9-b066-01a4db03dd9b",
   "metadata": {},
   "source": [
    "You will use 50000 samples for training and 5000 samples for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cebe06-7b68-46fb-95d5-3c14dab50468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50K pairs for training\n",
    "inputs_train = inputs[0:40000] \n",
    "targets_train = targets[0:40000]  \n",
    "\n",
    "# 5K pairs for testing\n",
    "inputs_test = inputs[40000:45000] \n",
    "targets_test =  targets[40000:45000] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d5315-cef9-489d-b833-6c5d70c278e8",
   "metadata": {},
   "source": [
    "Now, you can create the batch dataset of padded sequences. You will first tokenize the inputs and the targets. Then, using the function `tf.keras.preprocessing.sequence.pad_sequences`, you will ensure that the inputs and the outputs have the required lengths. Remember that the sequences longer than the required size will be truncated and the shorter ones will be padded with `0`. This setup is very similar to the other one used in this and the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b18fa93-6c8d-437e-b5bf-97d7ad9525f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the size of the input and output data so this can run in this environment\n",
    "encoder_maxlen = 150\n",
    "decoder_maxlen = 50\n",
    "\n",
    "inputs_str = [tokenizer.tokenize(s) for s in inputs_train]\n",
    "targets_str = [tf.concat([tokenizer.tokenize(s), [1]], 0) for s in targets_train]\n",
    "\n",
    "inputs  = tf.keras.preprocessing.sequence.pad_sequences(inputs_str,  maxlen=encoder_maxlen, padding='post', truncating='post')\n",
    "targets = tf.keras.preprocessing.sequence.pad_sequences(targets_str, maxlen=decoder_maxlen, padding='post', truncating='post')\n",
    "\n",
    "inputs  = tf.cast(inputs,  dtype=tf.int32)\n",
    "targets = tf.cast(targets, dtype=tf.int32)\n",
    "\n",
    "# Create the final training dataset.\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE  = 64\n",
    "dataset     = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011c071f-9518-4efe-814a-11d46aa735f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 150]), TensorShape([64, 50]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (batch, (inp, tar)) in enumerate(dataset):\n",
    "    if batch >=2:\n",
    "        break\n",
    "inp.shape, tar.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e5019e-7237-4485-8c42-655a73176e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 150), dtype=int32, numpy=\n",
       "array([[  822,    10,    86, ..., 13883, 27668,   120],\n",
       "       [  822,    10,   363, ...,     0,     0,     0],\n",
       "       [  822,    10,  2840, ...,  1888,    13,  6852],\n",
       "       ...,\n",
       "       [  822,    10,   366, ...,     0,     0,     0],\n",
       "       [  822,    10,   363, ...,     0,     0,     0],\n",
       "       [  822,    10,   366, ..., 12663,    12,  5530]])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16c0e24b-1dc2-4e80-ab36-478b93f2bb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150,), dtype=int32, numpy=\n",
       "array([  822,    10,   571,   186,  2417,   724,    54,  1400,    16,\n",
       "         531,    40,   969,  8210,    58,  2625,    10,    37, 13604,\n",
       "          19,     8,   192,    18,  5842,   336,  5640,    13,     8,\n",
       "         774,     6, 27647,    53,    16,     3, 20508,     8,  4668,\n",
       "           5,   242,  9385,    80,     6,   386,   190,  1296,     6,\n",
       "          11, 27137,     6,    34,    47,  6878,    45,     8,   531,\n",
       "          40,   969,  8210,     6,    84,    65,    46,  2417,  2614,\n",
       "          13,  3241,  6180,  5548,     5,    37, 13604,    21,   774,\n",
       "         192,   808,   286,    44,     8, 24723,   736, 11692,   532,\n",
       "           9,   929,     6,    84,    65,    46,  2417,  2614,    13,\n",
       "         147,     3, 14835,     5,    86,  9385,  2391,   190, 27255,\n",
       "           6,     8,  5669,    47,    44,     8, 16887,  8210,     6,\n",
       "          84,  4532,    46,  2417,    13,   147,     3, 18834,     5,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5f41a66-7635-4ceb-ace1-be38e56caf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(150,), dtype=int32, numpy=\n",
       "array([  822,    10,   363,    56,   534, 12927,     7,    13,     8,\n",
       "         467,  3480,    58,  2625,    10,  3608, 12927,     7,    13,\n",
       "           8,   467,  3480,     3,     9,  9091,  7505,   736,    23,\n",
       "          23,   115,    32, 31193,     6,    84, 12502,     7,     3,\n",
       "           9,  2142,    23,   412,    18, 30810,     3,  8646,    15,\n",
       "         106,   718,     8,    96,   254,     9,   162,    13, 18136,\n",
       "           7,   121,    11,    54,  2331,   331,   147,    12,     8,\n",
       "           3,  4685,  1421,  1027,  8804,     9,   467,     5,  2502,\n",
       "        1027,  8804,     9,    18,  3897,   736,    23,    23,   115,\n",
       "          32, 31193,     7,    43,  6746,  3621,    10,  7505,    11,\n",
       "         304,   106,  7505, 30064,     3,  6770,     7,     6,  1027,\n",
       "        8804,     9,    11,   451,    23,   157,  7882,  7505,    31,\n",
       "           7,   533,     6,    11, 17980,   106,  8716,  4110,  7505,\n",
       "          12,   240,  4394,    38,   231,  1783,     5,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4d153b0-3690-4365-917d-05c9957a84f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe2\\x96\\x81question'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_string(822)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "faf68a5c-fea5-49df-8b99-c28274fd8353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'.'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_string(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "312d2ec3-92c8-43f7-8c7a-f260b68d6ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([1525,   10, 6180, 5548,    1,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[5,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb4d3787-d43a-478d-98ec-d8edfeb894f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([1525,   10, 9091, 7505,  736,   23,   23,  115,   32,    1,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar[1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14b8e35a-ca27-4a55-a864-dfed159a3e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe2\\x96\\x81answer'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.id_to_string(1525)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c6faf2-5cf5-46cb-9dda-b8e72ad45984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'question: How many audience members can fit in Dolby Theatre? context: The finale is the two-hour last episode of the season, culminating in revealing the winner. For seasons one, three through six, and fourteen, it was broadcast from the Dolby Theatre, which has an audience capacity of approximately 3,400. The finale for season two took place at the Gibson Amphitheatre, which has an audience capacity of over 6,000. In seasons seven through thirteen, the venue was at the Nokia Theatre, which holds an audience of over 7,000.'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(inp[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf533a85-e208-4fd7-b102-859298a89dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'answer: 3,400'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(tar[5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7fdb6-f3fc-43e8-9221-b59d8f2a6923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6bfc128e-2642-414b-a111-a0baf89a83eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e6f7d7-8097-4939-81c0-4acb133d4a24",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 Fine tune the T5 model\n",
    "\n",
    "Now, you will train the model for 2 epochs. In the T5 model, all the weights are adjusted during the fine tuning. As usual, fine tuning this model to get state of the art results would require more time and resources than there are available in this environment, but you are welcome to train the model for more epochs and with more data using Colab GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "c410fcc8-10e8-43a1-aa5e-1445b3a82816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10]\n",
      "\n",
      "100:  0.5739165577292442\n",
      "\n",
      "\n",
      "200:  0.6171659803390503\n",
      "\n",
      "\n",
      "300:  0.6577478025356929\n",
      "\n",
      "\n",
      "400:  0.6968136766552925\n",
      "\n",
      "\n",
      "500:  0.7353509529829025\n",
      "\n",
      "\n",
      "600:  0.7694324104984601\n",
      "\n",
      "Time taken for one epoch: 138.55948305130005 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green navigation blue orange  red French Light Gothic penny']\n",
      "\n",
      "Epoch [2 / 10]\n",
      "\n",
      "100:  0.5321232953667641\n",
      "\n",
      "\n",
      "200:  0.5716301468014717\n",
      "\n",
      "\n",
      "300:  0.6038602851827939\n",
      "\n",
      "\n",
      "400:  0.6375588937848806\n",
      "\n",
      "\n",
      "500:  0.6651678727269172\n",
      "\n",
      "\n",
      "600:  0.6916743049522242\n",
      "\n",
      "Time taken for one epoch: 129.28625297546387 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green navigation French blue Light red orange yellow Rsbury']\n",
      "\n",
      "Epoch [3 / 10]\n",
      "\n",
      "100:  0.5389246946573257\n",
      "\n",
      "\n",
      "200:  0.5762896163761616\n",
      "\n",
      "\n",
      "300:  0.6035836226741473\n",
      "\n",
      "\n",
      "400:  0.630036330372095\n",
      "\n",
      "\n",
      "500:  0.6598749752044678\n",
      "\n",
      "\n",
      "600:  0.6850455930829048\n",
      "\n",
      "Time taken for one epoch: 129.98971796035767 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green red navigation blue French Indoorbury orange  Lewis']\n",
      "\n",
      "Epoch [4 / 10]\n",
      "\n",
      "100:  0.5332111844420433\n",
      "\n",
      "\n",
      "200:  0.5637677526473999\n",
      "\n",
      "\n",
      "300:  0.589761394560337\n",
      "\n",
      "\n",
      "400:  0.6184226699918508\n",
      "\n",
      "\n",
      "500:  0.6459910286068916\n",
      "\n",
      "\n",
      "600:  0.6707450745006402\n",
      "\n",
      "Time taken for one epoch: 130.723614692688 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'navigation green red French  blue Rs yellow pink orange']\n",
      "\n",
      "Epoch [5 / 10]\n",
      "\n",
      "100:  0.5333572831749916\n",
      "\n",
      "\n",
      "200:  0.5644902610778808\n",
      "\n",
      "\n",
      "300:  0.590357630054156\n",
      "\n",
      "\n",
      "400:  0.6163769295811653\n",
      "\n",
      "\n",
      "500:  0.6392636594772338\n",
      "\n",
      "\n",
      "600:  0.6628609360257784\n",
      "\n",
      "Time taken for one epoch: 130.86468887329102 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green blue navigation red French  orange we one Long']\n",
      "\n",
      "Epoch [6 / 10]\n",
      "\n",
      "100:  0.5216983553767204\n",
      "\n",
      "\n",
      "200:  0.5497780655324459\n",
      "\n",
      "\n",
      "300:  0.5766258706649144\n",
      "\n",
      "\n",
      "400:  0.6011684910953045\n",
      "\n",
      "\n",
      "500:  0.625688578248024\n",
      "\n",
      "\n",
      "600:  0.6498789436618487\n",
      "\n",
      "Time taken for one epoch: 130.57996940612793 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'blue green French red  Light orange pink darker one']\n",
      "\n",
      "Epoch [7 / 10]\n",
      "\n",
      "100:  0.5225130686163902\n",
      "\n",
      "\n",
      "200:  0.5465202225744724\n",
      "\n",
      "\n",
      "300:  0.5688190663854281\n",
      "\n",
      "\n",
      "400:  0.59637176848948\n",
      "\n",
      "\n",
      "500:  0.6195908132195472\n",
      "\n",
      "\n",
      "600:  0.6403320262332758\n",
      "\n",
      "Time taken for one epoch: 129.9414689540863 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green navigation French  blue pink redriol the recall']\n",
      "\n",
      "Epoch [8 / 10]\n",
      "\n",
      "100:  0.5180293866991996\n",
      "\n",
      "\n",
      "200:  0.5427566197514534\n",
      "\n",
      "\n",
      "300:  0.5653084441026052\n",
      "\n",
      "\n",
      "400:  0.5894992123544216\n",
      "\n",
      "\n",
      "500:  0.612182224035263\n",
      "\n",
      "\n",
      "600:  0.6351467875639597\n",
      "\n",
      "Time taken for one epoch: 132.81854581832886 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'blue navigation orange green red we nier Indoor mechanic']\n",
      "\n",
      "Epoch [9 / 10]\n",
      "\n",
      "100:  0.4959970164299011\n",
      "\n",
      "\n",
      "200:  0.5298829558491707\n",
      "\n",
      "\n",
      "300:  0.5527617879708608\n",
      "\n",
      "\n",
      "400:  0.5781840260326863\n",
      "\n",
      "\n",
      "500:  0.6044169459342956\n",
      "\n",
      "\n",
      "600:  0.6254777737955253\n",
      "\n",
      "Time taken for one epoch: 149.20573902130127 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'red navigation blue green our Long orange pink  Indoor']\n",
      "\n",
      "Epoch [10 / 10]\n",
      "\n",
      "100:  0.48836630523204805\n",
      "\n",
      "\n",
      "200:  0.5224683085083961\n",
      "\n",
      "\n",
      "300:  0.5471724184354146\n",
      "\n",
      "\n",
      "400:  0.571343797147274\n",
      "\n",
      "\n",
      "500:  0.5951041791439057\n",
      "\n",
      "\n",
      "600:  0.6171060379346212\n",
      "\n",
      "Time taken for one epoch: 146.75741624832153 sec\n",
      "question: What color is the sky? context: Sky is blue\n",
      "possible answers:  [b'green navigation blue red orange  pink white French Long']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformer.to(device)\n",
    "\n",
    "# test_example  = 0\n",
    "# true_summary  = summary_test[test_example]\n",
    "# true_document = document_test[test_example]\n",
    "\n",
    "\n",
    "# Training Hyperparameters\n",
    "num_epochs    = 10 #20\n",
    "learning_rate = 0.001\n",
    "batch_size    = 64\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "pad_idx    = 0\n",
    "criterion  = nn.NLLLoss(ignore_index=pad_idx)\n",
    "optimizer  = optim.AdamW(transformer.parameters())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch [{epoch+1} / {num_epochs}]')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    running_loss = 0\n",
    "    transformer.train()\n",
    "    for (batch, (inp, tar)) in enumerate(dataset):\n",
    "\n",
    "        inp1 = torch.tensor(inp.numpy()).long().clone().to(device)\n",
    "        tar1 = torch.tensor(tar.numpy()).long().clone().to(device)\n",
    "\n",
    "        # print('inp_data1: ', inp_data1.shape)\n",
    "        # print('target1: ',   target1.shape)\n",
    "\n",
    "        preds, _ = transformer(inp1, tar1[:, :-1])\n",
    "\n",
    "        # Ensure outputs is of type Float\n",
    "        outputs = preds.float().clone()\n",
    "        outputs = outputs.reshape(-1, preds.shape[2])\n",
    "        # print('outputs: ', outputs.shape)\n",
    "        \n",
    "        # Ensure targets is of type Long\n",
    "        targets = tar1[:, 1:].long().clone()\n",
    "        targets = targets.reshape(-1)\n",
    "        # print('targets: ', targets.shape)\n",
    "\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        running_loss     = running_loss+loss.item()\n",
    "        avg_running_loss = running_loss/(batch+1)\n",
    "\n",
    "        if (batch+1)%100 == 0:\n",
    "            print()\n",
    "            print(f'{batch+1}: ', avg_running_loss)\n",
    "            print()\n",
    "        \n",
    "        if (batch+1) >= len(dataset):\n",
    "            break\n",
    "    \n",
    "    print (f'Time taken for one epoch: {time.time() - start} sec')\n",
    "\n",
    "    transformer.eval()\n",
    "    eval_preds, _   = transformer(eval_inp, eval_tar_inp)\n",
    "    # Get top 10 indices and values\n",
    "    _, topk_indices = torch.topk(eval_preds[:,-1,:], k=10, dim=-1)\n",
    "        \n",
    "    topk_indices = topk_indices.to(torch.int32).to('cpu').clone()\n",
    "    topk_indices = topk_indices.numpy()\n",
    "    # topk_indices\n",
    "    topk_indices =  tokenizer.detokenize(topk_indices)\n",
    "\n",
    "    \n",
    "    print(example_question)\n",
    "    print('possible answers: ', topk_indices.numpy())\n",
    "    print()\n",
    "    torch.save(transformer, f\"{90+1+batch} pretrained-finetuned-QA transformer (encoder-decoder) 40000 seqs 10 epochs.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "ce770648-ac31-4b03-a79f-56f674b45e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer, \"pretrained-finetuned-QA transformer (encoder-decoder) 40000 seqs 10 epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5d8b2-c6f6-451f-ba8a-23b5256898c5",
   "metadata": {},
   "source": [
    "To get a model that works properly, you would need to train for about 100 epochs. So, we have pretrained a model for you. Just load the weights in the current model and let's use it for answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b187e2-6994-432f-91b5-bbbdc4cbf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restore the weights\n",
    "transformer = torch.load(\"best pretrained-finetuned-QA transformer (encoder-decoder) 40000 seqs 100 epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fde7d1-5524-4afb-8232-f542045c6e1c",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Implement your Question Answering model\n",
    "In this final step, you will implement the answer_question function, utilizing a pre-trained transformer model for question answering.\n",
    "\n",
    "To help you out the `transformer_utils.next_word` function is provided. This function receives the question and beginning of the answer (both in tensor format) alongside the model to predict the next token in the answer. The next cell shows how to use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ad0d747-5d16-4c17-96a7-284ce7de70df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an example question\n",
    "example_question = \"question: What color is the sky? context: Sky is blue\"\n",
    "# example_question = \"question: What is the color of his shirt? context: His boots are red. His pants are orange. His shirt is pink. His hair are yellow\"\n",
    "# example_question = \"question: Where is he sitting? context: He is sitting on a chair\"\n",
    "\n",
    "# example_question = \"question: When did Beyonce start becoming popular? context: Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles Crazy in Love and Baby Boy\"\n",
    "example_question = \"question: What color is the sky? context: Sky is blue answer: blue question What color is his shirt? context: His shirt is yellow answer: yellow question: what color is his bike? context: His bike is red answer: \"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fee9c18-c198-4a56-bef6-697e77406003",
   "metadata": {},
   "outputs": [],
   "source": [
    "list  = [example_question]\n",
    "ans   = 'answer: '\n",
    "ans_l = [ans]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00ebf122-aa1c-48d2-8094-a8fab6ac57a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 822,   10,  363,  945,   19,    8, 5796,   58, 2625,   10, 5643,   19,\n",
       "          1692, 1525,   10, 1692,  822,  363,  945,   19,  112, 8677,   58, 2625,\n",
       "            10,  978, 8677,   19, 4459, 1525,   10, 4459,  822,   10,  125,  945,\n",
       "            19,  112, 3724,   58, 2625,   10,  978, 3724,   19, 1131, 1525,   10]],\n",
       "        device='cuda:0', dtype=torch.int32),\n",
       " torch.Size([1, 48]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_inp = torch.tensor( tokenizer.tokenize(list).to_tensor().numpy(), dtype=torch.int32).to(device)\n",
    "eval_inp, eval_inp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a356677a-1b4c-4b0c-8829-947bfdb0227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_tar_inp = torch.tensor( tokenizer.tokenize(ans_l).to_tensor().numpy(), dtype=torch.int32 ).to(device)\n",
    "eval_tar_inp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d10fa5f-9880-420d-ac90-bf7ff0ac3f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "preds, _ = transformer(eval_inp, eval_tar_inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec27b0d7-3016-4402-b77c-3b43cf592c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'green orange white light  Laura yellow blue red given A un Light screen similar T darker natural Com the isfic Gal IPpper Test F we maark weak Usetic color Lord chemical elegant Stanley Can launch Hi Lewis considered Frenchshi stage ancient wheel Du will de bin black horse lead noble twotar Za simpleAIDS 13 no mo Tibetan State penny alegi Mac one hadity outputor mast recall beer Derby bulblig Universal Tall Gothic13 Nicholas Sche hiszel J weight battery frequency silver verticalual density industrial growth']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get top 10 indices and values\n",
    "topk_values, topk_indices = torch.topk(preds[:,-1,:], k=100, dim=-1)\n",
    "\n",
    "\n",
    "topk_indices = topk_indices.to(torch.int32).to('cpu').clone()\n",
    "\n",
    "topk_indices = topk_indices.numpy()\n",
    "\n",
    "# topk_indices\n",
    "topk_indices =  tokenizer.detokenize(topk_indices)\n",
    "\n",
    "print(topk_indices.numpy())\n",
    "\n",
    "\n",
    "# print(example_question)\n",
    "# print('ans: ', inp_de.numpy().decode('utf-8'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ae7f254-7828-4993-a8b6-9582152ecda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -0.0813,  -2.7179,  -5.6275,  -6.4738,  -6.6124,  -6.8272,  -6.9897,\n",
       "          -7.1885,  -7.2125,  -8.2757,  -8.5670,  -8.6899,  -9.0615,  -9.0740,\n",
       "          -9.0888,  -9.3679,  -9.4953,  -9.6246,  -9.6907,  -9.7247,  -9.7611,\n",
       "         -10.0464, -10.1812, -10.1812, -10.2328, -10.4417, -10.6004, -10.8265,\n",
       "         -10.8823, -10.9613, -10.9624, -11.0092, -11.0180, -11.0255, -11.0472,\n",
       "         -11.1022, -11.2539, -11.2852, -11.2997, -11.3050, -11.3092, -11.4974,\n",
       "         -11.5023, -11.5213, -11.5324, -11.5428, -11.7049, -11.8381, -11.9445,\n",
       "         -11.9921, -12.0436, -12.0628, -12.0748, -12.1048, -12.2280, -12.2547,\n",
       "         -12.2842, -12.3096, -12.3120, -12.3284, -12.3333, -12.3620, -12.3821,\n",
       "         -12.3840, -12.4263, -12.4953, -12.5118, -12.5983, -12.5990, -12.6279,\n",
       "         -12.6814, -12.7099, -12.7760, -12.7765, -12.7945, -12.8074, -12.8269,\n",
       "         -12.8546, -12.8660, -12.8794, -12.9298, -12.9732, -12.9931, -13.0472,\n",
       "         -13.0588, -13.0716, -13.1669, -13.1907, -13.2110, -13.2467, -13.2719,\n",
       "         -13.2772, -13.3081, -13.3104, -13.3221, -13.3247, -13.3451, -13.3933,\n",
       "         -13.4846, -13.5146]], device='cuda:0', grad_fn=<TopkBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ef065-561a-4303-9f56-d6198b3b9ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
