{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d4b8c52-1a56-4415-8031-d76d319f373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # suggestuions for performance enhanceent:\n",
    "# use their data generator\n",
    "# fine tune threshold or alpha margin on evaluation\n",
    "# further fine tune the remaining parameter on the test data\n",
    "# then tets on your own snetences,\n",
    "# maybe add more layers of differenr types,\n",
    "# maybe improve the test function by using distances squared (i am not sure if it'll work, but late's see)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8aa3b6",
   "metadata": {
    "colab_type": "text",
    "id": "-Jv7Y4hXwt0j"
   },
   "source": [
    "# Assignment 4:  Question duplicates\n",
    "\n",
    "Welcome to the fourth assignment of course 3. In this assignment you will explore Siamese networks applied to natural language processing. You will further explore the fundamentals of pytorch and you will be able to implement a more complicated structure using it. By completing this assignment, you will learn how to implement models with different architectures. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd8094f",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Overview](#0)\n",
    "- [1 - Importing the Data](#1)\n",
    "    - [1.1 - Loading in the Data](#1-1)\n",
    "    - [1.2 - Converting a Question to a Tensor](#1-2)\n",
    "    - [1.3 - Understanding the Iterator](#1-3)\n",
    "        - [Exercise 1 - data_generator (UNQ_C1)](#ex-1)\n",
    "- [2 - Defining the Siamese Model](#2)\n",
    "    - [2.1 - Understanding Siamese Network](#2-1)\n",
    "        - [Exercise 2 - Siamese (UNQ_C2)](#ex-2)\n",
    "    - [2.2 - Hard Negative Mining](#2-2)\n",
    "        - [Exercise 3 - TripletLossFn (UNQ_C3)](#ex-3)\n",
    "- [3 - Training](#3)\n",
    "    - [3.1 - Training the Model](#3-1)\n",
    "        - [Exercise 4 - train_model (UNQ_C4)](#ex-4)\n",
    "- [4 - Evaluation](#4)\n",
    "    - [4.1 - Evaluating your Siamese Network](#4-1)\n",
    "    - [4.2 - Classify](#4-2)\n",
    "        - [Exercise 5 - classify (UNQ_C5)](#ex-5)\n",
    "- [5 -Testing with your Own Questions](#5)\n",
    "    - [Exercise 6 - predict (UNQ_C6)](#ex-6)\n",
    "- [On Siamese Networks](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58bde56",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Overview\n",
    "In this assignment, concretely you will: \n",
    "\n",
    "- Learn about Siamese networks\n",
    "- Understand how the triplet loss works\n",
    "- Understand how to evaluate accuracy\n",
    "- Use cosine similarity between the model's outputted vectors\n",
    "- Use the data generator to get batches of questions\n",
    "- Predict using your own model\n",
    "\n",
    "By now, you are familiar with pytorch and know how to make use of classes to define your model. We will start this homework by asking you to preprocess the data the same way you did in the previous assignments. After processing the data you will build a classifier that will allow you to identify whether two questions are the same or not. \n",
    "<img src = \"images/meme.png\" style=\"width:550px;height:300px;\"/>\n",
    "\n",
    "\n",
    "You will process the data first and then pad in a similar way you have done in the previous assignment. Your model will take in the two question embeddings, run them through an LSTM, and then compare the outputs of the two sub networks using cosine similarity. Before taking a deep dive into the model, start by importing the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b92fe",
   "metadata": {
    "colab_type": "text",
    "id": "4sF9Hqzgwt0l"
   },
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Importing the Data\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Loading in the Data\n",
    "\n",
    "You will be using the Quora question answer dataset to build a model that could identify similar questions. This is a useful task because you don't want to have several versions of the same question posted. Several times when teaching I end up responding to similar questions on piazza, or on other community forums. This data set has been labeled for you. Run the cell below to import some of the packages you will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915d5159",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zdACgs491cs2",
    "outputId": "b31042ef-845b-46b8-c783-185e96b135f7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# set nltk path\n",
    "nltk.data.path.append('/nltk_data')\n",
    "\n",
    "# set random seeds\n",
    "rnd.seed(34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b94e2",
   "metadata": {
    "colab_type": "text",
    "id": "3GYhQRMspitx"
   },
   "source": [
    "You will now load in the data set. We have done some preprocessing for you. If you have taken the deeplearning specialization, this is a slightly different training method than the one you have seen there. If you have not, then don't worry about it, we will explain everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42473dfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "id": "sXWBVGWnpity",
    "outputId": "afa90d4d-fed7-43b8-bcba-48c95d600ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question pairs:  404351\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/questions.csv\")\n",
    "N    = len(data)\n",
    "\n",
    "print('Number of question pairs: ', N)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f0cd94",
   "metadata": {
    "colab_type": "text",
    "id": "gkSQTu7Ypit0"
   },
   "source": [
    "We first split the data into a train and test set. The test set will be used later to evaluate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa0c5036",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z00A7vEMpit1",
    "outputId": "c12ae7e8-a959-4f56-aa29-6ad34abc1c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 300000 Test set: 10240\n"
     ]
    }
   ],
   "source": [
    "N_train = 300000\n",
    "N_test  = 10*1024\n",
    "\n",
    "data_train = data[:N_train]\n",
    "data_test  = data[N_train:N_train+N_test]\n",
    "\n",
    "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n",
    "del(data) # remove to free memory ##############################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ef8eaf",
   "metadata": {
    "colab_type": "text",
    "id": "FbqIRRyEpit4"
   },
   "source": [
    "As explained in the lectures, we select only the question pairs that are duplicate to train the model. <br>\n",
    "We build two batches as input for the Siamese network and we assume that question $q1_i$ (question $i$ in the first batch) is a duplicate of $q2_i$ (question $i$ in the second batch), but all other questions in the second batch are not duplicates of $q1_i$.  \n",
    "The test set uses the original pairs of questions and the status describing if the questions are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b556be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Xi_TwXxxpit4",
    "outputId": "f146046f-9c0d-4d8a-ecf8-8d6a4a5371f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of duplicate questions:  111486\n",
      "indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
     ]
    }
   ],
   "source": [
    "td_index = (data_train['is_duplicate'] == 1).to_numpy()         #####################\n",
    "td_index = [i for i, x in enumerate(td_index) if x]   # if x is True then return the corresponding i-enumerate-integer-id\n",
    "\n",
    "print('number of duplicate questions: ', len(td_index))\n",
    "print('indexes of first ten duplicate questions:', td_index[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8f7003b9-b236-4bb5-97f7-3ccd3613831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "fb0a396e-c96a-47be-9cac-4f6391e42c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5     True\n",
       "6    False\n",
       "Name: is_duplicate, dtype: bool"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['is_duplicate'][:7] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "e8a3e949-5a54-4077-b56a-cfba9e54c70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_train['is_duplicate'][:7] == 1).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "c17d47b6-b6ef-4de0-8274-ead28e643113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((data_train['is_duplicate'][:7] == 1).to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "70fdc648-6154-48d4-b157-34e7e90efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d91f83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3I9oXSsKpit7",
    "outputId": "6f6bd3a1-219f-4fb3-a524-450c38bf44ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
      "is_duplicate:  1\n"
     ]
    }
   ],
   "source": [
    "print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\n",
    "print(data_train['question2'][5])\n",
    "print('is_duplicate: ', data_train['is_duplicate'][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7a9700",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHpZO58Dss_v"
   },
   "outputs": [],
   "source": [
    "Q1_train_words = np.array(data_train['question1'][td_index])\n",
    "Q2_train_words = np.array(data_train['question2'][td_index])\n",
    "\n",
    "Q1_test_words = np.array(data_test['question1'])\n",
    "Q2_test_words = np.array(data_test['question2'])\n",
    "y_test        = np.array(data_test['is_duplicate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef144a",
   "metadata": {
    "colab_type": "text",
    "id": "P5vBkxunpiuB"
   },
   "source": [
    "Above, you have seen that you only took the duplicated questions for training our model. <br>You did so on purpose, because the data generator will produce batches $([q1_1, q1_2, q1_3, ...]$, $[q2_1, q2_2,q2_3, ...])$  where $q1_i$ and $q2_k$ are duplicate if and only if $i = k$.\n",
    "\n",
    "<br>Let's print to see what your data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "724e90b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "joyrS1XEpLWn",
    "outputId": "3257cde7-3164-40d9-910e-fa91eae917a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING QUESTIONS:\n",
      "\n",
      "Question 1:  Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
      "Question 2:  I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me? \n",
      "\n",
      "Question 1:  What would a Trump presidency mean for current international master’s students on an F1 visa?\n",
      "Question 2:  How will a Trump presidency affect the students presently in US or planning to study in US? \n",
      "\n",
      "TESTING QUESTIONS:\n",
      "\n",
      "Question 1:  How do I prepare for interviews for cse?\n",
      "Question 2:  What is the best way to prepare for cse? \n",
      "\n",
      "is_duplicate = 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_train_words[0])\n",
    "print('Question 2: ', Q2_train_words[0], '\\n')\n",
    "print('Question 1: ', Q1_train_words[5])\n",
    "print('Question 2: ', Q2_train_words[5], '\\n')\n",
    "\n",
    "print('TESTING QUESTIONS:\\n')\n",
    "print('Question 1: ', Q1_test_words[0])\n",
    "print('Question 2: ', Q2_test_words[0], '\\n')\n",
    "print('is_duplicate =', y_test[0], '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7001f374",
   "metadata": {
    "colab_type": "text",
    "id": "WC_BZU3XpiuF"
   },
   "source": [
    "You will now encode each word of the selected duplicate pairs with an index. <br> Given a question, you can then just encode it as a list of numbers.  \n",
    "\n",
    "First you tokenize the questions using `nltk.word_tokenize`. <br>\n",
    "You need a python default dictionary which later, during inference, assigns the values $0$ to all Out Of Vocabulary (OOV) words.<br>\n",
    "Then you encode each word of the selected duplicate pairs with an index. Given a question, you can then just encode it as a list of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a6912e-94ca-4590-9e42-45bf87a29f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0646ecae-ade4-428e-84a5-be1cb66cb1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?',\n",
       "       'How can I be a good geologist?',\n",
       "       'How do I read and find my YouTube comments?', ...,\n",
       "       'What are the top 10 TV series one should genuinely watch?',\n",
       "       'Is there no life on other planets?',\n",
       "       'How do I tell the difference between infatuation and love?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_train_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "500992f0-916f-46fa-ba63-1c60de3c9c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111486,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_train_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d447a61e-c3c9-46a6-b02c-d1b904a8e29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Q1_train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "946e51e7-c5f9-4570-9b0d-24d69da6470a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hello world!', 'How are you!'], dtype='<U12')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"Hello world!\"\n",
    "b = 'How are you!'\n",
    "c = [a,b]\n",
    "d = np.array(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cf90f63-f1c6-4665-a580-3cbf02dc38ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', ''], dtype='<U12')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = np.empty_like(d)\n",
    "e # like d's structure, e is an empty array, also the dtypes are also same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998a09cc-39e4-48d3-8aa7-435aa1df29d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Q1_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mQ1_train\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Q1_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Q1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "7b890355-ce4f-405a-9761-ec2fb7aa736a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "828ae4aa",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbCoIgLQpiuF"
   },
   "outputs": [],
   "source": [
    "#create arrays\n",
    "# 4aron sets of sentences k corresponding structures and dtypes k hisaab say 4 empty arrays initialize kr deen \n",
    "\n",
    "Q1_train = np.empty_like(Q1_train_words)\n",
    "Q2_train = np.empty_like(Q2_train_words)\n",
    "\n",
    "Q1_test = np.empty_like(Q1_test_words)\n",
    "Q2_test = np.empty_like(Q2_test_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5772852b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "m9ZmfpGWpiuI",
    "outputId": "d2995c9a-92b4-4892-d34b-c77b94b27134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vocabulary is:  36268\n"
     ]
    }
   ],
   "source": [
    "# Building the vocabulary with the train set         (this might take a minute)\n",
    "from collections import defaultdict            # agar is dict ko koi aesi key pass kro gay, jo is k andar mojood nahi hay tu ye 0 return kray gi\n",
    "\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "for idx in range(len(Q1_train_words)):\n",
    "    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])          # ye vo jo empty arrays theen on ki fill krna start kia\n",
    "    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n",
    "    \n",
    "    q = Q1_train[idx] + Q2_train[idx]\n",
    "    \n",
    "    for word in q:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('The length of the vocabulary is: ', len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "3340a32e-496d-4848-8b40-318158ff28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e752ec82-650b-4969-9708-fc59dba9f612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111486,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b93e2e92-95b1-4a19-8604-c5e7edd6ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?']\n"
     ]
    }
   ],
   "source": [
    "print(Q1_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fb87128-5286-47bb-bbe8-c8da01e64c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1_train aik 1d array hi hay, but ....\n",
    "# so, nltk.word_tokenize(Q1_train_words[idx]), nay aik list return ki, or Q1_train k elements ye lists hain...\n",
    "# 1d array of lists-of-words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c70901d-bf35-4552-ba4e-cf1571e11289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Astrology', ':', 'I', 'am', 'a', 'Capricorn', 'Sun', 'Cap', 'moon', 'and', 'cap', 'rising', '...', 'what', 'does', 'that', 'say', 'about', 'me', '?', 'I', \"'m\", 'a', 'triple', 'Capricorn', '(', 'Sun', ',', 'Moon', 'and', 'ascendant', 'in', 'Capricorn', ')', 'What', 'does', 'this', 'say', 'about', 'me', '?']\n"
     ]
    }
   ],
   "source": [
    "print(Q1_train[0]+Q2_train[0])\n",
    "# ye lists concatenate ho gaieen\n",
    "# tu jab, np.arrays k corresponding elements lists hoon, tu vo sum nahi concatenate hotay hain...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf0a6e7-f397-4269-ba2b-ef86fdaa2de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['how r u']\n",
    "# default dict thi, is liye 0 return kia, jab key present nahi thi dict main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "b10331a3-4eb2-4d65-8f7a-56f9f305747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c5f5e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "TTMRF8eZpiuK",
    "outputId": "f81d4dc1-7cf9-4476-a454-467b54fe4dc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(vocab['<PAD>'])\n",
    "print(vocab['Astrology'])\n",
    "print(vocab['Astronomy'])  #not in vocabulary, returns 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "606be79c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sDs36m81g6f"
   },
   "outputs": [],
   "source": [
    "for idx in range(len(Q1_test_words)): \n",
    "    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n",
    "    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63d05b28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3QgGE9KlpiuP",
    "outputId": "19c3cf93-cf0d-4f8f-da99-e75481f16599"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has reduced to:  111486\n",
      "Test set length:  10240\n"
     ]
    }
   ],
   "source": [
    "print('Train set has reduced to: ', len(Q1_train) ) # pehlay bhi yehi length thi...\n",
    "print('Test set length: ', len(Q1_test) ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bacdb5",
   "metadata": {
    "colab_type": "text",
    "id": "BDcxEmX31y3d"
   },
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Converting a Question to a Tensor\n",
    "\n",
    "You will now convert every question to a tensor, or an array of numbers, using your vocabulary built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74c0f579",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOhNa-sapiuS"
   },
   "outputs": [],
   "source": [
    "# Converting questions to array of integers\n",
    "for i in range(len(Q1_train)):                             # outer loop\n",
    "    Q1_train[i] = [vocab[word] for word in Q1_train[i]]    # sub inner loop\n",
    "    Q2_train[i] = [vocab[word] for word in Q2_train[i]]    # serially-parallel-level sub-inner-loop-2\n",
    "                                                           # & so on ...\n",
    "        \n",
    "for i in range(len(Q1_test)):\n",
    "    Q1_test[i] = [vocab[word] for word in Q1_test[i]]      # ab har element par list of words ki bjaye, list of numbers pri hui hay\n",
    "    Q2_test[i] = [vocab[word] for word in Q2_test[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00e41e56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Dpawm38dpiuU",
    "outputId": "ef1aa65b-c89b-46f9-a9cf-f73748f1ee56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first question in the train set:\n",
      "\n",
      "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
      "\n",
      "encoded version:\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21] \n",
      "\n",
      "first question in the test set:\n",
      "\n",
      "How do I prepare for interviews for cse? \n",
      "\n",
      "encoded version:\n",
      "[32, 38, 4, 107, 65, 1015, 65, 11509, 21]\n"
     ]
    }
   ],
   "source": [
    "print('first question in the train set:\\n')\n",
    "print(Q1_train_words[0], '\\n') \n",
    "print('encoded version:')\n",
    "print(Q1_train[0],'\\n')\n",
    "\n",
    "print('first question in the test set:\\n')\n",
    "print(Q1_test_words[0], '\\n')\n",
    "print('encoded version:')\n",
    "print(Q1_test[0]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fa462e",
   "metadata": {
    "colab_type": "text",
    "id": "SuggGPaQpiuY"
   },
   "source": [
    "You will now split your train set into a training/validation set so that you can use it to train and evaluate your Siamese model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "940f9478",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "BmhrWPtgpiuY",
    "outputId": "7272fb74-79e6-499a-ce95-d11b9edcd64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate questions:  111486\n",
      "The length of the training set is:   89188\n",
      "The length of the validation set is:  22298\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data\n",
    "cut_off = int(len(Q1_train)*.8)\n",
    "\n",
    "train_Q1, train_Q2 = Q1_train[:cut_off],   Q2_train[:cut_off]\n",
    "val_Q1,     val_Q2 = Q1_train[cut_off: ],  Q2_train[cut_off:]\n",
    "\n",
    "print('Number of duplicate questions: ', len(Q1_train))\n",
    "print(\"The length of the training set is:  \", len(train_Q1))\n",
    "print(\"The length of the validation set is: \", len(val_Q1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b6a73",
   "metadata": {
    "colab_type": "text",
    "id": "iFOR19cX2TQs"
   },
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Understanding the Iterator \n",
    "\n",
    "Most of the time in Natural Language Processing, and AI in general we use batches when training our data sets. If you were to use stochastic gradient descent with one example at a time, it will take you forever to build a model. In this example, we show you how you can build a data generator that takes in $Q1$ and $Q2$ and returns a batch of size `batch_size`  in the following format $([q1_1, q1_2, q1_3, ...]$, $[q2_1, q2_2,q2_3, ...])$. The tuple consists of two arrays and each array has `batch_size` questions. Again, $q1_i$ and $q2_i$ are duplicates, but they are not duplicates with any other elements in the batch. \n",
    "\n",
    "<br>\n",
    "\n",
    "The command ```next(data_generator)```returns the next batch. This iterator returns the data in a format that you could directly use in your model when computing the feed-forward of your algorithm. This iterator returns a pair of arrays of questions. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - data_generator\n",
    "\n",
    "**Instructions:**  \n",
    "Implement the data generator below. Here are some things you will need. \n",
    "\n",
    "- While true loop.\n",
    "- if `index >= len_Q1`, set the `idx` to $0$.\n",
    "- The generator should return shuffled batches of data. To achieve this without modifying the actual question lists, a list containing the indexes of the questions is created. This list can be shuffled and used to get random batches everytime the index is reset.\n",
    "- Append elements of $Q1$ and $Q2$ to `input1` and `input2` respectively.\n",
    "- if `len(input1) == batch_size`, determine `max_len` as the longest question in `input1` and `input2`. Ceil `max_len` to a power of $2$ (for computation purposes) using the following command:  `max_len = 2**int(np.ceil(np.log2(max_len)))`.\n",
    "- Pad every question by `vocab['<PAD>']` until you get the length `max_len`.\n",
    "- Use yield to return `input1, input2`. \n",
    "- Don't forget to reset `input1, input2`  to empty arrays at the end (data generator resumes from where it last left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "38354450-431f-4eb5-98f7-2745a08bb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d428b437-2996-49be-82eb-db9c9dac58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(train_Q1_, train_Q2_, batch_size_, pad=1):\n",
    "    counter_1 = 0\n",
    "    counter_2 = batch_size_\n",
    "\n",
    "    while True:\n",
    "        batch_of_inputs_1 = []\n",
    "        batch_of_inputs_2 = []\n",
    "        \n",
    "        batch_of_inputs_1 = train_Q1_[counter_1:counter_2].copy()\n",
    "        batch_of_inputs_2 = train_Q2_[counter_1:counter_2].copy()\n",
    "\n",
    "        max_len_in_batch_of_inputs_1 = 0\n",
    "        for current_tensor in batch_of_inputs_1:\n",
    "            if len(current_tensor) > max_len_in_batch_of_inputs_1:\n",
    "                max_len_in_batch_of_inputs_1 = len(current_tensor)\n",
    "\n",
    "        max_len_in_batch_of_inputs_2 = 0\n",
    "        for current_tensor in batch_of_inputs_2:\n",
    "            if len(current_tensor) > max_len_in_batch_of_inputs_2:\n",
    "                max_len_in_batch_of_inputs_2 = len(current_tensor)\n",
    "\n",
    "        for i, current_tensor in enumerate(batch_of_inputs_1):\n",
    "            current_tensor = current_tensor + (max_len_in_batch_of_inputs_1 - len(current_tensor))*[1]\n",
    "            batch_of_inputs_1[i] = np.array(current_tensor)\n",
    "\n",
    "        for i, current_tensor in enumerate(batch_of_inputs_2):\n",
    "            current_tensor = current_tensor + (max_len_in_batch_of_inputs_2 - len(current_tensor))*[1]\n",
    "            batch_of_inputs_2[i] = np.array(current_tensor)\n",
    "\n",
    "        yield np.vstack(batch_of_inputs_1), np.vstack(batch_of_inputs_2)\n",
    "\n",
    "        counter_1+=batch_size_\n",
    "        counter_2+=batch_size_\n",
    "        if counter_2 >= len(train_Q1_):\n",
    "                counter_1 = 0\n",
    "                counter_2 = batch_size_\n",
    "        batch_of_inputs_1 = []\n",
    "        batch_of_inputs_2 = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cce7397f-5976-4fcf-b963-25a022e10415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 2, 3]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*[1] + [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ec07997-3588-421c-bbec-589b8ae27846",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_Q1, train_Q2, 2, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc0fcb43-f3ac-4b2a-9549-88098b81b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21],\n",
       "        [32, 33,  4, 34,  6, 35, 36, 21,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1]]),\n",
       " array([[ 4, 22,  6, 23,  7, 24,  8, 25, 26, 11, 27, 28,  7, 29, 30, 16,\n",
       "         31, 18, 19, 20, 21],\n",
       "        [30, 37,  4, 38, 39, 34,  6, 40, 36, 21,  1,  1,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(train_generator)\n",
    "a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e3adb43-152c-4776-9227-527ece0b1b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 20), (2, 21))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4892fde-0186-4dc0-8847-a9ee510d5a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[32, 38,  4, 41, 11, 42, 43, 44, 45, 21],\n",
       "        [30, 33, 49, 50, 51, 39, 52, 21,  1,  1]]),\n",
       " array([[32, 33,  4, 46, 47, 43, 48, 45, 21],\n",
       "        [32, 33, 53, 49, 54, 51, 39, 52, 21]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(train_generator)\n",
    "a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df25f14a-acf2-4400-9d8d-93689b7993ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 10), (2, 9))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "ce4b0bd5-1207-4cfc-adb1-f4e7b9ded69a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 33, 49, 50, 51, 39, 52, 21]"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Q1[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6283a7-ff49-4cff-b92f-71072ee18e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "4086c1a1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ibchgos48MtA"
   },
   "outputs": [],
   "source": [
    "# # UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# # GRADED FUNCTION: data_generator\n",
    "# def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n",
    "#     \"\"\"Generator function that yields batches of data\n",
    "\n",
    "#     Args:\n",
    "#         Q1 (list): List of transformed (to tensor) questions.\n",
    "#         Q2 (list): List of transformed (to tensor) questions.\n",
    "#         batch_size (int): Number of elements per batch.\n",
    "#         pad (int, optional): Pad character from the vocab. Defaults to 1.\n",
    "#         shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
    "#     Yields:\n",
    "#         tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
    "#         NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
    "#               input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
    "#     \"\"\"\n",
    "\n",
    "#     input1 = []\n",
    "#     input2 = []\n",
    "#     idx = 0\n",
    "#     len_q = len(Q1)\n",
    "#     question_indexes = [*range(len_q)]\n",
    "    \n",
    "#     if shuffle:\n",
    "#         rnd.shuffle(question_indexes)\n",
    "    \n",
    "#     ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "#     while True:\n",
    "#         if idx >= len_q:\n",
    "#             # if idx is greater than or equal to len_q, set idx accordingly \n",
    "#             # (Hint: look at the instructions above)\n",
    "#             idx = 0\n",
    "#             # shuffle to get random batches if shuffle is set to True\n",
    "#             if shuffle:\n",
    "#                 rnd.shuffle(question_indexes) \n",
    "        \n",
    "#         # get questions at the `question_indexes[idx]` position in Q1 and Q2\n",
    "#         q1 = Q1[question_indexes[idx]]\n",
    "#         q2 = Q2[question_indexes[idx]]\n",
    "        \n",
    "#         # increment idx by 1\n",
    "#         idx += 1\n",
    "#         # append q1\n",
    "#         input1.append(q1)\n",
    "#         # append q2\n",
    "#         input2.append(q2)\n",
    "#         if len(input1) == batch_size:\n",
    "#             # determine max_len as the longest question in input1 & input 2\n",
    "#             # Hint: use the `max` function. \n",
    "#             # take max of input1 & input2 and then max out of the two of them.\n",
    "#             max_len = max(max([len(q) for q in input1]), max([len(q) for q in input2]))\n",
    "#             # pad to power-of-2 (Hint: look at the instructions above)\n",
    "#             max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "#             b1 = [] \n",
    "#             b2 = [] \n",
    "#             for q1, q2 in zip(input1, input2):\n",
    "#                 # add [pad] to q1 until it reaches max_len\n",
    "#                 q1 = q1 + [pad] * (max_len - len(q1))\n",
    "#                 # add [pad] to q2 until it reaches max_len\n",
    "#                 q2 = q2 + [pad] * (max_len - len(q2))                \n",
    "#                 # append q1\n",
    "#                 b1.append(q1)\n",
    "#                 # append q2\n",
    "#                 b2.append(q2)\n",
    "#             # use b1 and b2\n",
    "#             yield np.array(b1), np.array(b2)\n",
    "#     ### END CODE HERE ###\n",
    "#             # reset the batches\n",
    "#             input1, input2 = [], []  # reset the batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "f549c272",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ZFZeBPnW8Mlb",
    "outputId": "7a31cd19-55dc-4b97-f288-6c59c6a34b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First questions  :  \n",
      " [[   30    87   669    11   670   131   525    11   418   780   527  1507\n",
      "     21     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]\n",
      " [   30    87   116  3141  6925    65    78  1633  2834   131 24752    65\n",
      "    140   421  1673    71    21     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1]] \n",
      "\n",
      "Second questions :  \n",
      " [[  32   76   78  741   72 4324  525   11  418  534 1261   77  308   21\n",
      "    30   87   78  669   11  670   21    1    1    1    1    1    1    1\n",
      "     1    1    1    1]\n",
      " [  30   87  216  567 6925   65 6488 1633 3229   28  140  421   21    1\n",
      "     1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "     1    1    1    1]]\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 2\n",
    "# res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n",
    "# print(\"First questions  : \",'\\n', res1, '\\n')\n",
    "# print(\"Second questions : \",'\\n', res2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa189f9",
   "metadata": {
    "colab_type": "text",
    "id": "tWJ1L9m2piui"
   },
   "source": [
    "**Note**: The following expected output is valid only if you run the above test cell **_once_** (first time). The output will change on each execution.\n",
    "\n",
    "If you think your implementation is correct and it is not matching the output, make sure to restart the kernel and run all the cells from the top again. \n",
    "\n",
    "**Expected Output:**\n",
    "```CPP\n",
    "First questions  :  \n",
    " [[  30   87   78  134 2132 1981   28   78  594   21    1    1    1    1\n",
    "     1    1]\n",
    " [  30   55   78 3541 1460   28   56  253   21    1    1    1    1    1\n",
    "     1    1]] \n",
    "\n",
    "Second questions :  \n",
    " [[  30  156   78  134 2132 9508   21    1    1    1    1    1    1    1\n",
    "     1    1]\n",
    " [  30  156   78 3541 1460  131   56  253   21    1    1    1    1    1\n",
    "     1    1]]\n",
    "```\n",
    "Now that you have your generator, you can just call it and it will return tensors which correspond to your questions in the Quora data set.<br>Now you can go ahead and start building your neural network. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5229ab4",
   "metadata": {
    "colab_type": "text",
    "id": "KmZRBoaMwt0w"
   },
   "source": [
    "## Defining the Siamese Model\n",
    "\n",
    "\n",
    "### - Understanding Siamese Network \n",
    "A Siamese network is a neural network which uses the same weights while working in tandem on two different input vectors to compute comparable output vectors.The Siamese network you are about to implement looks like this:\n",
    "\n",
    "<img src = \"images/siamese.png\" style=\"width:600px;height:300px;\"/>\n",
    "\n",
    "You get the question embedding, run it through an LSTM layer, normalize $v_1$ and $v_2$, and finally use a triplet loss (explained below) to get the corresponding cosine similarity for each pair of questions. As usual, you will start by importing the data set. The triplet loss makes use of a baseline (anchor) input that is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized. In math equations, you are trying to maximize the following.\n",
    "\n",
    "$$\\mathcal{L}(A, P, N)=\\max \\left(\\|\\mathrm{f}(A)-\\mathrm{f}(P)\\|^{2}-\\|\\mathrm{f}(A)-\\mathrm{f}(N)\\|^{2}+\\alpha, 0\\right)$$\n",
    "\n",
    "$A$ is the anchor input, for example $q1_1$, $P$ the duplicate input, for example, $q2_1$, and $N$ the negative input (the non duplicate question), for example $q2_2$.<br>\n",
    "$\\alpha$ is a margin; you can think about it as a safety net, or by how much you want to push the duplicates from the non duplicates. \n",
    "<br>\n",
    "\n",
    "\n",
    "### Exercise - Siamese\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "32b590ef-90a7-44a3-8637-ed5a59208177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "439e3942-0fcb-493e-92ab-4cd04749588e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41699"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0c7ae192-6935-4fbc-aa59-b72357aa40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f09c3d8-3d94-42ad-86cb-ebfd956448b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_Net(\n",
      "  (embedding): Embedding(41699, 128)\n",
      "  (lstm): LSTM(128, 128, num_layers=3, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size     = len(vocab)\n",
    "embedding_out  = 128\n",
    "n_layers       = 3\n",
    "\n",
    "class LSTM_Net(nn.Module):\n",
    "    def __init__(self, vocab_size_, embedding_out_, n_layers_):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size_, embedding_dim=embedding_out_)\n",
    "        self.lstm      = nn.LSTM(input_size=embedding_out_, hidden_size=embedding_out_, num_layers=n_layers_, batch_first=True)\n",
    "\n",
    "    \n",
    "    def forward(self, x, hidden, memmory_cell):\n",
    "        embedded_output                     = self.embedding(x)\n",
    "        lstm_output, (hidden, memmory_cell) = self.lstm(embedded_output, (hidden, memmory_cell))\n",
    "        \n",
    "        meaned_output                       = lstm_output.mean(dim=1)                  # meaned features for each sequence. mean of corresponding-embedding-features of all words of a sequence \n",
    "        l2_normalized_output                = F.normalize(meaned_output, dim=-1, p=2)  # L2 normalized rows | the L2 norm of each row will be 1\n",
    "        \n",
    "        return l2_normalized_output, hidden, memmory_cell\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LSTM_Net(vocab_size, embedding_out, n_layers).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e2b7c4-4d19-4508-a127-289efc0f510e",
   "metadata": {},
   "source": [
    "# Checking the inputs and ouputs of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "7b6ea23f-8b9b-47ae-98e2-90a0e5e7023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sequences:  torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "vocab_size=len(vocab)\n",
    "torch.manual_seed(0)\n",
    "input_sequences = torch.randint(0, vocab_size, (batch_size, 10))\n",
    "print('input_sequences: ', input_sequences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0c1be1e9-cb28-41b9-b1a7-65f8d0bdff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_out:  torch.Size([256, 10, 128])\n"
     ]
    }
   ],
   "source": [
    "vocab_size     = len(vocab)\n",
    "embedding_out = 128\n",
    "\n",
    "# embedding layer\n",
    "embedding_ = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_out)\n",
    "embed_out_ = embedding_(input_sequences)\n",
    "\n",
    "print('embed_out: ', embed_out_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2e9ecd3e-eb7e-49a8-9df8-21240d262387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([256, 10, 128])\n",
      "hn shape: torch.Size([1, 256, 128])\n",
      "cn shape: torch.Size([1, 256, 128])\n"
     ]
    }
   ],
   "source": [
    "# GRU layer\n",
    "\n",
    "# Defining the LSTM parameters\n",
    "input_size  = embedding_out  # Number of features in the input\n",
    "hidden_size = embedding_out # Number of features in the hidden state\n",
    "n_layers  = 1   # Number of recurrent layers\n",
    "\n",
    "\n",
    "# Create an LSTM layer\n",
    "lstm_ = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "\n",
    "# Optionally, create initial hidden and cell states\n",
    "h0 = torch.zeros(n_layers, batch_size, hidden_size)\n",
    "c0 = torch.zeros(n_layers, batch_size, hidden_size)\n",
    "\n",
    "\n",
    "# Forward pass through the LSTM\n",
    "lstm_out_, (hn, cn) = lstm_(embed_out_, (h0, c0))\n",
    "\n",
    "# Print the shapes of the outputs\n",
    "print(\"Output shape:\", lstm_out_.shape)  # Output shape: (batch_size, seq_len, num_directions * hidden_size)\n",
    "print(\"hn shape:\", hn.shape)          # hn shape: (num_layers * num_directions, batch_size, hidden_size)\n",
    "print(\"cn shape:\", cn.shape)          # cn shape: (num_layers * num_directions, batch_size, hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "50f26f4a-715e-44bb-9ee9-f779e3012601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_out = lstm_out_.mean(dim=1)\n",
    "mean_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8aa32aed-d1cd-4916-b4a8-5434196c00e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_normalized_out = F.normalize(mean_out, dim=-1, p=2)\n",
    "l2_normalized_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "958e4ea2-ea11-495b-8bd2-d8661d2b935d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0535,  0.1342,  0.0963, -0.0487, -0.0115, -0.1075,  0.0891,  0.1616,\n",
       "         0.1008,  0.0173], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_normalized_out[0,:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c11fca6c-8482-4aab-a82e-990c7003d16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm = torch.norm(l2_normalized_out[0,:], p=2)\n",
    "l2_norm\n",
    "\n",
    "# perfect!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e43f6-cd2c-41ff-b786-1fa294f13839",
   "metadata": {},
   "source": [
    "#### Comparing the final-layer-by-layer-output with the model's output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "0e380488-7daf-4760-ab2b-ab772bf863ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0246, -0.0611,  0.1375, -0.0348,  0.0479, -0.0559, -0.0248,  0.1212,\n",
       "         0.0304,  0.0172], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# from model\n",
    "l2_normalized_out_model, _ ,_ = model(input_sequences, h0, c0)\n",
    "l2_normalized_out_model[0,:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "2c057fe6-2fb0-43da-b3c9-8e4f7bc0dca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_normalized_out_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ea763289-0891-4aac-8a18-c1a1759378fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_norm_model = torch.norm(l2_normalized_out_model[0,:], p=2)\n",
    "l2_norm_model\n",
    "\n",
    "# perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098fbde",
   "metadata": {
    "colab_type": "text",
    "id": "KVo1Gvripiuo"
   },
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Hard Negative Mining\n",
    "\n",
    "\n",
    "You will now implement the `TripletLoss`.<br>\n",
    "As explained in the lecture, loss is composed of two terms. One term utilizes the mean of all the non duplicates, the second utilizes the *closest negative*. Our loss expression is then:\n",
    " \n",
    "\\begin{align}\n",
    " \\mathcal{Loss_{1}(A,P,N)} &=\\max \\left( -cos(A,P)  + mean_{neg} +\\alpha, 0\\right) \\\\\n",
    " \\mathcal{Loss_{2}(A,P,N)} &=\\max \\left( -cos(A,P)  + closest_{neg} +\\alpha, 0\\right) \\\\\n",
    "\\mathcal{Loss(A,P,N)} &= mean(Loss_1 + Loss_2) \\\\\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Further, two sets of instructions are provided. The first set provides a brief description of the task. If that set proves insufficient, a more detailed set can be displayed.  \n",
    "\n",
    "### Exercise - TripletLossFn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "d799656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Their input\n",
    "# v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
    "# v2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
    "# print(\"Triplet Loss:\", TripletLossFn(v1,v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255aee40-90a8-42c7-805a-cf9f269907b1",
   "metadata": {},
   "source": [
    "#### Their output\n",
    "Triplet Loss: 0.7035077"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78926cbc",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```CPP\n",
    "Triplet Loss: ~ 0.70\n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bedecb-5037-4c57-806c-7bb7d991fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a0e9ff-d1eb-4c73-8dc0-7236aebde146",
   "metadata": {},
   "source": [
    "##  loss fn in numpy - step by step, see c3w4 nb2 loss fn in numpy explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "ca75e966-237b-4779-9fb6-9f32967c1f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.95350769],\n",
       "       [-0.95350769, -1.        ]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])  # ye already normalized hain\n",
    "v2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
    "\n",
    "sim = np.dot(v1, v2.T)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5c6a187f-9b6a-435e-954c-e5cd7480d88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "b = sim.shape[0]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1bf38cb4-49dd-480b-a5b4-9cd20d9ed2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1.])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ap = np.diag(sim)\n",
    "sim_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7d1984f7-650c-4e7a-8599-fc115755e1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.95350769],\n",
       "       [-0.95350769,  0.        ]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_an = sim - np.diag(sim_ap)\n",
    "sim_an\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ada1c57a-852d-4dbf-a104-0b813aa4771d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95350769],\n",
       "       [-0.95350769]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_neg = np.sum(sim_an, axis=-1, keepdims=True) / (b - 1)\n",
    "mean_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "6909078e-83f4-4df7-9862-9f8a563baf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [False,  True]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_1 = np.identity(b) == 1            # mask to exclude the diagonal\n",
    "mask_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b392c75d-93ef-4bd6-ba4a-18506acf7af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap\n",
    "mask_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "961c8f3c-1131-454d-aae2-945127e8e826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = mask_1 | mask_2\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "df9df966-af59-482b-92e3-b4decfa40c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.        ,  0.95350769],\n",
       "       [-2.        , -2.        ]])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_an_masked = np.copy(sim_an)         # create a copy to preserve sim_an\n",
    "sim_an_masked[mask] = -2\n",
    "sim_an_masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "ddc42581-3359-401a-ba4c-8d17d8caf761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95350769],\n",
       "       [-2.        ]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neg = np.max(sim_an_masked, axis=1, keepdims=True)\n",
    "closest_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "060455d4-debf-4b5b-8296-4295628d7c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20350769],\n",
       "       [0.29649231]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alpha margin\n",
    "alpha = 0.25\n",
    "\n",
    "# Modified triplet loss\n",
    "# Loss 1\n",
    "l_1 = np.maximum(mean_neg - sim_ap.reshape(b, 1) + alpha, 0)\n",
    "l_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "43504db7-eaa8-4c58-8d54-3534b9a14cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20350769],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss 2\n",
    "l_2 = np.maximum(closest_neg - sim_ap.reshape(b, 1) + alpha, 0)\n",
    "l_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "7fbc729c-e1ae-4cd5-b0bf-3ea1cb69e245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40701537],\n",
       "       [0.29649231]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss full\n",
    "l_full = l_1 + l_2\n",
    "l_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2e87530d-e2a9-42cb-a17f-4d57a071b7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7035076825158911"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost\n",
    "cost = np.sum(l_full)\n",
    "cost\n",
    "#perfect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5712579-15ff-47b8-9caf-99d0e9b47152",
   "metadata": {},
   "source": [
    "## loss fn in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "631212c4-8433-4c2f-8753-1c53b07a34a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.9535],\n",
       "        [-0.9535, -1.0000]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.tensor([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])  # ye already normalized hain\n",
    "v2 = torch.tensor([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
    "\n",
    "sim = torch.matmul(v1, v2.T)  # pairwise cosine sim\n",
    "sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72680076-2dd1-480c-8276-b02d6566a014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "b = sim.shape[0]\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d206fe49-6d6f-4f04-80f9-6d29797f8dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., -1.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ap = torch.diag(sim)  # the positive ones (duplicates)\n",
    "sim_ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b1913d9-86ef-4b42-bb98-cd7ccd77e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.9535],\n",
       "        [-0.9535,  0.0000]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_an = sim - torch.diag(sim_ap)\n",
    "sim_an\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce1caec5-028b-4040-b226-a04a08f03926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9535],\n",
       "        [-0.9535]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_neg = torch.sum(sim_an, dim=-1, keepdim=True) / (b - 1)   # direct mean na lena, vahan bt default 'b' say divide hoga, hum nay (b-1) say divide krna hay\n",
    "# also notice: it's, keepdim NOT keepdimS  !!!\n",
    " # keepdimS will also work but will later cause problems\n",
    "mean_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83183f5f-9677-490e-ac04-cf70e92e4152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [False,  True]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_1 = torch.eye(b, device=sim.device) == 1 # mask to exclude the diagonal           # mask_1 = torch.eye(b) == 1\n",
    "mask_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffc3b272-ab56-4e14-beac-224e6002df96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap\n",
    "mask_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efcc8391-51d9-495b-bea6-d8b24fa6fd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False],\n",
       "        [ True,  True]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = mask_1 | mask_2\n",
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e770a66d-7cb7-41a0-9e5f-8d8ce1690834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0000,  0.9535],\n",
       "        [-2.0000, -2.0000]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing the Trues from mask with -2\n",
    "sim_an_masked = sim_an.clone()  # create a copy to preserve sim_an\n",
    "sim_an_masked[mask] = -2\n",
    "\n",
    "\n",
    "# sim_an_masked = torch.clone(sim_an)         # create a copy to preserve sim_an\n",
    "\n",
    "sim_an_masked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "740cfbd2-15ad-484e-8b08-bc4808f3bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9535],\n",
       "        [-2.0000]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_neg = torch.max(sim_an_masked, axis=1, keepdim=True).values                ############################# closest_neg = torch.max(sim_an_masked, axis=1, keepdims=True)\n",
    "                                                                                   ####################closest_neg = closest_neg.values                                             ###########\n",
    "closest_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d669641f-5f0e-413c-93ee-0e0833a4910d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2035],\n",
       "        [0.2965]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alpha margin\n",
    "alpha = 0.25\n",
    "\n",
    "# Modified triplet loss\n",
    "# Loss 1\n",
    "# l_1 = torch.maximum(mean_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0)) ##############\n",
    "l_1 = torch.maximum(mean_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0.0, device=sim.device))\n",
    "\n",
    "l_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01626a7e-2234-44cb-9ebc-fc3ecd3ab34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2035],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss 2\n",
    "#l_2 = torch.maximum(closest_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0)) ##################\n",
    "l_2 = torch.maximum(closest_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0.0, device=sim.device))\n",
    "l_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "36ba9915-0138-4691-8aa2-0b39c13068ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4070],\n",
       "        [0.2965]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss full\n",
    "l_full = l_1 + l_2\n",
    "l_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d74a86d-1023-43a4-986d-b7bc2321e60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7035)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost\n",
    "cost = torch.sum(l_full)\n",
    "cost\n",
    "#perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccf5bf-9ecf-4dcc-a280-cc4ae2ccade7",
   "metadata": {},
   "source": [
    "## Complete TripletLossFn (pytorch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c0911d2b-0302-42b3-b56c-d270fc286094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss: tensor(0.7035)\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "def TripletLossFn(v1_, v2_, margin_=0.25):\n",
    "    \"\"\"Custom Loss function.\n",
    "\n",
    "    Args:\n",
    "        v1 (torch.Tensor): Tensor with dimension (batch_size, model_dimension) associated to Q1.\n",
    "        v2 (torch.Tensor): Tensor with dimension (batch_size, model_dimension) associated to Q2.\n",
    "        margin (float, optional): Desired margin. Defaults to 0.25.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Triplet Loss.\n",
    "    \"\"\"\n",
    "    # use torch to take the dot product of the two batches (don't forget to transpose the second argument)\n",
    "    sim = torch.matmul(v1_, v2_.T)  # pairwise cosine sim\n",
    "    # calculate new batch size\n",
    "    b   = sim.shape[0]\n",
    "    # use torch to grab all positive `diagonal` entries in `scores`\n",
    "    sim_ap = torch.diag(sim)  # the positive ones (duplicates)\n",
    "    # all similarities between the anchor(positive) and the negative sentences\n",
    "    sim_an = sim - torch.diag(sim_ap)\n",
    "\n",
    "\n",
    "    # taking the mean of each row of similarities matrix, excluding diag entries\n",
    "    mean_neg = torch.sum(sim_an, dim=-1, keepdims=True) / (b - 1)  # direct mean na lena, vahan bt default 'b' say divide hoga, hum nay (b-1) say divide krna hay\n",
    "\n",
    "    \n",
    "    # mask to exclude the diagonal from similarities matrix\n",
    "    mask_1 = torch.eye(b, device=sim.device) == 1\n",
    "    # mask to exclude sim_an > sim_ap | i.e. all the similaritiesin each row that are greater than the similarity b/w duplicates for that row\n",
    "    mask_2 = sim_an > sim_ap.reshape(b, 1)\n",
    "\n",
    "\n",
    "    # combining the two masks            | False*False=False else, always True, e.g: False*True=True .....\n",
    "    mask          = mask_1 | mask_2\n",
    "\n",
    "    \n",
    "    # replacing the Trues from mask with -2\n",
    "    sim_an_masked = torch.clone(sim_an)         # create a copy to preserve sim_an\n",
    "    sim_an_masked[mask] = -2\n",
    "\n",
    "\n",
    "    # return the largest value in a row\n",
    "    closest_neg = torch.max(sim_an_masked, axis=1, keepdims=True)\n",
    "    closest_neg = closest_neg.values                                             ########### notice -----.values\n",
    "    \n",
    "\n",
    "    # Loss 1\n",
    "    l_1 = torch.maximum(mean_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0)) ######### notice torch.tensor()\n",
    "    # Loss 2\n",
    "    l_2 = torch.maximum(closest_neg - sim_ap.reshape(b, 1) + alpha, torch.tensor(0)) ######\n",
    "    # Loss full\n",
    "    l_full = l_1 + l_2\n",
    "    # Cost\n",
    "    triplet_loss = torch.sum(l_full)\n",
    "    \n",
    "    return triplet_loss\n",
    "\n",
    "\n",
    "# Example usage\n",
    "v1 = torch.tensor([[0.26726124, 0.53452248, 0.80178373], [-0.5178918, -0.57543534, -0.63297887]])\n",
    "v2 = torch.tensor([[0.26726124, 0.53452248, 0.80178373], [0.5178918, 0.57543534, 0.63297887]])\n",
    "print(\"Triplet Loss:\", TripletLossFn(v1, v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603cd80-1e73-47b9-828d-9b307721c2f5",
   "metadata": {},
   "source": [
    "### Making a TripletLoss layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3064d177-4580-412c-96dc-6dca20fcaf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.703507661819458"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Define the TripletLoss module\n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletLoss, self).__init__()\n",
    "\n",
    "    def forward(self, v1_, v2_, LossFn, margin_=0.25):\n",
    "        return LossFn(v1_, v2_, margin_)\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# batch_of_output_vectors_1 = torch.randn(10, 128, requires_grad=True)  # Example tensor with requires_grad=True\n",
    "# batch_of_output_vectors_2 = torch.randn(10, 128, requires_grad=True)  # Example tensor with requires_grad=True\n",
    "\n",
    "# criterion = TripletLoss()\n",
    "# optimizer = torch.optim.Adam([batch_of_output_vectors_1, batch_of_output_vectors_2], lr=0.001)\n",
    "\n",
    "# loss = criterion(batch_of_output_vectors_1, batch_of_output_vectors_2, TripletLossFn, 0.25)\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "# loss.item()\n",
    "\n",
    "\n",
    "criterion = TripletLoss()\n",
    "loss = criterion(v1, v2, TripletLossFn, 0.25)\n",
    "loss.item()\n",
    "# perfect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db732b-4128-486e-8ed1-fb07fc3dd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d21a4d",
   "metadata": {
    "colab_type": "text",
    "id": "lsvjaCQ6wt02"
   },
   "source": [
    "# Training\n",
    "\n",
    "Now you are going to train your model. As usual, you have to define the cost function and the optimizer. You also have to feed in the built model. Before, going into the training, we will use a special data set up. We will define the inputs using the data generator we built above. The lambda function acts as a seed to remember the last batch that was given. Run the cell below to get the question pairs inputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351528ca-d787-48df-869e-40d49cf9593a",
   "metadata": {},
   "source": [
    "## Testing Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f7817481",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iPk7gh-nzCBg",
    "outputId": "a2e8525d-f89a-4d9d-c0d6-bd7406f0246a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_generator() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_Q1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Q2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<PAD>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m val_generator   \u001b[38;5;241m=\u001b[39m data_generator(val_Q1,   val_Q2,   batch_size, vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_Q1.shape \u001b[39m\u001b[38;5;124m'\u001b[39m, train_Q1\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mTypeError\u001b[0m: data_generator() got an unexpected keyword argument 'shuffle'"
     ]
    }
   ],
   "source": [
    "# batch_size = 256\n",
    "# train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'], shuffle=False)\n",
    "# val_generator   = data_generator(val_Q1,   val_Q2,   batch_size, vocab['<PAD>'], shuffle=False)\n",
    "\n",
    "# print('train_Q1.shape ', train_Q1.shape)\n",
    "# print('val_Q1.shape   ', val_Q1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "9d32bbd8-152d-499a-ac75-85b55a80385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   2,    3,    4, ...,    1,    1,    1],\n",
       "        [  32,   33,    4, ...,    1,    1,    1],\n",
       "        [  32,   38,    4, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [  30,   87,   78, ...,    1,    1,    1],\n",
       "        [  32,   16,  224, ...,    1,    1,    1],\n",
       "        [  30, 1238,  315, ...,    1,    1,    1]]),\n",
       " array([[   4,   22,    6, ...,    1,    1,    1],\n",
       "        [  30,   37,    4, ...,    1,    1,    1],\n",
       "        [  32,   33,    4, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [  30,   87,  116, ...,    1,    1,    1],\n",
       "        [  32,   16,  224, ...,    1,    1,    1],\n",
       "        [  30, 1238,  315, ...,    1,    1,    1]]))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a, b = next(train_generator)\n",
    "# a, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "cf4bb10c-b08d-4687-a9c9-925d618c6f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "eb8480a8-6e1f-4fc7-97f5-8bd813641d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 32), (256, 32))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a.shape, b.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "73c8079d-0ceb-4380-b109-bb9f80f47e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  30,  156,   78, ...,    1,    1,    1],\n",
       "        [  30,   55,  224, ...,    1,    1,    1],\n",
       "        [ 168, 1747,  636, ...,    1,    1,    1],\n",
       "        ...,\n",
       "        [  32,   37,    4, ...,    1,    1,    1],\n",
       "        [ 676,    4,   33, ...,    1,    1,    1],\n",
       "        [  32,  156, 1051, ...,    1,    1,    1]]),\n",
       " array([[ 30, 156,  78, ...,   1,   1,   1],\n",
       "        [443, 138, 218, ...,   1,   1,   1],\n",
       "        [244, 636,  78, ...,   1,   1,   1],\n",
       "        ...,\n",
       "        [ 30,  87,  78, ...,   1,   1,   1],\n",
       "        [676,  33,   4, ...,   1,   1,   1],\n",
       "        [ 30, 156,  78, ...,   1,   1,   1]]))"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a, b = next(train_generator)\n",
    "# a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "5031c911-6d44-4825-b3ca-bf596b3b5cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((256, 64), (256, 64))"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a.shape, b.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f80e5-0d52-4af0-ada0-3fb74d636e54",
   "metadata": {},
   "source": [
    "# Optimizer and Loss Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1934b3d9-cd13-42f1-b7e1-5b606d320b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "\n",
    "criterion = TripletLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d284bc72-d736-4fc7-8579-e5e1627d8261",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "6fe68ea8-572d-40ca-a096-7d1afe77b22a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  50\n",
      "loss:  83.63920114554611\n",
      "\n",
      "i:  100\n",
      "loss:  71.14529264091266\n",
      "\n",
      "i:  150\n",
      "loss:  60.63262353353942\n",
      "\n",
      "i:  200\n",
      "loss:  53.54369906525114\n",
      "\n",
      "i:  250\n",
      "loss:  48.63179216726843\n",
      "\n",
      "i:  300\n",
      "loss:  44.803419246230014\n",
      "\n",
      "Epoch [1/10], Average Loss: 41.931504634868105\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  21.804274951710422\n",
      "\n",
      "i:  100\n",
      "loss:  21.556599494254236\n",
      "\n",
      "i:  150\n",
      "loss:  20.702452931183064\n",
      "\n",
      "i:  200\n",
      "loss:  20.096617784073104\n",
      "\n",
      "i:  250\n",
      "loss:  19.613032010446982\n",
      "\n",
      "i:  300\n",
      "loss:  19.109027571060334\n",
      "\n",
      "Epoch [2/10], Average Loss: 18.73993757734326\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  15.184262930178175\n",
      "\n",
      "i:  100\n",
      "loss:  15.249895766229912\n",
      "\n",
      "i:  150\n",
      "loss:  14.851211276275432\n",
      "\n",
      "i:  200\n",
      "loss:  14.60398600943646\n",
      "\n",
      "i:  250\n",
      "loss:  14.381918481621609\n",
      "\n",
      "i:  300\n",
      "loss:  14.111959333831686\n",
      "\n",
      "Epoch [3/10], Average Loss: 13.908172107357691\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  11.801751959557627\n",
      "\n",
      "i:  100\n",
      "loss:  11.944552742608703\n",
      "\n",
      "i:  150\n",
      "loss:  11.651383286280348\n",
      "\n",
      "i:  200\n",
      "loss:  11.465320686795819\n",
      "\n",
      "i:  250\n",
      "loss:  11.288965120733497\n",
      "\n",
      "i:  300\n",
      "loss:  11.095198493463256\n",
      "\n",
      "Epoch [4/10], Average Loss: 10.958298330662243\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  9.541891537460627\n",
      "\n",
      "i:  100\n",
      "loss:  9.639260381755262\n",
      "\n",
      "i:  150\n",
      "loss:  9.434634473939605\n",
      "\n",
      "i:  200\n",
      "loss:  9.323006957324584\n",
      "\n",
      "i:  250\n",
      "loss:  9.169540733930123\n",
      "\n",
      "i:  300\n",
      "loss:  9.030722855729518\n",
      "\n",
      "Epoch [5/10], Average Loss: 8.917542814183713\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  7.867535768770704\n",
      "\n",
      "i:  100\n",
      "loss:  8.00342075895555\n",
      "\n",
      "i:  150\n",
      "loss:  7.848337890296582\n",
      "\n",
      "i:  200\n",
      "loss:  7.750425682732122\n",
      "\n",
      "i:  250\n",
      "loss:  7.615431757087252\n",
      "\n",
      "i:  300\n",
      "loss:  7.485958180158241\n",
      "\n",
      "Epoch [6/10], Average Loss: 7.401294529267232\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  6.633712946199903\n",
      "\n",
      "i:  100\n",
      "loss:  6.680862162372853\n",
      "\n",
      "i:  150\n",
      "loss:  6.553938298825397\n",
      "\n",
      "i:  200\n",
      "loss:  6.540467858907595\n",
      "\n",
      "i:  250\n",
      "loss:  6.465136272498811\n",
      "\n",
      "i:  300\n",
      "loss:  6.371176858280981\n",
      "\n",
      "Epoch [7/10], Average Loss: 6.308726747944567\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  5.692279067693972\n",
      "\n",
      "i:  100\n",
      "loss:  5.670375389627891\n",
      "\n",
      "i:  150\n",
      "loss:  5.591456037483468\n",
      "\n",
      "i:  200\n",
      "loss:  5.574656238603355\n",
      "\n",
      "i:  250\n",
      "loss:  5.496192276715282\n",
      "\n",
      "i:  300\n",
      "loss:  5.411531729555605\n",
      "\n",
      "Epoch [8/10], Average Loss: 5.35501556820036\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  4.982156692766676\n",
      "\n",
      "i:  100\n",
      "loss:  4.954599803036983\n",
      "\n",
      "i:  150\n",
      "loss:  4.874166643382698\n",
      "\n",
      "i:  200\n",
      "loss:  4.842058427298247\n",
      "\n",
      "i:  250\n",
      "loss:  4.759899448113613\n",
      "\n",
      "i:  300\n",
      "loss:  4.688754046874189\n",
      "\n",
      "Epoch [9/10], Average Loss: 4.645135420441286\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "i:  50\n",
      "loss:  4.400715051912794\n",
      "\n",
      "i:  100\n",
      "loss:  4.401053202034223\n",
      "\n",
      "i:  150\n",
      "loss:  4.344447846444237\n",
      "\n",
      "i:  200\n",
      "loss:  4.332285465885751\n",
      "\n",
      "i:  250\n",
      "loss:  4.2582718395141965\n",
      "\n",
      "i:  300\n",
      "loss:  4.190472526011673\n",
      "\n",
      "Epoch [10/10], Average Loss: 4.150574739478038\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size  = 256\n",
    "# resetting training gen\n",
    "train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n",
    "\n",
    "n_epochs = 10\n",
    "steps_per_epoch = len(train_Q1)//batch_size\n",
    "\n",
    "margin = 0.25\n",
    "\n",
    "# setting up initial hidden and cell state\n",
    "num_layers  = 3\n",
    "batch_size  = batch_size\n",
    "hidden_size = 128\n",
    "# Optionally, create initial hidden and cell states\n",
    "hidden_state = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "memmory_cell = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "# hidden_state.shape\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()                  # agar evaluation accuracy etc bhi check kr rahay hotay tu i guess model ko dobara is tarin mode main dalna zroori tha\n",
    "    total_loss=0.0\n",
    "\n",
    "    i=0\n",
    "    \n",
    "    for batch_of_inputs_1, batch_of_inputs_2 in train_generator:\n",
    "        i+=1\n",
    "        batch_of_inputs_1, batch_of_inputs_2 = torch.from_numpy(batch_of_inputs_1).long().to(device), torch.from_numpy(batch_of_inputs_2).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        batch_of_output_vectors_1, _, _ = model(batch_of_inputs_1, hidden_state, memmory_cell)     # OR batch_of_output_vectors_1, hidden_state, memmory_cell\n",
    "        batch_of_output_vectors_2, _, _ = model(batch_of_inputs_2, hidden_state, memmory_cell)     # OR batch_of_output_vectors_2, hidden_state, memmory_cell\n",
    "\n",
    "        \n",
    "        # Computing the loss\n",
    "        loss = criterion(batch_of_output_vectors_1, batch_of_output_vectors_2, TripletLossFn)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('i: ',i)\n",
    "            print('loss: ', total_loss / (i + 1))\n",
    "            print()\n",
    "        if i >= steps_per_epoch:\n",
    "            break\n",
    "\n",
    "\n",
    "    avg_loss = total_loss / (i + 1)\n",
    "    print(f\"Epoch [{epoch + 1}/{n_epochs}], Average Loss: {avg_loss}\")\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "451b6a1b-0a0b-4c25-8a7e-73599a3fd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'siamese_network.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7213fb6",
   "metadata": {
    "colab_type": "text",
    "id": "abKPe7d4wt1C"
   },
   "source": [
    "# Evaluation  \n",
    "\n",
    "### Evaluating your Siamese Network\n",
    "\n",
    "In this section you will learn how to evaluate a Siamese network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94c40a",
   "metadata": {
    "colab_type": "text",
    "id": "QDi4MBiKpivF"
   },
   "source": [
    "## Classify\n",
    "To determine the accuracy of the model, we will utilize the test set that was configured earlier. While in training we used only positive examples, the test data, Q1_test, Q2_test and y_test, is setup as pairs of questions, some of which are duplicates some are not. \n",
    "This routine will run all the test question pairs through the model, compute the cosine simlarity of each pair, threshold it and compare the result to  y_test - the correct response from the data set. The results are accumulated to produce an accuracy.\n",
    "\n",
    "\n",
    "\n",
    "### Exercise - classify\n",
    "\n",
    "**Instructions**  \n",
    " - Loop through the incoming data in `batch_size` chunks\n",
    " - Use the data generator to load `q1`, `q2` a batch at a time.\n",
    " - copy a `batch_size` chunk of `y` into `y_test`\n",
    " - compute `v1`, `v2` using the model\n",
    " - for each element of the batch\n",
    "        - compute the cos similarity of each pair of entries, `v1[j]`,`v2[j]`\n",
    "        - determine if `d` > threshold\n",
    "        - increment accuracy if that result matches the expected results (`y_test[j]`)\n",
    " - compute the final accuracy and return\n",
    " \n",
    "Due to some limitations of this environment, running classify multiple times may result in the kernel failing. If that happens *Restart Kernal & clear output* and then run from the top. During development, consider using a smaller set of data to reduce the number of calls to model(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "4fdb2f8c",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-h6ZH507fUm"
   },
   "outputs": [],
   "source": [
    "def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n",
    "    \"\"\"Function to test the accuracy of the model.\n",
    "\n",
    "    Args:\n",
    "        test_Q1 (numpy.ndarray): Array of Q1 questions.\n",
    "        test_Q2 (numpy.ndarray): Array of Q2 questions.\n",
    "        y (numpy.ndarray): Array of actual target.\n",
    "        threshold (float): Desired threshold.\n",
    "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
    "        vocab (collections.defaultdict): The vocabulary used.\n",
    "        data_generator (function): Data generator function. Defaults to data_generator.\n",
    "        batch_size (int, optional): Size of the batches. Defaults to 64.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model.\n",
    "    \"\"\"    \n",
    "    \n",
    "    \n",
    "    accuracy = 0\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    for i in range(0, len(test_Q1), batch_size):\n",
    "        # Call the data generator (built in Ex 01) with shuffle= None\n",
    "        # use batch size chuncks of questions as Q1 & Q2 arguments of the data generator. e.g x[i:i + batch_size]\n",
    "        # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
    "        q1, q2 = next(data_generator(test_Q1[i:i+batch_size],test_Q2[i:i+batch_size],batch_size,vocab['<PAD>']))\n",
    "\n",
    "        q1, q2 = torch.from_numpy(q1).long().to(device), torch.from_numpy(q2).long().to(device)\n",
    "        # use batch size chuncks of actual output targets (same syntax as example above)\n",
    "        y_test = y[i:i+batch_size]\n",
    "        y_test = torch.from_numpy(y_test).long().to(device)\n",
    "\n",
    "\n",
    "        # setting up initial hidden and cell state\n",
    "        num_layers  = 3\n",
    "        batch_size  = batch_size\n",
    "        hidden_size = 128\n",
    "        # Optionally, create initial hidden and cell states\n",
    "        hidden_state = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "        memmory_cell = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "        # hidden_state.shape\n",
    "    \n",
    "        \n",
    "        # Call the model    \n",
    "        v1, _, _ = model(q1, hidden_state, memmory_cell)     # OR batch_of_output_vectors_1, hidden_state, memmory_cell\n",
    "        v2, _, _ = model(q2, hidden_state, memmory_cell)     # OR batch_of_output_vectors_2, hidden_state, memmory_cell\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n",
    "            # don't forget to transpose the second argument\n",
    "            d = torch.matmul(v1[j],v2[j])   # yahan .T lenay ki zroorat nahi hay\n",
    "            # is d greater than the threshold?\n",
    "            res = d > threshold\n",
    "            # increment accurancy if y_test is equal `res`\n",
    "            accuracy += (y_test[j]==res)\n",
    "    # compute accuracy using accuracy and total length of test questions\n",
    "    accuracy = accuracy / len(test_Q1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "e959d477-aec6-4d2e-a759-09fc87251048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy tensor(0.7294, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# this takes around 1 minute\n",
    "accuracy = classify(Q1_test,Q2_test, y_test, 0.66, model, vocab, batch_size = 512) \n",
    "print(\"Accuracy\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4b4dc1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yeQjHxkfpivH",
    "outputId": "103b8449-896f-403d-f011-583df70afdae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.74423826\n"
     ]
    }
   ],
   "source": [
    "# # this takes around 1 minute\n",
    "# accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \n",
    "# print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0ad8af-9232-426a-9a05-babba05793fa",
   "metadata": {},
   "source": [
    "##### their result\n",
    "Accuracy 0.74423826"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9d7ae",
   "metadata": {
    "colab_type": "text",
    "id": "CsokYZwhpivJ"
   },
   "source": [
    "**Expected Result**  \n",
    "Accuracy ~0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c782b10",
   "metadata": {
    "colab_type": "text",
    "id": "4-STC44Ywt1I"
   },
   "source": [
    "<a name='5'></a>\n",
    "## 5 -Testing with your Own Questions\n",
    "\n",
    "In this section you will test the model with your own questions. You will write a function `predict` which takes two questions as input and returns $1$ or $0$ depending on whether the question pair is a duplicate or not.   \n",
    "\n",
    "But first, we build a reverse vocabulary that allows to map encoded questions back to words: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645a1aa",
   "metadata": {
    "colab_type": "text",
    "id": "21h3Y0FNpivK"
   },
   "source": [
    "Write a function `predict`that takes in two questions, the model, and the vocabulary and returns whether the questions are duplicates ($1$) or not duplicates ($0$) given a similarity threshold. \n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercise 6 - predict\n",
    "\n",
    "\n",
    "**Instructions:** \n",
    "- Tokenize your question using `nltk.word_tokenize` \n",
    "- Create Q1,Q2 by encoding your questions as a list of numbers using vocab\n",
    "- pad Q1,Q2 with next(data_generator([Q1], [Q2],1,vocab['<PAD>']))\n",
    "- use model() to create v1, v2\n",
    "- compute the cosine similarity (dot product) of v1, v2\n",
    "- compute res by comparing d to the threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "5ab9b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# GRADED FUNCTION: predict\n",
    "def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n",
    "    \"\"\"Function for predicting if two questions are duplicates.\n",
    "\n",
    "    Args:\n",
    "        question1 (str): First question.\n",
    "        question2 (str): Second question.\n",
    "        threshold (float): Desired threshold.\n",
    "        model (trax.layers.combinators.Parallel): The Siamese model.\n",
    "        vocab (collections.defaultdict): The vocabulary used.\n",
    "        data_generator (function): Data generator function. Defaults to data_generator.\n",
    "        verbose (bool, optional): If the results should be printed out. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the questions are duplicates, False otherwise.\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (Replace instances of 'None' with your code) ###\n",
    "    # use `nltk` word tokenize function to tokenize\n",
    "    q1 = nltk.word_tokenize(question1)  # tokenize\n",
    "    q2 = nltk.word_tokenize(question2)  # tokenize\n",
    "    Q1, Q2 = [], []\n",
    "    for word in q1:  # encode q1\n",
    "        # append the 'word' index in `vocab`\n",
    "        Q1.append(vocab[word])\n",
    "    for word in q2:  # encode q2\n",
    "        # append the 'word' index in `vocab`\n",
    "        Q2.append(vocab[word])\n",
    "        \n",
    "    # Call the data generator (built in Ex 01) using next()\n",
    "    # pass [Q1] & [Q2] as Q1 & Q2 arguments of the data generator. Set batch size as 1\n",
    "    # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n",
    "    Q1, Q2 = next(data_generator([Q1],[Q2],1,pad=vocab['<PAD>']))\n",
    "    Q1, Q2 = torch.from_numpy(Q1).long().to(device), torch.from_numpy(Q2).long().to(device)\n",
    "    \n",
    "    # setting up initial hidden and cell state\n",
    "    num_layers  = 3\n",
    "    batch_size  = 1\n",
    "    hidden_size = 128\n",
    "    # Optionally, create initial hidden and cell states\n",
    "    hidden_state = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    memmory_cell = torch.zeros(num_layers, batch_size, hidden_size).to(device)\n",
    "    # hidden_state.shape\n",
    "\n",
    "    \n",
    "    # Call the model\n",
    "    v1, _, _ = model(Q1, hidden_state, memmory_cell)     # OR batch_of_output_vectors_1, hidden_state, memmory_cell\n",
    "    v2, _, _ = model(Q2, hidden_state, memmory_cell)     # OR batch_of_output_vectors_2, hidden_state, memmory_cell\n",
    "\n",
    "\n",
    "    # take dot product to compute cos similarity of each pair of entries, v1, v2\n",
    "    # don't forget to transpose the second argument\n",
    "    d = torch.matmul(v1,v2.T)\n",
    "    # is d greater than the threshold?\n",
    "    res = d > threshold\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n",
    "        print(\"d   = \", d)\n",
    "        print(\"res = \", res)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "e55d5de3-00f1-4511-9f6b-4201779b659d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  tensor([[585,  76,   4,  46,  53,  21]], device='cuda:0') \n",
      "Q2  =  tensor([[ 585,   33,    4,   46,   53, 7280,   21]], device='cuda:0')\n",
      "d   =  tensor([[0.8003]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "res =  tensor([[True]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True]], device='cuda:0')"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to try with your own questions\n",
    "question1 = \"When will I see you?\"\n",
    "question2 = \"When can I see you again?\"\n",
    "# 1/True means it is duplicated, 0/False otherwise\n",
    "predict(question1 , question2, 0.55, model, vocab, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8904f47",
   "metadata": {
    "colab_type": "text",
    "id": "7OEKCa_hpivP"
   },
   "source": [
    "##### Expected Output\n",
    "If input is:\n",
    "```CPP\n",
    "question1 = \"When will I see you?\"\n",
    "question2 = \"When can I see you again?\"\n",
    "```\n",
    "\n",
    "Output is (d may vary a bit):\n",
    "```CPP\n",
    "Q1  =  [[585  76   4  46  53  21   1   1]] \n",
    "Q2  =  [[ 585   33    4   46   53 7280   21    1]]\n",
    "d   =  0.8585515\n",
    "res =  True\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "35bb9960",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "DZccIQ_lpivQ",
    "outputId": "3ed0af7e-5d44-4eb3-cebe-d6f74abe3e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  tensor([[  443,  1145,  3159,  1169,    78, 29017,    21]], device='cuda:0') \n",
      "Q2  =  tensor([[  443,  1145,    60, 15302,    28,    78,  7431,    21]],\n",
      "       device='cuda:0')\n",
      "d   =  tensor([[0.4475]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "res =  tensor([[False]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False]], device='cuda:0')"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to try with your own questions\n",
    "question1 = \"Do they enjoy eating the dessert?\"\n",
    "question2 = \"Do they like hiking in the desert?\"\n",
    "# 1/True means it is duplicated, 0/False otherwise\n",
    "predict(question1 , question2, 0.55, model, vocab, verbose=True) # 0.7 onhoon ny\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5020603",
   "metadata": {
    "colab_type": "text",
    "id": "lWrt-yCMpivS"
   },
   "source": [
    "##### Expected output\n",
    "\n",
    "If input is:\n",
    "```CPP\n",
    "question1 = \"Do they enjoy eating the dessert?\"\n",
    "question2 = \"Do they like hiking in the desert?\"\n",
    "```\n",
    "\n",
    "Output  (d may vary a bit):\n",
    "\n",
    "```CPP\n",
    "Q1  =  [[  443  1145  3159  1169    78 29017    21     1]] \n",
    "Q2  =  [[  443  1145    60 15302    28    78  7431    21]]\n",
    "d   =  0.53644466\n",
    "res =  False\n",
    "False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b06762",
   "metadata": {
    "colab_type": "text",
    "id": "NAfV3l5Zwt1L"
   },
   "source": [
    "You can see that the Siamese network is capable of catching complicated structures. Concretely it can identify question duplicates although the questions do not have many words in common. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "id": "40d94678-1ad2-46d5-8ad8-9727a0fbca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1  =  tensor([[ 443,   53,   60,  128,  495,  986,   28,   78, 1432,   21]],\n",
      "       device='cuda:0') \n",
      "Q2  =  tensor([[ 443,   53,   60, 1149,  960,   28,   78, 1432,   21]],\n",
      "       device='cuda:0')\n",
      "d   =  tensor([[0.5583]], device='cuda:0', grad_fn=<MmBackward0>)\n",
      "res =  tensor([[False]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False]], device='cuda:0')"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feel free to try with your own questions\n",
    "question1 = \"Do you like getting up early in the morning?\"\n",
    "question2 = \"Do you like sleeping late in the morning?\"\n",
    "# 1/True means it is duplicated, 0/False otherwise\n",
    "predict(question1 , question2, 0.66, model, vocab, verbose=True) # 0.7 onhoon nay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f176d2",
   "metadata": {
    "colab_type": "text",
    "id": "FsE8tdTLwt1M"
   },
   "source": [
    "<a name='6'></a>\n",
    "###  <span style=\"color:blue\"> On Siamese Networks </span>\n",
    "\n",
    "Siamese networks are important and useful. Many times there are several questions that are already asked in quora, or other platforms and you can use Siamese networks to avoid question duplicates. \n",
    "\n",
    "Congratulations, you have now built a powerful system that can recognize question duplicates. In the next course we will use transformers for machine translation, summarization, question answering, and chatbots. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736712bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "56d44d6a8424451b5ce45d1ae0b0b7865dc60710e7f74571dd51dd80d7829ee9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
